,Unnamed: 0,Id,Cluster,Sub Cluster,Method,Leak,Fix,Explanation,Explanation - Non leak,New explanation,Model info
0,0,1.0,Imputation,Statistical Imputation,fillna,"1 # Load dataset
2 df = pd.read_csv(""data.csv"")
3 
4 # üö® POTENTIAL LEAKAGE STEP: Imputation applied to the full dataset BEFORE splitting
5 # The mean includes values from both training and future test data.
6 df['income'] = df['income'].fillna(df['income'].mean())
7 
8 # Now we split the dataset
9 X = df.drop(columns='target')
10 y = df['target']
11 X_train, X_test, y_train, y_test = train_test_split(
12     X, y, test_size=0.3, random_state=42
13 )
14 
15 # TRAINING: Model is trained on the training data
16 model = LogisticRegression()
17 model.fit(X_train, y_train)
18 
19 # TESTING: The model is evaluated on the test data
20 preds = model.predict(X_test)","1 # Load dataset
2 df = pd.read_csv(""data.csv"")
3 
4 # FIRST split the data to isolate train/test
5 X = df.drop(columns='target')
6 y = df['target']
7 X_train, X_test, y_train, y_test = train_test_split(
8     X, y, test_size=0.3, random_state=42
9 )
10 
11 # Compute the mean ONLY on training data
12 income_mean = X_train['income'].mean()
13 
14 # Apply the imputation separately
15 X_train['income'] = X_train['income'].fillna(income_mean)
16 X_test['income'] = X_test['income'].fillna(income_mean)
17 
18 # Train and evaluate
19 model = LogisticRegression()
20 model.fit(X_train, y_train)
21 preds = model.predict(X_test)"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Mean imputation applied to the full dataset before splitting, introducing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 20,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 17]  
[Testing method: predict, Testing line: 20]"
1,1,2.0,Imputation,Statistical Imputation,fillna,"1 # Load Titanic dataset (assumed available as 'titanic.csv')
2 df = pd.read_csv(""titanic.csv"")
3 df = df[['Age', 'Pclass', 'Survived']]
4 
5 # ‚ùå Leakage occurs here: we impute using mean computed from the entire dataset (including future test data)
6 df['Age'] = df['Age'].fillna(df['Age'].mean())  # <-- Leakage: global mean includes info from test data
7 
8 # Now we split the already-transformed data
9 X = df[['Age', 'Pclass']]
10 y = df['Survived']
11 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
12 
13 # The imputed X_train is used to train the model
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 
17 # The imputed X_test is used to evaluate the model
18 print(model.score(X_test, y_test))","1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 # First split the data
5 X = df[['Age', 'Pclass']]
6 y = df['Survived']
7 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
8 
9 # ‚úÖ Impute using statistics computed only from the training set
10 age_mean = X_train['Age'].mean()
11 X_train['Age'] = X_train['Age'].fillna(age_mean)
12 X_test['Age'] = X_test['Age'].fillna(age_mean)  # <-- Uses train mean, avoids test data influence
13 
14 # Transformed X_train is used to train the model
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 
18 # Transformed X_test is used to evaluate the model
19 print(model.score(X_test, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Mean imputation is performed on the entire dataset, including future test data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 18]"
2,2,3.0,Imputation,Statistical Imputation,fillna,"1 df = pd.read_csv(""insurance.csv"")  # Assumed to have missing values in 'bmi'
2 
3 # ‚ùå Leakage: imputing 'bmi' before the split using global mean
4 df['bmi'] = df['bmi'].fillna(df['bmi'].mean())  # <-- Uses info from entire dataset, including test set
5 
6 X = df[['age', 'bmi', 'children']]
7 y = df['charges']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
9 
10 # Transformed X_train (with global stats) is used to train the model
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 
15 # Transformed X_test (with global stats) is used for evaluation
16 print(model.score(X_test, y_test))","1 df = pd.read_csv(""insurance.csv"")
2 
3 X = df[['age', 'bmi', 'children']]
4 y = df['charges']
5 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
6 
7 # ‚úÖ Impute using statistics from training set only
8 bmi_mean = X_train['bmi'].mean()
9 X_train['bmi'] = X_train['bmi'].fillna(bmi_mean)
10 X_test['bmi'] = X_test['bmi'].fillna(bmi_mean)  # <-- No test info used
11 
12 # Transformed X_train is used for model training
13 model = LinearRegression()
14 model.fit(X_train, y_train)
15 
16 # Transformed X_test is used for evaluation
17 print(model.score(X_test, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Imputing missing values in 'bmi' using the global mean of the entire dataset, which includes test data.""},
            {""line_number"": 11, ""explanation"": ""Training the model on X_train, which is transformed using the global statistics of the entire dataset, including test data.""},
            {""line_number"": 16, ""explanation"": ""Evaluating the model on X_test, which is transformed using the same global statistics as X_train, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 16]"
3,3,4.0,Imputation,Statistical Imputation,fillna,"1 df = pd.read_csv(""adult.csv"")  # Assumed to have missing values in 'workclass'
2 df = df[['age', 'workclass', 'education-num', 'income']]
3 
4 # ‚ùå Leakage: mode computed from full dataset (includes future test info)
5 mode_workclass = df['workclass'].mode()[0]
6 df['workclass'] = df['workclass'].fillna(mode_workclass)  # <-- Leakage here
7 
8 X = df[['age', 'workclass', 'education-num']]
9 y = df['income']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
11 
12 # Convert categorical to dummies (after leakage)
13 X_train = pd.get_dummies(X_train)
14 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
15 
16 # Model trained and evaluated on transformed data that leaked test info
17 from sklearn.linear_model import LogisticRegression
18 model = LogisticRegression(max_iter=1000)
19 model.fit(X_train, y_train)
20 print(model.score(X_test, y_test))
21 ","1 df = pd.read_csv(""adult.csv"")
2 df = df[['age', 'workclass', 'education-num', 'income']]
3 
4 X = df[['age', 'workclass', 'education-num']]
5 y = df['income']
6 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
7 
8 # ‚úÖ Impute using mode from training data only
9 mode_workclass = X_train['workclass'].mode()[0]
10 X_train['workclass'] = X_train['workclass'].fillna(mode_workclass)
11 X_test['workclass'] = X_test['workclass'].fillna(mode_workclass)
12 
13 # Encode categoricals after correct imputation
14 X_train = pd.get_dummies(X_train)
15 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
16 
17 # Transformed X_train is used to train
18 model = LogisticRegression(max_iter=1000)
19 model.fit(X_train, y_train)
20 
21 # Transformed X_test is used to evaluate
22 print(model.score(X_test, y_test))
23 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Mode computed from full dataset (includes future test info) and used to impute missing values in 'workclass' column""},
            {""line_number"": 6, ""explanation"": ""Imputed 'workclass' values are then applied to the full dataset, leaking test data to the training set""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed with information from the entire dataset.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior imputation.""
    },
    {
      ""line_number"": 20,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data through prior imputation.""
    }
  ]
}
","[Training method: fit, Training line: 19]  
[Testing method: score, Testing line: 20]"
4,4,5.0,Imputation,Statistical Imputation,"df.replace(np.nan, df.mean())","1  # Load dataset
2 df = pd.read_csv(""data.csv"")
3     
4 # üö® Potentially leaky transformation:
5 # Imputation is applied to the full dataset using the global mean (including test data)
6 df = df.replace(np.nan, df.mean())  # ‚ö†Ô∏è Statistical imputation done pre-split
7     
8 # Now we split the data
9 X = df.drop(columns='target')
10 y = df['target']
11 X_train, X_test, y_train, y_test = train_test_split(
12     X, y, test_size=0.3, random_state=42
13 )
14     
15 # Model is trained on the imputed training data
16 model = LogisticRegression()
17 model.fit(X_train, y_train)
18     
19 # Model is evaluated on the imputed test data
20 preds = model.predict(X_test)","1  # Load dataset
2 df = pd.read_csv(""data.csv"")
3     
4 # üö® Potentially leaky transformation:
5 # Imputation is applied to the full dataset using the global mean (including test data)
6 df = df.replace(np.nan, df.mean())  # ‚ö†Ô∏è Statistical imputation done pre-split
7     
8 # Now we split the data
9 X = df.drop(columns='target')
10 y = df['target']
11 X_train, X_test, y_train, y_test = train_test_split(
12     X, y, test_size=0.3, random_state=42
13 )
14     
15 # Model is trained on the imputed training data
16 model = LogisticRegression()
17 model.fit(X_train, y_train)
18 # Model is evaluated on the imputed test data
19 preds = model.predict(X_test)"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Statistical imputation (mean) is applied to the full dataset before splitting""},
            {""line_number"": 15, ""explanation"": ""Model is trained on the imputed training data (leakage from preprocessing)""},
            {""line_number"": 19, ""explanation"": ""Model is evaluated on the imputed test data (leakage from preprocessing)""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 20,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 17]  
[Testing method: predict, Testing line: 20]"
5,5,6.0,Imputation,Statistical Imputation,"df.replace(np.nan, df.mean())","1 df = pd.read_csv(""titanic.csv"")  # Assumes columns like Age, Pclass, Survived
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 # ‚ùå Leakage: replacing NaNs using mean of the full dataset (including future test data)
5 df = df.replace(np.nan, df.mean())  # <-- Mean includes info from the entire dataset
6 
7 X = df[['Age', 'Pclass']]
8 y = df['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
10 
11 # Model is trained on X_train that contains imputed values from global mean
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 
15 # X_test was also imputed using test data stats, so evaluation is affected
16 print(model.score(X_test, y_test))","1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 X = df[['Age', 'Pclass']]
5 y = df['Survived']
6 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
7 
8 # ‚úÖ Compute means from training data only
9 age_mean = X_train['Age'].mean()
10 
11 # Replace NaNs in X_train and X_test using train-only mean
12 X_train = X_train.replace(np.nan, {'Age': age_mean})
13 X_test = X_test.replace(np.nan, {'Age': age_mean})
14 
15 # Transformed X_train is used for model training
16 model = LogisticRegression()
17 model.fit(X_train, y_train)
18 
19 # Transformed X_test is used for evaluation
20 print(model.score(X_test, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Mean imputation is applied to the entire dataset, including future test data""},
            {""line_number"": 15, ""explanation"": ""X_test is also imputed using train data statistics, leading to evaluation bias""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 16]"
6,6,7.0,Imputation,Statistical Imputation,"df.replace(np.nan, df.mean())","1 df = pd.read_csv(""insurance.csv"")  # Dataset with 'age', 'bmi', 'charges', etc.
2 
3 # ‚ùå Leakage: replacing NaNs with mean values computed from the full dataset
4 df = df.replace(np.nan, df.mean())  # <-- Includes test info
5 
6 X = df[['age', 'bmi', 'children']]
7 y = df['charges']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
9 
10 # The model is trained on data that includes leaked imputation values
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 
15 # And tested on the same transformed values
16 print(model.score(X_test, y_test))
17 ","1 df = pd.read_csv(""insurance.csv"")
2 
3 X = df[['age', 'bmi', 'children']]
4 y = df['charges']
5 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)
6 
7 # ‚úÖ Compute train-only means
8 bmi_mean = X_train['bmi'].mean()
9 
10 # Replace NaNs using train-only statistics
11 X_train = X_train.replace(np.nan, {'bmi': bmi_mean})
12 X_test = X_test.replace(np.nan, {'bmi': bmi_mean})
13 
14 # Model training on properly preprocessed data
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 
18 # Evaluation on test set, no leakage from its own statistics
19 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Mean values are computed from the full dataset, including test data.""},
            {""line_number"": 11, ""explanation"": ""The model is trained on data that includes leaked imputation values.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 16]"
7,7,8.0,Imputation,Statistical Imputation,"df.replace(np.nan, df.mean())","1 df = pd.read_csv(""house_prices.csv"")  # Assumes 'LotFrontage', 'GrLivArea', 'SalePrice'
2 
3 # ‚ùå Replacing NaNs globally ‚Äî this is leakage
4 df = df.replace(np.nan, df.mean())  # <-- Global means include test data
5 
6 X = df[['LotFrontage', 'GrLivArea']]
7 y = df['SalePrice']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
9 
10 from sklearn.linear_model import Ridge
11 model = Ridge()
12 model.fit(X_train, y_train)
13 
14 print(model.score(X_test, y_test))  # Evaluation is affected by leakage
15 ","1 df = pd.read_csv(""house_prices.csv"")
2 
3 X = df[['LotFrontage', 'GrLivArea']]
4 y = df['SalePrice']
5 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)
6 
7 # ‚úÖ Train-only mean computation
8 lf_mean = X_train['LotFrontage'].mean()
9 
10 # Replace missing values with training set mean only
11 X_train = X_train.replace(np.nan, {'LotFrontage': lf_mean})
12 X_test = X_test.replace(np.nan, {'LotFrontage': lf_mean})
13 
14 model = Ridge()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Global mean imputation on full dataset before train-test split""},
            {""line_number"": 14, ""explanation"": ""Evaluation on test data that has already been transformed by the model""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 14]"
8,8,9.0,Imputation,Statistical Imputation,SimpleImputer,"1 # Load PIMA Diabetes dataset
2 df = pd.read_csv(""diabetes.csv"")  # Columns like Glucose, BMI, etc.
3 X = df.drop(columns=['Outcome'])
4 y = df['Outcome']
5 
6 # ‚ùå Leakage: Fitting the imputer on the entire dataset before the train-test split
7 imputer = SimpleImputer(strategy='mean')
8 X_imputed = imputer.fit_transform(X)  # <-- Leakage: statistics computed using the full dataset
9 
10 # Now split AFTER transformation ‚Äî test data has influenced the imputer
11 X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)
12 
13 # Transformed X_train is used to train the model
14 model = LogisticRegression(max_iter=1000)
15 model.fit(X_train, y_train)
16 
17 # Transformed X_test is used to evaluate the model
18 print(""Accuracy:"", accuracy_score(y_test, model.predict(X_test)))","1 # Load the dataset
2 df = pd.read_csv(""diabetes.csv"")
3 X = df.drop(columns=['Outcome'])
4 y = df['Outcome']
5 
6 # First: split the data
7 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
8 
9 # ‚úÖ Fit the imputer only on the training data
10 imputer = SimpleImputer(strategy='mean')
11 X_train_imputed = imputer.fit_transform(X_train)  # Uses only training data to compute statistics
12 X_test_imputed = imputer.transform(X_test)        # Applies training stats to test data
13 
14 # Transformed X_train is used to train the model
15 model = LogisticRegression(max_iter=1000)
16 model.fit(X_train_imputed, y_train)
17 
18 # Transformed X_test is used to evaluate the model
19 print(""Accuracy:"", accuracy_score(y_test, model.predict(X_test_imputed)))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""SimpleImputer is fitted on the entire dataset X before the train-test split, which can lead to leakage by computing statistics based on the entire dataset.""},
            {""line_number"": 11, ""explanation"": ""The train-test split is performed after imputation, but the imputer has already been fitted on the entire dataset, leading to information leakage from the test set to the training set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed, meaning the test data influenced the imputation process.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that was influenced by the test data during imputation.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during imputation.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: predict, Testing line: 18]"
9,9,10.0,Imputation,Statistical Imputation,SimpleImputer,"1 
2 df = pd.read_csv(""house_prices.csv"")  # Assume it has 'LotFrontage', 'GrLivArea', 'SalePrice'
3 X = df[['LotFrontage', 'GrLivArea']]
4 y = df['SalePrice']
5 
6 # ‚ùå Leakage: Imputer is fit on the entire dataset (before the split)
7 imputer = SimpleImputer(strategy='mean')
8 X_imputed = imputer.fit_transform(X)  # <-- Uses both train and test data to compute mean
9 
10 # Split happens after leakage
11 X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=0)
12 
13 # Train and evaluate the model on data that has seen leakage
14 model = LinearRegression()
15 model.fit(X_train, y_train)
16 print(""MSE:"", mean_squared_error(y_test, model.predict(X_test)))","1 X = df[['LotFrontage', 'GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
4 
5 # ‚úÖ Imputer is fit only on the training set
6 imputer = SimpleImputer(strategy='mean')
7 X_train_imputed = imputer.fit_transform(X_train)  # <-- Only training data used
8 X_test_imputed = imputer.transform(X_test)        # <-- Applies same transformation
9 
10 # Model trained and evaluated without leakage
11 model = LinearRegression()
12 model.fit(X_train_imputed, y_train)
13 print(""MSE:"", mean_squared_error(y_test, model.predict(X_test_imputed)))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Imputer is fit on the entire dataset (before the split)""},
            {""line_number"": 13, ""explanation"": ""Model is trained and evaluated on data that has already seen leakage (X_train and X_test contain the same imputed values)""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: predict, Testing line: 16]"
10,10,11.0,Imputation,Statistical Imputation,SimpleImputer,"1 df = pd.read_csv(""heart.csv"")  # Assume it has 'chol', 'age', 'target'
2 
3 X = df[['age', 'chol']]
4 y = df['target']
5 
6 # ‚ùå Leakage: Imputer fit on the entire dataset before splitting
7 imputer = SimpleImputer(strategy='mean')
8 X_imputed = imputer.fit_transform(X)  # <-- Leakage: test data influences imputation
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.25, random_state=1)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression(max_iter=1000)
14 model.fit(X_train, y_train)
15 print(""Accuracy:"", model.score(X_test, y_test))","1 X = df[['age', 'chol']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)
4 
5 # ‚úÖ Fit imputer only on training data
6 imputer = SimpleImputer(strategy='mean')
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = LogisticRegression(max_iter=1000)
11 model.fit(X_train_imputed, y_train)
12 print(""Accuracy:"", model.score(X_test_imputed, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Imputer fit on the entire dataset before splitting, leading to overlap leakage as test data influences imputation""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed, meaning the test data has influenced the imputation process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior imputation.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data through the imputation process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
11,11,12.0,Imputation,Statistical Imputation,SimpleImputer,"1 df = pd.read_csv(""StudentsPerformance.csv"")  # Assume it has 'math score', 'reading score', 'writing score'
2 
3 X = df[['math score', 'reading score']]
4 y = df['writing score']
5 
6 # ‚ùå Leakage: Imputer trained on all available data
7 imputer = SimpleImputer(strategy='mean')
8 X_imputed = imputer.fit_transform(X)  # <-- Includes test data information
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(""R2:"", model.score(X_test, y_test))","1 X = df[['math score', 'reading score']]
2 y = df['writing score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
4 
5 # ‚úÖ Train-only imputation
6 imputer = SimpleImputer(strategy='mean')
7 X_train_imputed = imputer.fit_transform(X_train)  # Only training data used to compute mean
8 X_test_imputed = imputer.transform(X_test)        # Applies same transformation to test data
9 
10 model = Ridge()
11 model.fit(X_train_imputed, y_train)
12 print(""R2:"", model.score(X_test_imputed, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Imputer trained on full dataset, including test data, before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
12,12,13.0,Imputation,Statistical Imputation,MeanMedianImputer,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 # ‚ùå Imputer is fit on entire dataset before the split
5 imputer = MeanMedianImputer(imputation_method='mean', variables=['Age'])
6 df_transformed = imputer.fit_transform(df)  # <-- Leakage: statistics include both train and test data
7 
8 # Now we split AFTER the transformation ‚Äî leakage has occurred
9 X = df_transformed[['Age', 'Pclass']]
10 y = df_transformed['Survived']
11 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
12 
13 # Model is trained and evaluated on data transformed with leaked information
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))","1 # Load and split FIRST
2 df = pd.read_csv(""titanic.csv"")
3 df = df[['Age', 'Pclass', 'Survived']]
4 X = df[['Age', 'Pclass']]
5 y = df['Survived']
6 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
7 
8 # ‚úÖ Imputer fit only on training data
9 imputer = MeanMedianImputer(imputation_method='mean', variables=['Age'])
10 X_train = imputer.fit_transform(X_train)
11 X_test = imputer.transform(X_test)  # <-- Applies train-derived mean
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Imputer is fit on entire dataset before the split""},
            {""line_number"": 13, ""explanation"": ""Model is trained and evaluated on data transformed with leaked information""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
13,13,14.0,Imputation,Statistical Imputation,MeanMedianImputer,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Leakage: median calculated from full dataset
5 imputer = MeanMedianImputer(imputation_method='median', variables=['LotFrontage'])
6 df_transformed = imputer.fit_transform(df)
7 
8 X = df_transformed[['LotFrontage', 'GrLivArea']]
9 y = df_transformed['SalePrice']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))","1 df = pd.read_csv(""house_prices.csv"")
2 X = df[['LotFrontage', 'GrLivArea']]
3 y = df['SalePrice']
4 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
5 
6 # ‚úÖ Fit on training data only
7 imputer = MeanMedianImputer(imputation_method='median', variables=['LotFrontage'])
8 X_train = imputer.fit_transform(X_train)
9 X_test = imputer.transform(X_test)
10 
11 model = Ridge()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Median calculated from full dataset, which can lead to preprocessing leakage by introducing bias into the imputed values.""},
            {""line_number"": 10, ""explanation"": ""train_test_split is not called before imputation, which can lead to overlap leakage by using the same indices for both training and testing sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
14,14,15.0,Imputation,Statistical Imputation,MeanMedianImputer,"1 df = pd.read_csv(""StudentsPerformance.csv"")  # Contains: 'math score', 'reading score', 'writing score'
2 
3 # ‚ùå Fit on full dataset
4 imputer = MeanMedianImputer(imputation_method='mean', variables=['math score'])
5 df_transformed = imputer.fit_transform(df)
6 
7 X = df_transformed[['math score', 'reading score']]
8 y = df_transformed['writing score']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['math score', 'reading score']]
2 y = df['writing score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Fit imputer only on training data
6 imputer = MeanMedianImputer(imputation_method='mean', variables=['math score'])
7 X_train = imputer.fit_transform(X_train)
8 X_test = imputer.transform(X_test)
9 
10 model = LinearRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""MeanMedianImputer is fit on the full dataset before splitting it into train and test sets, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
15,15,16.0,Imputation,Statistical Imputation,MeanMedianImputer,"1 df = pd.read_csv(""heart.csv"")  # Contains: 'chol', 'age', 'target'
2 
3 # ‚ùå Fit on full dataset
4 imputer = MeanMedianImputer(imputation_method='median', variables=['chol'])
5 df_transformed = imputer.fit_transform(df)
6 
7 X = df_transformed[['age', 'chol']]
8 y = df_transformed['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression(max_iter=1000)
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'chol']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Train-only fitting of imputer
6 imputer = MeanMedianImputer(imputation_method='median', variables=['chol'])
7 X_train = imputer.fit_transform(X_train)
8 X_test = imputer.transform(X_test)
9 
10 model = LogisticRegression(max_iter=1000)
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""MeanMedianImputer is fitted on the full dataset before train-test split""},
            {""line_number"": 7, ""explanation"": ""X contains features from the full dataset, not only the training set""},
            {""line_number"": 13, ""explanation"": ""Model is trained on the full dataset, not only the training set""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
16,16,17.0,Imputation,Statistical Imputation,EndTailImputer,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Survived']]
3 
4 # ‚ùå Fit EndTailImputer before splitting
5 imputer = EndTailImputer(imputation_method='gaussian', tail='right', variables=['Age'])
6 df_transformed = imputer.fit_transform(df)  # <-- Leakage: test data is part of tail statistics
7 
8 # Now we split the already-transformed data
9 X = df_transformed[['Age', 'Fare']]
10 y = df_transformed['Survived']
11 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
12 
13 # Both X_train and X_test are derived from transformed (leaky) data
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))","1 X = df[['Age', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Fit imputer on training data only
6 imputer = EndTailImputer(imputation_method='gaussian', tail='right', variables=['Age'])
7 X_train = imputer.fit_transform(X_train)
8 X_test = imputer.transform(X_test)  # <-- Uses training stats, no leakage
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""EndTailImputer is fit on the full dataset, including test data, before the train-test split, leading to preprocessing leakage.""},
            {""line_number"": 13, ""explanation"": ""Both X_train and X_test are derived from the same transformed data, which is a form of overlap leakage, as the test set data has already been seen during preprocessing.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
17,17,18.0,Imputation,Statistical Imputation,EndTailImputer,"1 df = pd.read_csv(""heart.csv"")  # Assume 'chol' (cholesterol) has missing values
2 
3 imputer = EndTailImputer(imputation_method='max', variables=['chol'])
4 df_transformed = imputer.fit_transform(df)  # ‚ùå Leakage: test data influences imputation value
5 
6 X = df_transformed[['age', 'chol']]
7 y = df_transformed['target']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['age', 'chol']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Fit only on training set
6 imputer = EndTailImputer(imputation_method='max', variables=['chol'])
7 X_train = imputer.fit_transform(X_train)
8 X_test = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Imputation method is applied to the full dataset before train-test split, causing test data to influence imputation values.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
18,18,19.0,Imputation,Statistical Imputation,EndTailImputer,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Fit before split
5 imputer = EndTailImputer(imputation_method='iqr', tail='right', variables=['LotFrontage'])
6 df_transformed = imputer.fit_transform(df)  # <-- Includes test data in IQR stats
7 
8 X = df_transformed[['LotFrontage', 'GrLivArea']]
9 y = df_transformed['SalePrice']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['LotFrontage', 'GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 imputer = EndTailImputer(imputation_method='iqr', tail='right', variables=['LotFrontage'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EndTailImputer is fit on the entire dataset, including test data, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
19,19,20.0,Imputation,Statistical Imputation,EndTailImputer,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 
3 imputer = EndTailImputer(imputation_method='gaussian', tail='right', variables=['math score'])
4 df_transformed = imputer.fit_transform(df)  # ‚ùå Includes future test data in tail computation
5 
6 X = df_transformed[['math score', 'reading score']]
7 y = df_transformed['writing score']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
9 
10 from sklearn.linear_model import LinearRegression
11 model = LinearRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['math score', 'reading score']]
2 y = df['writing score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 imputer = EndTailImputer(imputation_method='gaussian', tail='right', variables=['math score'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""EndTailImputer is applied to the entire dataset, including future test data, which can lead to preprocessing leakage as the imputation method is based on the entire dataset.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
20,20,21.0,Imputation,Statistical Imputation,CategoricalImputer,"1 df = pd.read_csv(""titanic.csv"")  # Assume columns: Embarked, Pclass, Survived
2 df = df[['Embarked', 'Pclass', 'Survived']]
3 
4 # ‚ùå Imputer is fit on the entire dataset ‚Äî includes test data
5 imputer = CategoricalImputer(imputation_method='frequent', variables=['Embarked'])
6 df_transformed = imputer.fit_transform(df)  # <-- Leakage: test info used to compute most frequent category
7 
8 # Train-test split happens after the data was already transformed
9 X = df_transformed[['Embarked', 'Pclass']]
10 y = df_transformed['Survived']
11 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
12 
13 # Transformed X_train is used for training and X_test for evaluation
14 X_train = pd.get_dummies(X_train)
15 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
16 
17 model = LogisticRegression(max_iter=1000)
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))","1 X = df[['Embarked', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fit imputer on training set only
6 imputer = CategoricalImputer(imputation_method='frequent', variables=['Embarked'])
7 X_train = imputer.fit_transform(X_train)
8 X_test = imputer.transform(X_test)  # <-- Applies training-mode category
9 
10 # Encode and align
11 X_train = pd.get_dummies(X_train)
12 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
13 
14 model = LogisticRegression(max_iter=1000)
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Imputer is fit on the entire dataset, including test data, which can introduce leakage as the most frequent category in the test set may be learned from the training set.""},
            {""line_number"": 11, ""explanation"": ""Train-test split should be done before any preprocessing steps, including data transformation and encoding. In this case, the test set is being transformed using the model learned from the training set, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
21,21,22.0,Imputation,Statistical Imputation,CategoricalImputer,"1 df = pd.read_csv(""loan_prediction.csv"")  # Assume columns: Self_Employed, Education, Loan_Status
2 
3 imputer = CategoricalImputer(imputation_method='frequent', variables=['Self_Employed'])
4 df_transformed = imputer.fit_transform(df)  # ‚ùå Imputation uses full dataset ‚Äî includes test info
5 
6 X = df_transformed[['Self_Employed', 'Education']]
7 y = df_transformed['Loan_Status']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
9 
10 # Model uses leaky data
11 X_train = pd.get_dummies(X_train)
12 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
13 
14 from sklearn.linear_model import LogisticRegression
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['Self_Employed', 'Education']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 imputer = CategoricalImputer(imputation_method='frequent', variables=['Self_Employed'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)  # ‚úÖ No leakage ‚Äî test data untouched
8 
9 X_train = pd.get_dummies(X_train)
10 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""CategoricalImputer is applied to full dataset, including test data, which leads to preprocessing leakage.""},
            {""line_number"": 11, ""explanation"": ""One-hot encoding is applied to train data twice, which is unnecessary and introduces overlap leakage since the transformed X_train is used as input to X_test.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
22,22,23.0,Imputation,Statistical Imputation,CategoricalImputer,"1 df = pd.read_csv(""adult.csv"")  # Assume missing values in 'workclass'
2 
3 imputer = CategoricalImputer(imputation_method='frequent', variables=['workclass'])
4 df_transformed = imputer.fit_transform(df)  # ‚ùå Mode includes info from test set
5 
6 X = df_transformed[['age', 'workclass']]
7 y = df_transformed['income']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
9 
10 X_train = pd.get_dummies(X_train)
11 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
12 
13 from sklearn.linear_model import LogisticRegression
14 model = LogisticRegression(max_iter=1000)
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['age', 'workclass']]
2 y = df['income']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 imputer = CategoricalImputer(imputation_method='frequent', variables=['workclass'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)  # ‚úÖ Uses mode from training set only
8 
9 X_train = pd.get_dummies(X_train)
10 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
11 
12 model = LogisticRegression(max_iter=1000)
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""CategoricalImputer is applied to full dataset before splitting""},
            {""line_number"": 10, ""explanation"": ""One-hot encoding is applied to train set and then to test set using the same columns""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
23,23,24.0,Imputation,Statistical Imputation,CategoricalImputer,"1 df = pd.read_csv(""bank.csv"")  # Assume 'job' has missing values
2 
3 imputer = CategoricalImputer(imputation_method='frequent', variables=['job'])
4 df_transformed = imputer.fit_transform(df)  # ‚ùå Fit on full data ‚Äî test leakage
5 
6 X = df_transformed[['job', 'education']]
7 y = df_transformed['y']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
9 
10 X_train = pd.get_dummies(X_train)
11 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
12 
13 from sklearn.tree import DecisionTreeClassifier
14 model = DecisionTreeClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['job', 'education']]
2 y = df['y']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 imputer = CategoricalImputer(imputation_method='frequent', variables=['job'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)  # ‚úÖ Proper separation ‚Äî no test info used in training
8 
9 X_train = pd.get_dummies(X_train)
10 X_test = pd.get_dummies(X_test).reindex(columns=X_train.columns, fill_value=0)
11 
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Fit CategoricalImputer on full dataset before splitting""},
            {""line_number"": 10, ""explanation"": ""One-hot encoding applied to train and test data using the same columns from the full dataset""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
24,24,25.0,Imputation,Statistical Imputation,df.fillna(method='ffill') ,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 # ‚ùå Forward fill before splitting ‚Äî leaks future (test) values into training set
5 df = df.fillna(method='ffill')  # <-- This forward-fill includes test-set values
6 
7 X = df[['Age', 'Pclass']]
8 y = df['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))","1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 X = df[['Age', 'Pclass']]
5 y = df['Survived']
6 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
7 
8 # ‚úÖ Apply forward fill AFTER split on each set separately
9 X_train = X_train.fillna(method='ffill')
10 X_test = X_test.fillna(method='ffill')  # <-- No leakage: only uses past values within test set
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Forward filling NaN values before splitting leads to leakage of future (test) values into training set""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Forward fill imputation is applied to the full dataset before train-test split, allowing test data values to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed, using information from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data through the forward fill.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
25,25,26.0,Imputation,Statistical Imputation,df.fillna(method='ffill') ,"1 df = pd.read_csv(""heart.csv"")  # Assume missing values in 'chol'
2 df = df[['age', 'chol', 'target']]
3 
4 # ‚ùå Forward fill globally ‚Äî test rows may influence training via fill
5 df = df.fillna(method='ffill')  # <-- Leakage occurs across future split
6 
7 X = df[['age', 'chol']]
8 y = df['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'chol']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Apply forward fill separately on each set
6 X_train = X_train.fillna(method='ffill')
7 X_test = X_test.fillna(method='ffill')  # <-- Ensures no cross-contamination
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Forward fill is applied to the entire dataset, not only to the train set. This can cause information from future rows to leak into the training data, leading to an incorrect model.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Forward fill imputation is applied to the entire dataset before the train-test split, allowing test data to influence the imputation of training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the data has already been imputed, which means the training data is contaminated with information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test data due to prior imputation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that was used to influence the training data during imputation.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
26,26,27.0,Imputation,Statistical Imputation,df.fillna(method='ffill') ,"1 df = pd.read_csv(""loan_prediction.csv"")
2 df = df[['Credit_History', 'ApplicantIncome', 'Loan_Status']]
3 
4 # ‚ùå Forward fill before split ‚Äî allows leakage from test to train
5 df = df.fillna(method='ffill')  # <-- Fills forward across train-test boundary
6 
7 X = df[['Credit_History', 'ApplicantIncome']]
8 y = df['Loan_Status']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.tree import DecisionTreeClassifier
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Credit_History', 'ApplicantIncome']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Forward fill done after splitting ‚Äî avoids info leakage
6 X_train = X_train.fillna(method='ffill')
7 X_test = X_test.fillna(method='ffill')
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Forward fill method applied to the full dataset without considering the train-test split boundary, allowing information from test data to leak into the train data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Forward fill imputation is applied to the entire dataset before the train-test split, allowing test data to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed, meaning the training data has been contaminated with information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to prior imputation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during imputation.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
27,27,28.0,Imputation,Statistical Imputation,df.fillna(method='ffill') ,"1 df = pd.read_csv(""winequality-red.csv"")  # Assume missing values in 'pH'
2 df = df[['pH', 'alcohol', 'quality']]
3 
4 # ‚ùå Forward fill before split
5 df = df.fillna(method='ffill')  # <-- Future rows influence past data
6 
7 X = df[['pH', 'alcohol']]
8 y = df['quality']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['pH', 'alcohol']]
2 y = df['quality']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fill forward independently
6 X_train = X_train.fillna(method='ffill')
7 X_test = X_test.fillna(method='ffill')
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Forward fill method fills missing values using future rows, which can introduce preprocessing leakage as the filled values are based on the future data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation using forward fill is applied to the entire dataset before the train-test split, allowing information from future rows (potentially test data) to influence past rows (training data).""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed, meaning the training and test sets are both contaminated.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by test data through improper preprocessing.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to potentially misleading performance metrics.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
28,28,29.0,Imputation,Statistical Imputation,df.fillna(method='bfill') ,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 # ‚ùå Backward fill applied to full dataset before split ‚Äî future/test rows may fill earlier/train ones
5 df = df.fillna(method='bfill')  # <-- Leakage: test values may influence training rows
6 
7 X = df[['Age', 'Pclass']]
8 y = df['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))","1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Pclass', 'Survived']]
3 
4 X = df[['Age', 'Pclass']]
5 y = df['Survived']
6 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
7 
8 # ‚úÖ Apply bfill separately on training and test sets
9 X_train = X_train.fillna(method='bfill')
10 X_test = X_test.fillna(method='bfill')  # <-- No data leakage between sets
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Backward fill applied to full dataset before split ‚Äî future/test rows may fill earlier/train ones""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Backward fill is applied to the full dataset before train-test split, allowing test data to influence the imputation of training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been filled, meaning the training data is contaminated with information from the test set.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test data due to improper preprocessing.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in preprocessing before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
29,29,30.0,Imputation,Statistical Imputation,df.fillna(method='bfill') ,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Backward fill before split ‚Äî future (test) rows may backfill training data
5 df = df.fillna(method='bfill')  # <-- Leakage occurs here
6 
7 X = df[['LotFrontage', 'GrLivArea']]
8 y = df['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['LotFrontage', 'GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Safe bfill applied post-split, independently
6 X_train = X_train.fillna(method='bfill')
7 X_test = X_test.fillna(method='bfill')
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Backward fill method 'bfill' is applied to the full dataset before splitting the data into train and test sets, potentially leaking information from the test set into the training set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Backward fill is applied to the full dataset before train-test split, allowing test data to influence the imputation of training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been backfilled, meaning the training data has been contaminated with information from the test data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test data due to improper preprocessing.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to potentially biased evaluation results.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
30,30,31.0,Imputation,Statistical Imputation,df.fillna(method='bfill') ,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['math score', 'reading score', 'writing score']]
3 
4 # ‚ùå bfill before split ‚Äî rows from test set may fill training values
5 df = df.fillna(method='bfill')  # <-- Risk of leakage
6 
7 X = df[['math score', 'reading score']]
8 y = df['writing score']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['math score', 'reading score']]
2 y = df['writing score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Post-split bfill ‚Äî each set is handled independently
6 X_train = X_train.fillna(method='bfill')
7 X_test = X_test.fillna(method='bfill')
8 
9 model = LinearRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""DataFrame is filled with missing values using the 'bfill' method before splitting the dataset into train and test sets, which can lead to preprocessing leakage as information from the test set may fill missing values in the training set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Backfill imputation is applied to the full dataset before train-test split, allowing test data to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been backfilled, leading to potential data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data due to prior backfill imputation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in the backfill imputation before the split.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
31,31,32.0,Imputation,Statistical Imputation,df.fillna(method='bfill') ,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'thalach', 'target']]  # Assume 'thalach' (max heart rate) has missing values
3 
4 # ‚ùå bfill before split ‚Äî future data may influence training
5 df = df.fillna(method='bfill')  # <-- This introduces leakage
6 
7 X = df[['age', 'thalach']]
8 y = df['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression(max_iter=1000)
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Apply backward fill only after splitting
6 X_train = X_train.fillna(method='bfill')
7 X_test = X_test.fillna(method='bfill')
8 
9 model = LogisticRegression(max_iter=1000)
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Backfilling missing values with future data before splitting introduces overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Backfill imputation is applied to the full dataset before train-test split, allowing test data to influence the imputation of training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed, meaning the training data has been contaminated with information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test set due to prior imputation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in the imputation process before the split.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
32,32,33.0,Imputation,Model-Based Imputation,Regression Imputation,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # ‚ùå Regression imputation BEFORE split (uses all data, including test rows)
5 age_df = df[df['Age'].notnull()]
6 missing_age_df = df[df['Age'].isnull()]
7 
8 # Train regressor on full data (leakage)
9 reg = LinearRegression()
10 reg.fit(age_df[['Fare', 'Pclass']], age_df['Age'])
11 
12 # Predict missing ages (leaky ‚Äî test data was used to train imputer)
13 df.loc[df['Age'].isnull(), 'Age'] = reg.predict(missing_age_df[['Fare', 'Pclass']])
14 
15 # Now split after transformation ‚Äî leakage has already occurred
16 X = df[['Age', 'Fare', 'Pclass']]
17 y = df['Survived']
18 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
19 
20 model = LogisticRegression()
21 model.fit(X_train, y_train)
22 print(model.score(X_test, y_test))","1 # Split first
2 X = df[['Age', 'Fare', 'Pclass']]
3 y = df['Survived']
4 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
5 
6 # ‚úÖ Train imputer ONLY on training data
7 known = X_train[X_train['Age'].notnull()]
8 unknown = X_train[X_train['Age'].isnull()]
9 reg = LinearRegression()
10 reg.fit(known[['Fare', 'Pclass']], known['Age'])
11 
12 # Impute only on training set
13 X_train.loc[X_train['Age'].isnull(), 'Age'] = reg.predict(unknown[['Fare', 'Pclass']])
14 
15 # Apply same model to test set missing values
16 X_test_missing = X_test[X_test['Age'].isnull()]
17 if not X_test_missing.empty:
18     X_test.loc[X_test['Age'].isnull(), 'Age'] = reg.predict(X_test_missing[['Fare', 'Pclass']])
19 
20 model = LogisticRegression()
21 model.fit(X_train, y_train)
22 print(model.score(X_test, y_test))
23 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Regression imputation is performed on the full dataset before train-test split""},
            {""line_number"": 9, ""explanation"": ""Model is trained on the full dataset (leakage)""},
            {""line_number"": 13, ""explanation"": ""Prediction of missing values is done on the full dataset (leakage)""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""The regression model for imputing missing 'Age' values is trained on the entire dataset, including test data, which causes data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Missing 'Age' values are predicted using a model trained on the entire dataset, allowing test data statistics to influence the imputation.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Train-test split is performed after the data has already been imputed using information from the entire dataset, including the test set.""
    },
    {
      ""line_number"": 21,
      ""explanation"": ""The model is trained on data that has been contaminated by leakage from the imputation process.""
    },
    {
      ""line_number"": 22,
      ""explanation"": ""The model is evaluated on test data that has been contaminated by leakage from the imputation process.""
    }
  ]
}
","[Training method: fit, Training line: 21]  
[Testing method: score, Testing line: 22]"
33,33,34.0,Imputation,Model-Based Imputation,Regression Imputation,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'YearBuilt', 'SalePrice']]
3 
4 # ‚ùå Impute using regression on full dataset
5 reg = LinearRegression()
6 reg.fit(df[df['LotFrontage'].notnull()][['GrLivArea', 'YearBuilt']], df[df['LotFrontage'].notnull()]['LotFrontage'])
7 
8 df.loc[df['LotFrontage'].isnull(), 'LotFrontage'] = reg.predict(df[df['LotFrontage'].isnull()][['GrLivArea', 'YearBuilt']])
9 
10 # Split after ‚Äî test data helped impute training
11 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
12 y = df['SalePrice']
13 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
14 
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Impute LotFrontage using training data only
6 known = X_train[X_train['LotFrontage'].notnull()]
7 unknown = X_train[X_train['LotFrontage'].isnull()]
8 reg = LinearRegression()
9 reg.fit(known[['GrLivArea', 'YearBuilt']], known['LotFrontage'])
10 X_train.loc[unknown.index, 'LotFrontage'] = reg.predict(unknown[['GrLivArea', 'YearBuilt']])
11 
12 # Impute test set using the same model (no refit)
13 test_missing = X_test[X_test['LotFrontage'].isnull()]
14 if not test_missing.empty:
15     X_test.loc[test_missing.index, 'LotFrontage'] = reg.predict(test_missing[['GrLivArea', 'YearBuilt']])
16 
17 model = LinearRegression()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Regression model is fit on a subset of the data, but the imputation is done on the full dataset, which introduces leakage by sharing information between train and test sets.""},
            {""line_number"": 8, ""explanation"": ""The imputed values are filled into the original dataframe, which means the test set also contains the imputed values from the training set, leading to leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation model is fitted on the entire dataset, including test data, which allows test data statistics to influence the imputation.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data to influence the imputed values in the training set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after data has already been imputed using information from the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that was influenced by the test data during imputation.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the imputation process.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
34,34,35.0,Imputation,Model-Based Imputation,Regression Imputation,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 # ‚ùå Fit regressor on entire dataset to predict missing 'chol'
5 reg = LinearRegression()
6 reg.fit(df[df['chol'].notnull()][['age', 'thalach']], df[df['chol'].notnull()]['chol'])
7 
8 df.loc[df['chol'].isnull(), 'chol'] = reg.predict(df[df['chol'].isnull()][['age', 'thalach']])
9 
10 X = df[['age', 'chol', 'thalach']]
11 y = df['target']
12 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
13 
14 from sklearn.linear_model import LogisticRegression
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Fit regression imputer only on training data
6 known = X_train[X_train['chol'].notnull()]
7 unknown = X_train[X_train['chol'].isnull()]
8 reg = LinearRegression()
9 reg.fit(known[['age', 'thalach']], known['chol'])
10 X_train.loc[unknown.index, 'chol'] = reg.predict(unknown[['age', 'thalach']])
11 
12 # Apply imputer to test set using same model
13 test_missing = X_test[X_test['chol'].isnull()]
14 if not test_missing.empty:
15     X_test.loc[test_missing.index, 'chol'] = reg.predict(test_missing[['age', 'thalach']])
16 
17 model = LogisticRegression()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 "," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }

This code does not have leakage. The Linear Regression model is not being used to predict missing values in the dataset. Instead, it is being used to handle missing values by imputing them using the regression model. This is done after the train-test split. The Logistic Regression model is being fitted on the split dataset."," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""The LinearRegression model is fit on the entire dataset to predict missing 'chol' values, which includes information from the test set.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""The predicted 'chol' values are filled in the dataset before the train-test split, causing data leakage as test data statistics influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the 'chol' values have been imputed using a model trained on the entire dataset, leading to leakage.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the imputation step.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the imputation step.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
35,35,36.0,Imputation,Model-Based Imputation,Regression Imputation,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 # ‚ùå Regressor fit on full dataset
5 reg = LinearRegression()
6 reg.fit(df[df['BMI'].notnull()][['Glucose', 'Age']], df[df['BMI'].notnull()]['BMI'])
7 
8 df.loc[df['BMI'].isnull(), 'BMI'] = reg.predict(df[df['BMI'].isnull()][['Glucose', 'Age']])
9 
10 X = df[['Glucose', 'BMI', 'Age']]
11 y = df['Outcome']
12 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
13 
14 from sklearn.linear_model import LogisticRegression
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Train imputer only on X_train
6 known = X_train[X_train['BMI'].notnull()]
7 unknown = X_train[X_train['BMI'].isnull()]
8 reg = LinearRegression()
9 reg.fit(known[['Glucose', 'Age']], known['BMI'])
10 X_train.loc[unknown.index, 'BMI'] = reg.predict(unknown[['Glucose', 'Age']])
11 
12 # Apply same model to test data
13 test_missing = X_test[X_test['BMI'].isnull()]
14 if not test_missing.empty:
15     X_test.loc[test_missing.index, 'BMI'] = reg.predict(test_missing[['Glucose', 'Age']])
16 
17 model = LogisticRegression()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""The model is fit on the full dataset before splitting it into train and test sets, which can lead to preprocessing leakage as features are transformed based on the target variable.""},
            {""line_number"": 8, ""explanation"": ""The missing values in the 'BMI' column are filled using the regression model that was fit on the full dataset, introducing overlap leakage as the test set is now contaminated with the information from the train set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""The Linear Regression model is fit on the entire dataset to impute missing BMI values, causing data leakage as it uses information from the test set.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""The imputation of missing BMI values is done using a model trained on the full dataset, contaminating the test set with training data information.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the BMI values have been imputed using a model trained on the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""The Logistic Regression model is trained on data that has been contaminated by the imputation process, which used information from the test set.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""The model is evaluated on a test set that has been contaminated by the imputation process, which used information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
36,36,37.0,Imputation,Model-Based Imputation,KNNImputer,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # ‚ùå KNNImputer fit on the entire dataset ‚Äî includes both training and future test data
5 imputer = KNNImputer(n_neighbors=3)
6 df_imputed = imputer.fit_transform(df[['Age', 'Fare', 'Pclass']])  # <-- Leakage occurs here
7 
8 X = pd.DataFrame(df_imputed, columns=['Age', 'Fare', 'Pclass'])
9 y = df['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))","1 X = df[['Age', 'Fare', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Fit KNNImputer only on training data ‚Äî no leakage
6 imputer = KNNImputer(n_neighbors=3)
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)  # <-- Applies imputer without re-fitting on test
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""KNNImputer fit on the entire dataset ‚Äî includes both training and future test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
37,37,38.0,Imputation,Model-Based Imputation,KNNImputer,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Imputer fitted before train-test split
5 imputer = KNNImputer(n_neighbors=5)
6 df_imputed = imputer.fit_transform(df[['LotFrontage', 'GrLivArea']])  # <-- Test data influences imputation
7 
8 X = pd.DataFrame(df_imputed, columns=['LotFrontage', 'GrLivArea'])
9 y = df['SalePrice']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['LotFrontage', 'GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Imputer trained only on training data
6 imputer = KNNImputer(n_neighbors=5)
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = Ridge()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Imputer is fitted using the full dataset before train-test split, which can introduce leakage when test data influences imputation""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
38,38,39.0,Imputation,Model-Based Imputation,KNNImputer,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 # ‚ùå Imputer fit before split ‚Äî test data used during neighbor computation
5 imputer = KNNImputer(n_neighbors=3)
6 df_imputed = imputer.fit_transform(df[['Glucose', 'BMI', 'Age']])  # <-- Leakage
7 
8 X = pd.DataFrame(df_imputed, columns=['Glucose', 'BMI', 'Age'])
9 y = df['Outcome']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ KNNImputer fit only on training data
6 imputer = KNNImputer(n_neighbors=3)
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Imputer fit on full dataset before train-test split, affecting test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""KNNImputer is fit on the entire dataset before train-test split, allowing test data to influence the imputation of training data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed using the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
39,39,40.0,Imputation,Model-Based Imputation,KNNImputer,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 # ‚ùå KNNImputer sees entire dataset
5 imputer = KNNImputer(n_neighbors=4)
6 df_imputed = imputer.fit_transform(df[['age', 'chol', 'thalach']])  # <-- Future/test rows used for neighbors
7 
8 X = pd.DataFrame(df_imputed, columns=['age', 'chol', 'thalach'])
9 y = df['target']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Fit on training data only
6 imputer = KNNImputer(n_neighbors=4)
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""KNNImputer fits on the entire dataset, including future/test rows, leading to preprocessing leakage.""},
            {""line_number"": 10, ""explanation"": ""train_test_split is not called before the model is trained, leading to overlap leakage as the test set is not properly separated.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data to influence the imputation of training data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed, meaning the test data influenced the training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data during imputation.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used during the imputation process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
40,40,41.0,Imputation,Model-Based Imputation,Autoencoder-Based Imputation ,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # Normalize and fill missing with 0 temporarily
5 data = df[['Age', 'Fare', 'Pclass']].copy()
6 mask = data.isnull()
7 data = data.fillna(0)
8 
9 # ‚ùå Train autoencoder on full data (includes test rows)
10 model = Sequential([
11     Input(shape=(3,)),
12     Dense(4, activation='relu'),
13     Dense(3)
14 ])
15 model.compile(optimizer='adam', loss='mse')
16 model.fit(data, data, epochs=50, verbose=0)
17 
18 # Predict missing values
19 reconstructed = model.predict(data)
20 data[mask] = reconstructed[mask]
21 
22 df[['Age', 'Fare', 'Pclass']] = data
23 
24 # Now split (leakage has already happened)
25 X = df[['Age', 'Fare', 'Pclass']]
26 y = df['Survived']
27 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
28 
29 model_final = LogisticRegression()
30 model_final.fit(X_train, y_train)
31 print(model_final.score(X_test, y_test))","1 X = df[['Age', 'Fare', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # Preprocessing: fill missing with 0 temporarily for training
6 train_data = X_train.copy()
7 train_mask = train_data.isnull()
8 train_data = train_data.fillna(0)
9 
10 # ‚úÖ Train autoencoder ONLY on training data
11 model = Sequential([
12     Input(shape=(3,)),
13     Dense(4, activation='relu'),
14     Dense(3)
15 ])
16 model.compile(optimizer='adam', loss='mse')
17 model.fit(train_data, train_data, epochs=50, verbose=0)
18 
19 # Impute training data
20 train_reconstructed = model.predict(train_data)
21 train_data[train_mask] = train_reconstructed[train_mask]
22 
23 # Impute test data using same model (no retraining)
24 test_data = X_test.copy()
25 test_mask = test_data.isnull()
26 test_data = test_data.fillna(0)
27 test_reconstructed = model.predict(test_data)
28 test_data[test_mask] = test_reconstructed[test_mask]
29 
30 model_final = LogisticRegression()
31 model_final.fit(train_data, y_train)
32 print(model_final.score(test_data, y_test))
33 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""Model is trained on full dataset, including test rows""},
            {""line_number"": 25, ""explanation"": ""X_train and X_test are created after the model has already been trained on the full dataset, causing overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 16,
      ""explanation"": ""The autoencoder model is trained on the entire dataset, including test data, which allows information from the test set to influence the model.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Predictions for missing values are made using the autoencoder trained on the full dataset, contaminating the data with test set information.""
    },
    {
      ""line_number"": 24,
      ""explanation"": ""Train-test split is performed after the data has been reconstructed using the autoencoder trained on the full dataset, leading to data leakage.""
    },
    {
      ""line_number"": 30,
      ""explanation"": ""The Logistic Regression model is trained on data that has been contaminated by the autoencoder's predictions, which were influenced by the test set.""
    },
    {
      ""line_number"": 31,
      ""explanation"": ""The model evaluation is performed on a test set that has been contaminated by the autoencoder's predictions, leading to misleading performance metrics.""
    }
  ]
}
","[Training method: fit, Training line: 30]  
[Testing method: score, Testing line: 31]"
41,41,42.0,Imputation,Model-Based Imputation,Autoencoder-Based Imputation ,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'YearBuilt', 'SalePrice']]
3 
4 # Temporary fill for training
5 data = df[['LotFrontage', 'GrLivArea', 'YearBuilt']].fillna(0)
6 mask = df[['LotFrontage', 'GrLivArea', 'YearBuilt']].isnull()
7 
8 # ‚ùå Autoencoder trained on full data, including test info
9 model = Sequential([
10     Input(shape=(3,)),
11     Dense(4, activation='relu'),
12     Dense(3)
13 ])
14 model.compile(optimizer='adam', loss='mse')
15 model.fit(data, data, epochs=50, verbose=0)
16 
17 reconstructed = model.predict(data)
18 data[mask] = reconstructed[mask]
19 df[['LotFrontage', 'GrLivArea', 'YearBuilt']] = data
20 
21 # Split AFTER imputation ‚Äî leakage has occurred
22 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
23 y = df['SalePrice']
24 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
25 
26 model_final = Ridge()
27 model_final.fit(X_train, y_train)
28 print(model_final.score(X_test, y_test))","1 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # Train-only data preparation
6 train_data = X_train.fillna(0)
7 train_mask = X_train.isnull()
8 
9 # ‚úÖ Train autoencoder only on training data
10 model = Sequential([
11     Input(shape=(3,)),
12     Dense(4, activation='relu'),
13     Dense(3)
14 ])
15 model.compile(optimizer='adam', loss='mse')
16 model.fit(train_data, train_data, epochs=50, verbose=0)
17 
18 train_reconstructed = model.predict(train_data)
19 train_data[train_mask] = train_reconstructed[train_mask]
20 
21 # Impute test data using same model
22 test_data = X_test.fillna(0)
23 test_mask = X_test.isnull()
24 test_reconstructed = model.predict(test_data)
25 test_data[test_mask] = test_reconstructed[test_mask]
26 
27 model_final = Ridge()
28 model_final.fit(train_data, y_train)
29 print(model_final.score(test_data, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Model is trained and evaluated on full dataset, including test information""},
            {""line_number"": 15, ""explanation"": ""Model is fit on the same data that was previously transformed and imputed""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Autoencoder model is trained on the entire dataset, including test data, which contaminates the training process with test data information.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Reconstructed data from the autoencoder, which was trained on the full dataset, is used to fill missing values, leading to data leakage.""
    },
    {
      ""line_number"": 24,
      ""explanation"": ""Train-test split is performed after data has already been imputed and transformed using information from the entire dataset.""
    },
    {
      ""line_number"": 27,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to prior transformations.""
    },
    {
      ""line_number"": 28,
      ""explanation"": ""Model is evaluated on the contaminated test data, which has been influenced by the training process due to prior leakage.""
    }
  ]
}
","[Training method: fit, Training line: 27]  
[Testing method: score, Testing line: 28]"
42,42,43.0,Imputation,Model-Based Imputation,Autoencoder-Based Imputation ,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 data = df[['age', 'chol', 'thalach']].fillna(0)
5 mask = df[['age', 'chol', 'thalach']].isnull()
6 
7 # ‚ùå Training on full dataset causes leakage
8 model = Sequential([
9     Input(shape=(3,)),
10     Dense(4, activation='relu'),
11     Dense(3)
12 ])
13 model.compile(optimizer='adam', loss='mse')
14 model.fit(data, data, epochs=50, verbose=0)
15 
16 reconstructed = model.predict(data)
17 data[mask] = reconstructed[mask]
18 df[['age', 'chol', 'thalach']] = data
19 
20 X = df[['age', 'chol', 'thalach']]
21 y = df['target']
22 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
23 
24 from sklearn.linear_model import LogisticRegression
25 model_final = LogisticRegression()
26 model_final.fit(X_train, y_train)
27 print(model_final.score(X_test, y_test))
28 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 train_data = X_train.fillna(0)
6 train_mask = X_train.isnull()
7 
8 # ‚úÖ Train autoencoder only on training data
9 model = Sequential([
10     Input(shape=(3,)),
11     Dense(4, activation='relu'),
12     Dense(3)
13 ])
14 model.compile(optimizer='adam', loss='mse')
15 model.fit(train_data, train_data, epochs=50, verbose=0)
16 
17 train_reconstructed = model.predict(train_data)
18 train_data[train_mask] = train_reconstructed[train_mask]
19 
20 test_data = X_test.fillna(0)
21 test_mask = X_test.isnull()
22 test_reconstructed = model.predict(test_data)
23 test_data[test_mask] = test_reconstructed[test_mask]
24 
25 model_final = LogisticRegression()
26 model_final.fit(train_data, y_train)
27 print(model_final.score(test_data, y_test))
28 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Model is trained on the full dataset before splitting (X = df[['age', 'chol', 'thalach']])""},
            {""line_number"": 14, ""explanation"": ""Model is fit with the same data as for training (model.fit(data, data))""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""The autoencoder model is trained on the full dataset, including test data, causing data leakage.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Reconstructed values from the autoencoder, trained on the full dataset, are used to fill missing values, contaminating the dataset.""
    },
    {
      ""line_number"": 22,
      ""explanation"": ""Train-test split is performed after data has already been imputed and reconstructed using the full dataset, leading to leakage.""
    },
    {
      ""line_number"": 26,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 27,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 26]  
[Testing method: score, Testing line: 27]"
43,43,44.0,Imputation,Model-Based Imputation,Autoencoder-Based Imputation ,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 data = df[['Glucose', 'BMI', 'Age']].fillna(0)
5 mask = df[['Glucose', 'BMI', 'Age']].isnull()
6 
7 # ‚ùå Training on full data includes test info
8 model = Sequential([
9     Input(shape=(3,)),
10     Dense(4, activation='relu'),
11     Dense(3)
12 ])
13 model.compile(optimizer='adam', loss='mse')
14 model.fit(data, data, epochs=50, verbose=0)
15 
16 reconstructed = model.predict(data)
17 data[mask] = reconstructed[mask]
18 df[['Glucose', 'BMI', 'Age']] = data
19 
20 X = df[['Glucose', 'BMI', 'Age']]
21 y = df['Outcome']
22 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
23 
24 from sklearn.linear_model import LogisticRegression
25 model_final = LogisticRegression()
26 model_final.fit(X_train, y_train)
27 print(model_final.score(X_test, y_test))
28 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 train_data = X_train.fillna(0)
6 train_mask = X_train.isnull()
7 
8 # ‚úÖ Train autoencoder only on training data
9 model = Sequential([
10     Input(shape=(3,)),
11     Dense(4, activation='relu'),
12     Dense(3)
13 ])
14 model.compile(optimizer='adam', loss='mse')
15 model.fit(train_data, train_data, epochs=50, verbose=0)
16 
17 train_reconstructed = model.predict(train_data)
18 train_data[train_mask] = train_reconstructed[train_mask]
19 
20 test_data = X_test.fillna(0)
21 test_mask = X_test.isnull()
22 test_reconstructed = model.predict(test_data)
23 test_data[test_mask] = test_reconstructed[test_mask]
24 
25 model_final = LogisticRegression()
26 model_final.fit(train_data, y_train)
27 print(model_final.score(test_data, y_test))
28 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Model is trained on the entire dataset, including test data""},
            {""line_number"": 14, ""explanation"": ""Model is fit using the same data as for prediction, which includes test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""The model is trained on the full dataset, including test data, which contaminates the training process.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Reconstructed values from the model trained on full data are used to fill missing values, contaminating the dataset with test data information.""
    },
    {
      ""line_number"": 22,
      ""explanation"": ""Train-test split is performed after data has already been imputed and reconstructed using the full dataset, leading to leakage.""
    },
    {
      ""line_number"": 26,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set.""
    },
    {
      ""line_number"": 27,
      ""explanation"": ""Model is evaluated on the contaminated test data, which has been influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 26]  
[Testing method: score, Testing line: 27]"
44,44,45.0,Imputation,Model-Based Imputation,"Generative Adversarial Networks 
(GANs) for Imputation ","1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # Simulate missingness and GAN-based imputation
5 data = df[['Age', 'Fare', 'Pclass']].copy()
6 mask = data.isnull()
7 
8 # ‚ùå Simulate a GAN trained on full dataset (imputation uses full-data correlations)
9 # In practice: you'd train GAIN or similar here
10 gan_imputed_data = data.fillna(data.mean()) + np.random.normal(0, 0.1, data.shape)  # Fake GAN behavior
11 
12 # Use this data downstream
13 df[['Age', 'Fare', 'Pclass']] = gan_imputed_data
14 
15 # Split happens AFTER leakage occurred
16 X = df[['Age', 'Fare', 'Pclass']]
17 y = df['Survived']
18 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
19 
20 model = LogisticRegression()
21 model.fit(X_train, y_train)
22 print(model.score(X_test, y_test))","1 X = df[['Age', 'Fare', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ GAN (simulated) is trained only on training data
6 train_data = X_train.copy()
7 train_mask = train_data.isnull()
8 train_data_imputed = train_data.fillna(train_data.mean()) + np.random.normal(0, 0.1, train_data.shape)
9 
10 test_data = X_test.copy()
11 test_mask = test_data.isnull()
12 test_data_imputed = test_data.fillna(train_data.mean()) + np.random.normal(0, 0.1, test_data.shape)  # Reuse train-only distribution
13 
14 model = LogisticRegression()
15 model.fit(train_data_imputed, y_train)
16 print(model.score(test_data_imputed, y_test))
17 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""GAN model is trained on the full dataset, which might leak information to the imputation process""},
            {""line_number"": 13, ""explanation"": ""Imputed data is directly applied to the original dataset without proper splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Imputation using the mean of the entire dataset is performed before the train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""The imputed data, which contains leakage from the test set, is assigned back to the dataframe before splitting.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Train-test split is performed after the data has already been imputed with leakage.""
    },
    {
      ""line_number"": 21,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set.""
    },
    {
      ""line_number"": 22,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to potentially inflated performance metrics.""
    }
  ]
}
","[Training method: fit, Training line: 21]  
[Testing method: score, Testing line: 22]"
45,45,46.0,Imputation,Model-Based Imputation,"Generative Adversarial Networks 
(GANs) for Imputation ","1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'YearBuilt', 'SalePrice']]
3 
4 # ‚ùå GAN trained on all data (test info leaks in)
5 data = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
6 gan_imputed = data.fillna(data.mean()) + np.random.normal(0, 0.1, data.shape)  # Fake GAN behavior
7 
8 df[['LotFrontage', 'GrLivArea', 'YearBuilt']] = gan_imputed
9 
10 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
11 y = df['SalePrice']
12 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
13 
14 from sklearn.linear_model import Ridge
15 model = Ridge()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ GAN (simulated) trained only on training data
6 X_train_imp = X_train.fillna(X_train.mean()) + np.random.normal(0, 0.1, X_train.shape)
7 X_test_imp = X_test.fillna(X_train.mean()) + np.random.normal(0, 0.1, X_test.shape)
8 
9 model = Ridge()
10 model.fit(X_train_imp, y_train)
11 print(model.score(X_test_imp, y_test))
12 "," {
        ""leakage_detected"": false
    }

    {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""The entire dataset is being used to generate imputed values, which can include test data.""},
            {""line_number"": 8, ""explanation"": ""Imputed values are being overwritten back to the original dataset, contaminating the test data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation using mean is applied to the entire dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been imputed with test data information.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to potentially inflated performance metrics.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
46,46,47.0,Imputation,Model-Based Imputation,"Generative Adversarial Networks 
(GANs) for Imputation ","1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 data = df[['Glucose', 'BMI', 'Age']]
5 gan_imputed = data.fillna(data.mean()) + np.random.normal(0, 0.05, data.shape)
6 
7 df[['Glucose', 'BMI', 'Age']] = gan_imputed
8 
9 X = df[['Glucose', 'BMI', 'Age']]
10 y = df['Outcome']
11 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
12 
13 from sklearn.linear_model import LogisticRegression
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 X_train_imp = X_train.fillna(X_train.mean()) + np.random.normal(0, 0.05, X_train.shape)
6 X_test_imp = X_test.fillna(X_train.mean()) + np.random.normal(0, 0.05, X_test.shape)
7 
8 model = LogisticRegression()
9 model.fit(X_train_imp, y_train)
10 print(model.score(X_test_imp, y_test))
11 "," {
        ""leakage_detected"": false
    }

This code does not contain leakage. The data is being preprocessed (imputed with GAN) before the train-test split. This is not considered leakage as long as the same transformation is applied to both the training and test sets. In this case, the transformation is being applied to the entire dataset, but that is not the issue. The issue would arise if the transformation was only applied to the training set."," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
47,47,48.0,Imputation,Model-Based Imputation,"Generative Adversarial Networks 
(GANs) for Imputation ","1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 gan_imputed = df[['age', 'chol', 'thalach']].fillna(df.mean()) + np.random.normal(0, 0.1, df.shape)
5 
6 df[['age', 'chol', 'thalach']] = gan_imputed
7 
8 X = df[['age', 'chol', 'thalach']]
9 y = df['target']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 X_train_imp = X_train.fillna(X_train.mean()) + np.random.normal(0, 0.1, X_train.shape)
6 X_test_imp = X_test.fillna(X_train.mean()) + np.random.normal(0, 0.1, X_test.shape)
7 
8 model = LogisticRegression()
9 model.fit(X_train_imp, y_train)
10 print(model.score(X_test_imp, y_test))
11 "," {
        ""leakage_detected"": false
    }

This code snippet does not contain any leakage. The data preprocessing (imputation) is done on the subset of the data (X) that will be used for training and testing."," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
48,48,49.0,Imputation,Iterative & Multiple Imputation,iterativeImputer,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # ‚ùå Fit IterativeImputer on full data (includes test-set information)
5 imp = IterativeImputer()
6 X_imputed = imp.fit_transform(df[['Age', 'Fare', 'Pclass']])  # <-- Leakage occurs here
7 
8 X = pd.DataFrame(X_imputed, columns=['Age', 'Fare', 'Pclass'])
9 y = df['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))","1 X = df[['Age', 'Fare', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Fit IterativeImputer ONLY on training data
6 imp = IterativeImputer()
7 X_train_imputed = imp.fit_transform(X_train)
8 X_test_imputed = imp.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""IterativeImputer is fitted on the full dataset, including test-set indices, before the train-test split. This can lead to information leakage as the imputer may use test-set information to fill missing values in the training set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
49,49,50.0,Imputation,Iterative & Multiple Imputation,iterativeImputer,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'YearBuilt', 'SalePrice']]
3 
4 imp = IterativeImputer()
5 X_imputed = imp.fit_transform(df[['LotFrontage', 'GrLivArea', 'YearBuilt']])  # ‚ùå Trained on all data
6 
7 X = pd.DataFrame(X_imputed, columns=['LotFrontage', 'GrLivArea', 'YearBuilt'])
8 y = df['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 imp = IterativeImputer()
6 X_train_imputed = imp.fit_transform(X_train)
7 X_test_imputed = imp.transform(X_test)  # ‚úÖ Uses training-only model for imputation
8 
9 model = Ridge()
10 model.fit(X_train_imputed, y_train)
11 print(model.score(X_test_imputed, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""IterativeImputer is fit on the entire dataset without splitting it, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
50,50,51.0,Imputation,Iterative & Multiple Imputation,iterativeImputer,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 imp = IterativeImputer()
5 X_imputed = imp.fit_transform(df[['age', 'chol', 'thalach']])  # ‚ùå Fit on full dataset
6 
7 X = pd.DataFrame(X_imputed, columns=['age', 'chol', 'thalach'])
8 y = df['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 imp = IterativeImputer()
6 X_train_imputed = imp.fit_transform(X_train)
7 X_test_imputed = imp.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_imputed, y_train)
11 print(model.score(X_test_imputed, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""IterativeImputer is fit on the full dataset before splitting it into train and test sets, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
51,51,52.0,Imputation,Iterative & Multiple Imputation,iterativeImputer,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 imp = IterativeImputer()
5 X_imputed = imp.fit_transform(df[['Glucose', 'BMI', 'Age']])  # ‚ùå Fit before split = leakage
6 
7 X = pd.DataFrame(X_imputed, columns=['Glucose', 'BMI', 'Age'])
8 y = df['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 imp = IterativeImputer()
6 X_train_imputed = imp.fit_transform(X_train)
7 X_test_imputed = imp.transform(X_test)  # ‚úÖ No test data involved in imputer training
8 
9 model = LogisticRegression()
10 model.fit(X_train_imputed, y_train)
11 print(model.score(X_test_imputed, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Fit IterativeImputer on full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
52,52,53.0,Imputation,Iterative & Multiple Imputation,"Expectation-Maximization (EM) 
Imputation","1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # ‚ùå EM Imputation applied to full dataset ‚Äî includes test info
5 imputer = IterativeImputer()
6 X_imputed = imputer.fit_transform(df[['Age', 'Fare', 'Pclass']])  # <-- Leakage here
7 
8 X = pd.DataFrame(X_imputed, columns=['Age', 'Fare', 'Pclass'])
9 y = df['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Age', 'Fare', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ EM Imputer fit only on training set
6 imputer = IterativeImputer()
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Imputation applied to full dataset before splitting""},
            {""line_number"": 10, ""explanation"": ""train_test_split is not called before imputation""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
53,53,54.0,Imputation,Iterative & Multiple Imputation,"Expectation-Maximization (EM) 
Imputation","1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'YearBuilt', 'SalePrice']]
3 
4 # ‚ùå Fit EM imputer before split ‚Äî includes test data
5 imputer = IterativeImputer()
6 X_imputed = imputer.fit_transform(df[['LotFrontage', 'GrLivArea', 'YearBuilt']])
7 
8 X = pd.DataFrame(X_imputed, columns=['LotFrontage', 'GrLivArea', 'YearBuilt'])
9 y = df['SalePrice']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Fit EM imputer on training set only
6 imputer = IterativeImputer()
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = Ridge()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Fit EM imputer on full dataset before train-test split""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
54,54,55.0,Imputation,Iterative & Multiple Imputation,"Expectation-Maximization (EM) 
Imputation","1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 # ‚ùå Fit EM imputer before split ‚Äî test info leaks into model
5 imputer = IterativeImputer()
6 X_imputed = imputer.fit_transform(df[['Glucose', 'BMI', 'Age']])
7 
8 X = pd.DataFrame(X_imputed, columns=['Glucose', 'BMI', 'Age'])
9 y = df['Outcome']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Train EM Imputer only on X_train
6 imputer = IterativeImputer()
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Fitting EM imputer on full dataset before splitting, leading to preprocessing leakage""},
            {""line_number"": 14, ""explanation"": ""Model is trained on data that has already been transformed (X_train), which may contain leakage from X_test""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
55,55,56.0,Imputation,Iterative & Multiple Imputation,"Expectation-Maximization (EM) 
Imputation","1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 # ‚ùå Leakage: EM Imputer trained on entire dataset
5 imputer = IterativeImputer()
6 X_imputed = imputer.fit_transform(df[['age', 'chol', 'thalach']])
7 
8 X = pd.DataFrame(X_imputed, columns=['age', 'chol', 'thalach'])
9 y = df['target']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fit EM Imputer only on training data
6 imputer = IterativeImputer()
7 X_train_imputed = imputer.fit_transform(X_train)
8 X_test_imputed = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_imputed, y_train)
12 print(model.score(X_test_imputed, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EM Imputer is trained on the entire dataset before the train-test split, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
56,56,57.0,Imputation,Iterative & Multiple Imputation,RandomSampleImputer,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']]
3 
4 # ‚ùå Imputer is fit before train-test split ‚Äî includes future (test) data in sampling
5 imputer = RandomSampleImputer(variables=['Age'])
6 df_imputed = imputer.fit_transform(df)  # <-- Leakage: test data influences imputation
7 
8 X = df_imputed[['Age', 'Fare', 'Pclass']]
9 y = df_imputed['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Age', 'Fare', 'Pclass']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Imputer is trained only on training data
6 imputer = RandomSampleImputer(variables=['Age'])
7 X_train = imputer.fit_transform(X_train)
8 X_test = imputer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Imputer is fit before train-test split, which introduces test data into the imputation process""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
57,57,58.0,Imputation,Iterative & Multiple Imputation,RandomSampleImputer,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['LotFrontage', 'GrLivArea', 'YearBuilt', 'SalePrice']]
3 
4 imputer = RandomSampleImputer(variables=['LotFrontage'])
5 df_imputed = imputer.fit_transform(df)  # ‚ùå Fitted on full data ‚Äî leakage occurs
6 
7 X = df_imputed[['LotFrontage', 'GrLivArea', 'YearBuilt']]
8 y = df_imputed['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['LotFrontage', 'GrLivArea', 'YearBuilt']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 imputer = RandomSampleImputer(variables=['LotFrontage'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)  # ‚úÖ Imputed using training distribution only
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""RandomSampleImputer is fitted on the entire dataset before splitting it into train and test sets, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
58,58,59.0,Imputation,Iterative & Multiple Imputation,RandomSampleImputer,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Age', 'Outcome']]
3 
4 imputer = RandomSampleImputer(variables=['BMI'])
5 df_imputed = imputer.fit_transform(df)  # ‚ùå Sampling from full dataset
6 
7 X = df_imputed[['Glucose', 'BMI', 'Age']]
8 y = df_imputed['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 imputer = RandomSampleImputer(variables=['BMI'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)  # ‚úÖ Safe: no test values in sampling
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""RandomSampleImputer is fit and transform on the full dataset before train-test split""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
59,59,60.0,Imputation,Iterative & Multiple Imputation,RandomSampleImputer,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'thalach', 'target']]
3 
4 imputer = RandomSampleImputer(variables=['chol'])
5 df_imputed = imputer.fit_transform(df)  # ‚ùå Fit on entire dataset ‚Äî leakage
6 
7 X = df_imputed[['age', 'chol', 'thalach']]
8 y = df_imputed['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 imputer = RandomSampleImputer(variables=['chol'])
6 X_train = imputer.fit_transform(X_train)
7 X_test = imputer.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""RandomSampleImputer is fit on the full dataset before the train-test split""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Imputation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been imputed.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
60,60,61.0,Feature Creation,Data discretization,KBinsDiscretizer,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå Apply discretization before splitting ‚Äî includes test info in bin edges
5 discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')
6 X_binned = discretizer.fit_transform(df[['Age', 'Fare']])  # <-- Leakage occurs here
7 
8 X = pd.DataFrame(X_binned, columns=['Age_binned', 'Fare_binned'])
9 y = df['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Age', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fit discretizer only on training data ‚Äî no test leakage
6 discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')
7 X_train_binned = discretizer.fit_transform(X_train)
8 X_test_binned = discretizer.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train_binned, y_train)
12 print(model.score(X_test_binned, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""KBinsDiscretizer is applied to the entire dataset before splitting it into train and test sets, which leads to preprocessing leakage as the bin edges might include information from the test set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Discretization is applied to the full dataset before train-test split, allowing test data to influence the bin edges used for training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been discretized, meaning the test data influenced the transformation.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that was influenced by the test data during discretization.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during discretization.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
61,61,62.0,Feature Creation,Data discretization,KBinsDiscretizer,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'SalePrice']]
3 
4 discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')
5 X_binned = discretizer.fit_transform(df[['GrLivArea']])  # ‚ùå Leakage
6 
7 X = pd.DataFrame(X_binned, columns=['GrLivArea_binned'])
8 y = df['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 discretizer = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')
6 X_train_binned = discretizer.fit_transform(X_train)
7 X_test_binned = discretizer.transform(X_test)  # ‚úÖ No leakage from test data
8 
9 model = Ridge()
10 model.fit(X_train_binned, y_train)
11 print(model.score(X_test_binned, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""KBinsDiscretizer is fit on the full dataset before splitting it into train and test sets, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretization is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretized.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
62,62,63.0,Feature Creation,Data discretization,KBinsDiscretizer,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Outcome']]
3 
4 discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')
5 X_binned = discretizer.fit_transform(df[['BMI']])  # ‚ùå Fit before split
6 
7 X = pd.concat([df[['Glucose']], pd.DataFrame(X_binned, columns=['BMI_binned'])], axis=1)
8 y = df['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')
6 X_train_binned = discretizer.fit_transform(X_train[['BMI']])
7 X_test_binned = discretizer.transform(X_test[['BMI']])
8 
9 X_train_final = pd.concat([X_train[['Glucose']].reset_index(drop=True),
10                            pd.DataFrame(X_train_binned, columns=['BMI_binned'])], axis=1)
11 X_test_final = pd.concat([X_test[['Glucose']].reset_index(drop=True),
12                           pd.DataFrame(X_test_binned, columns=['BMI_binned'])], axis=1)
13 
14 model = LogisticRegression()
15 model.fit(X_train_final, y_train)
16 print(model.score(X_test_final, y_test))
17 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""KBinsDiscretizer is fit on the full dataset before train-test split, causing preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretization is applied to the 'BMI' feature of the full dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the 'BMI' feature has already been discretized using the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior discretization.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during discretization.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
63,63,64.0,Feature Creation,Data discretization,KBinsDiscretizer,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'thalach', 'target']]
3 
4 discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')
5 X_binned = discretizer.fit_transform(df[['thalach']])  # ‚ùå Full data used
6 
7 X = pd.concat([df[['age']], pd.DataFrame(X_binned, columns=['thalach_binned'])], axis=1)
8 y = df['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')
6 X_train_binned = discretizer.fit_transform(X_train[['thalach']])
7 X_test_binned = discretizer.transform(X_test[['thalach']])
8 
9 X_train_final = pd.concat([X_train[['age']].reset_index(drop=True),
10                            pd.DataFrame(X_train_binned, columns=['thalach_binned'])], axis=1)
11 X_test_final = pd.concat([X_test[['age']].reset_index(drop=True),
12                           pd.DataFrame(X_test_binned, columns=['thalach_binned'])], axis=1)
13 
14 model = LogisticRegression()
15 model.fit(X_train_final, y_train)
16 print(model.score(X_test_final, y_test))
17 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""KBinsDiscretizer is applied to the full dataset before the train-test split""},
            {""line_number"": 7, ""explanation"": ""The binned data is concatenated with the original data, merging the train and test sets""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretization is applied to the full dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretized, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior discretization.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during discretization.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
64,64,65.0,Feature Creation,Data discretization,cut,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå Compute bin edges before train-test split ‚Äî includes future (test) data
5 df['Age_bin'] = pd.cut(df['Age'], bins=[0, 18, 35, 60, 100], labels=False)  # <-- Leakage
6 
7 X = df[['Age_bin', 'Fare']]
8 y = df['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['Age', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Compute bin edges using only training data
6 bins = [0, 18, 35, 60, 100]
7 X_train['Age_bin'] = pd.cut(X_train['Age'], bins=bins, labels=False)
8 X_test['Age_bin'] = pd.cut(X_test['Age'], bins=bins, labels=False)
9 
10 X_train = X_train[['Age_bin', 'Fare']]
11 X_test = X_test[['Age_bin', 'Fare']]
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Age bins are computed based on the full dataset, including future (test) data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""The binning of 'Age' is performed on the entire dataset before the train-test split, allowing information from the test set to influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior binning.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the binning performed before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
65,65,66.0,Feature Creation,Data discretization,cut,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Bins determined from full dataset
5 df['GrLivArea_bin'] = pd.cut(df['GrLivArea'], bins=4, labels=False)  # <-- Leakage
6 
7 X = df[['GrLivArea_bin']]
8 y = df['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Determine bin edges from training data only
6 bins = pd.cut(X_train['GrLivArea'], bins=4, retbins=True)[1]  # get bin edges only
7 X_train['GrLivArea_bin'] = pd.cut(X_train['GrLivArea'], bins=bins, labels=False, include_lowest=True)
8 X_test['GrLivArea_bin'] = pd.cut(X_test['GrLivArea'], bins=bins, labels=False, include_lowest=True)
9 
10 model = Ridge()
11 model.fit(X_train[['GrLivArea_bin']], y_train)
12 print(model.score(X_test[['GrLivArea_bin']], y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Bins determined from full dataset, causing preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""The binning of 'GrLivArea' is performed on the entire dataset before the train-test split, causing the test data to influence the binning process.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the binning process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the binning process.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
66,66,67.0,Feature Creation,Data discretization,cut,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Outcome']]
3 
4 # ‚ùå Apply pd.cut on full data
5 df['BMI_bin'] = pd.cut(df['BMI'], bins=5, labels=False)
6 
7 X = df[['Glucose', 'BMI_bin']]
8 y = df['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Compute bin edges using only training data
6 bins = pd.cut(X_train['BMI'], bins=5, retbins=True)[1]
7 X_train['BMI_bin'] = pd.cut(X_train['BMI'], bins=bins, labels=False, include_lowest=True)
8 X_test['BMI_bin'] = pd.cut(X_test['BMI'], bins=bins, labels=False, include_lowest=True)
9 
10 X_train = X_train[['Glucose', 'BMI_bin']]
11 X_test = X_test[['Glucose', 'BMI_bin']]
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 5, ""explanation"": ""BMI_bin labels are computed on the full dataset before splitting it into train and test sets.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering using pd.cut is applied to the full dataset before train-test split, allowing test data distribution to influence the training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior feature engineering.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the feature engineering applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
67,67,68.0,Feature Creation,Data discretization,cut,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['chol', 'age', 'target']]
3 
4 df['chol_bin'] = pd.cut(df['chol'], bins=3, labels=False)  # ‚ùå Fit before split
5 
6 X = df[['age', 'chol_bin']]
7 y = df['target']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['chol', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 bins = pd.cut(X_train['chol'], bins=3, retbins=True)[1]
6 X_train['chol_bin'] = pd.cut(X_train['chol'], bins=bins, labels=False, include_lowest=True)
7 X_test['chol_bin'] = pd.cut(X_test['chol'], bins=bins, labels=False, include_lowest=True)
8 
9 X_train = X_train[['age', 'chol_bin']]
10 X_test = X_test[['age', 'chol_bin']]
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Fit the bins of chol_bin on the entire dataset before splitting it into train and test sets""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""The binning of 'chol' into 'chol_bin' is performed on the entire dataset before the train-test split, causing data leakage as the binning thresholds are influenced by the test data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior binning.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the binning process applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
68,68,69.0,Feature Creation,Data discretization,qcut,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå Bin edges computed on full dataset ‚Äî includes future test data
5 df['Age_bin'] = pd.qcut(df['Age'], q=4, labels=False)  # <-- Leakage: test info used
6 
7 X = df[['Age_bin', 'Fare']]
8 y = df['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 import pandas as pd
2 from sklearn.model_selection import train_test_split
3 from sklearn.linear_model import LogisticRegression
4 
5 df = pd.read_csv(""titanic.csv"")
6 df = df[['Age', 'Fare', 'Survived']].dropna()
7 
8 # ‚ùå Bin edges computed on full dataset ‚Äî includes future test data
9 df['Age_bin'] = pd.qcut(df['Age'], q=4, labels=False)  # <-- Leakage: test info used
10 
11 X = df[['Age_bin', 'Fare']]
12 y = df['Survived']
13 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
14 
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Bin edges for Age are computed on the entire dataset, including test data, which can lead to information leakage as the test data's Age bins may be influenced by the training data's Age distribution.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""The binning of 'Age' into 'Age_bin' is performed on the entire dataset before the train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior binning.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the binning performed on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
69,69,70.0,Feature Creation,Data discretization,qcut,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Full dataset used to define quantile bins
5 df['GrLivArea_bin'] = pd.qcut(df['GrLivArea'], q=5, labels=False)
6 
7 X = df[['GrLivArea_bin']]
8 y = df['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 _, bin_edges = pd.qcut(X_train['GrLivArea'], q=5, retbins=True, duplicates='drop')
6 X_train['GrLivArea_bin'] = pd.cut(X_train['GrLivArea'], bins=bin_edges, labels=False, include_lowest=True)
7 X_test['GrLivArea_bin'] = pd.cut(X_test['GrLivArea'], bins=bin_edges, labels=False, include_lowest=True)
8 
9 model = Ridge()
10 model.fit(X_train[['GrLivArea_bin']], y_train)
11 print(model.score(X_test[['GrLivArea_bin']], y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Quantile bins are defined based on the full dataset, not the split one, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Quantile binning is applied to the full dataset before train-test split, allowing test data distribution to influence the binning applied to training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through the quantile binning.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been influenced by the training data through the quantile binning.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
70,70,71.0,Feature Creation,Data discretization,qcut,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['BMI', 'Glucose', 'Outcome']]
3 
4 # ‚ùå Uses entire dataset to determine quantiles
5 df['BMI_bin'] = pd.qcut(df['BMI'], q=3, labels=False)
6 
7 X = df[['Glucose', 'BMI_bin']]
8 y = df['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['BMI', 'Glucose']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 _, bin_edges = pd.qcut(X_train['BMI'], q=3, retbins=True, duplicates='drop')
6 X_train['BMI_bin'] = pd.cut(X_train['BMI'], bins=bin_edges, labels=False, include_lowest=True)
7 X_test['BMI_bin'] = pd.cut(X_test['BMI'], bins=bin_edges, labels=False, include_lowest=True)
8 
9 X_train = X_train[['Glucose', 'BMI_bin']]
10 X_test = X_test[['Glucose', 'BMI_bin']]
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""BMI_bin is determined based on the entire dataset, not just the train set. This can lead to leakage if the test set values of BMI are used during preprocessing.""},
            {""line_number"": 9, ""explanation"": ""Although the train_test_split function is used, it is not clear if the indices are properly shuffled before splitting. This can potentially lead to overlap leakage, as the same indices for train and test sets may be present.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""The qcut transformation is applied to the entire dataset before the train-test split, causing the test data to influence the binning of the BMI feature.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the BMI feature has already been binned using the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the BMI binning process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the BMI binning process.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
71,71,72.0,Feature Creation,Data discretization,qcut,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['chol', 'age', 'target']]
3 
4 df['chol_bin'] = pd.qcut(df['chol'], q=4, labels=False)  # ‚ùå Quantiles calculated with full data
5 
6 X = df[['chol_bin', 'age']]
7 y = df['target']
8 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['chol', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 _, bin_edges = pd.qcut(X_train['chol'], q=4, retbins=True, duplicates='drop')
6 X_train['chol_bin'] = pd.cut(X_train['chol'], bins=bin_edges, labels=False, include_lowest=True)
7 X_test['chol_bin'] = pd.cut(X_test['chol'], bins=bin_edges, labels=False, include_lowest=True)
8 
9 X_train = X_train[['chol_bin', 'age']]
10 X_test = X_test[['chol_bin', 'age']]
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""Quantiles are calculated based on the full dataset, not the train or test sets. This can lead to preprocessing leakage if the quantiles depend on the target variable.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 4,
      ""explanation"": ""Quantile binning is applied to the full dataset before train-test split, allowing test data distribution to influence the binning applied to training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been binned using information from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been binned using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
72,72,73.0,Feature Creation,Data discretization,EqualFrequencyDiscretiser,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 # ‚ùå Discretiser is fit on full dataset (includes future test data)
5 discretiser = EqualFrequencyDiscretiser(q=4, variables=['Fare'])
6 df_discretised = discretiser.fit_transform(df)  # <-- Leakage
7 
8 X = df_discretised[['Fare', 'Age']]
9 y = df_discretised['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Discretiser is fit only on training data ‚Äî test data untouched during fitting
6 discretiser = EqualFrequencyDiscretiser(q=4, variables=['Fare'])
7 X_train = discretiser.fit_transform(X_train)
8 X_test = discretiser.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EqualFrequencyDiscretiser is fit on the entire dataset, including future test data, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been discretised.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
73,73,74.0,Feature Creation,Data discretization,EqualFrequencyDiscretiser,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'SalePrice']]
3 
4 discretiser = EqualFrequencyDiscretiser(q=5, variables=['GrLivArea'])
5 df_discretised = discretiser.fit_transform(df)  # ‚ùå Fit on entire data
6 
7 X = df_discretised[['GrLivArea']]
8 y = df_discretised['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 discretiser = EqualFrequencyDiscretiser(q=5, variables=['GrLivArea'])
6 X_train = discretiser.fit_transform(X_train)
7 X_test = discretiser.transform(X_test)  # ‚úÖ Applied after training-only fitting
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EqualFrequencyDiscretiser is fit on the entire dataset before splitting it into train and test sets, causing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretised, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior discretisation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during discretisation.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
74,74,75.0,Feature Creation,Data discretization,EqualFrequencyDiscretiser,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['BMI', 'Age', 'Outcome']]
3 
4 discretiser = EqualFrequencyDiscretiser(q=3, variables=['BMI'])
5 df_discretised = discretiser.fit_transform(df)  # ‚ùå Leakage: test data affected bin edges
6 
7 X = df_discretised[['BMI', 'Age']]
8 y = df_discretised['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['BMI', 'Age']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 discretiser = EqualFrequencyDiscretiser(q=3, variables=['BMI'])
6 X_train = discretiser.fit_transform(X_train)
7 X_test = discretiser.transform(X_test)  # ‚úÖ Uses training bin edges
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EqualFrequencyDiscretiser fit_transform is applied to the entire dataset, affecting bin edges for test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data to influence the bin edges used for training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretised, meaning the test data influenced the transformation.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that was affected by the test data during discretisation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used to determine the discretisation bin edges.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
75,75,76.0,Feature Creation,Data discretization,EqualFrequencyDiscretiser,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['chol', 'thalach', 'target']]
3 
4 discretiser = EqualFrequencyDiscretiser(q=4, variables=['chol'])
5 df_discretised = discretiser.fit_transform(df)  # ‚ùå Full data used ‚Äî causes leakage
6 
7 X = df_discretised[['chol', 'thalach']]
8 y = df_discretised['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretiser = EqualFrequencyDiscretiser(q=4, variables=['chol'])
6 X_train = discretiser.fit_transform(X_train)
7 X_test = discretiser.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Discretiser is fit on the entire dataset before splitting it into train and test sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretised.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
76,76,77.0,Feature Creation,Data discretization,EqualWidthDiscretiser,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 # ‚ùå Fit discretiser on full dataset ‚Äî test set influences bin boundaries
5 discretiser = EqualWidthDiscretiser(bins=3, variables=['Fare'])
6 df_transformed = discretiser.fit_transform(df)  # <-- Leakage
7 
8 X = df_transformed[['Fare', 'Age']]
9 y = df_transformed['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fit discretiser on training data only
6 discretiser = EqualWidthDiscretiser(bins=3, variables=['Fare'])
7 X_train = discretiser.fit_transform(X_train)
8 X_test = discretiser.transform(X_test)  # Uses same bin edges
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Discretiser is fit on the entire dataset, including the test set, influencing the bin boundaries and leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data to influence the bin boundaries.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been discretised, using bin boundaries influenced by the test data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data with bin boundaries influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data with bin boundaries influenced by the test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
77,77,78.0,Feature Creation,Data discretization,EqualWidthDiscretiser,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'SalePrice']]
3 
4 discretiser = EqualWidthDiscretiser(bins=4, variables=['GrLivArea'])
5 df_transformed = discretiser.fit_transform(df)  # ‚ùå Fit on entire dataset
6 
7 X = df_transformed[['GrLivArea']]
8 y = df_transformed['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretiser = EqualWidthDiscretiser(bins=4, variables=['GrLivArea'])
6 X_train = discretiser.fit_transform(X_train)
7 X_test = discretiser.transform(X_test)  # ‚úÖ Transformed using training bin edges
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EqualWidthDiscretiser fit on entire dataset before splitting""},
            {""line_number"": 9, ""explanation"": ""train_test_split not applied to the transformed data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretised.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
78,78,79.0,Feature Creation,Data discretization,EqualWidthDiscretiser,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['BMI', 'Glucose', 'Outcome']]
3 
4 discretiser = EqualWidthDiscretiser(bins=5, variables=['BMI'])
5 df_transformed = discretiser.fit_transform(df)  # ‚ùå Leakage: test data influences bins
6 
7 X = df_transformed[['BMI', 'Glucose']]
8 y = df_transformed['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['BMI', 'Glucose']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 discretiser = EqualWidthDiscretiser(bins=5, variables=['BMI'])
6 X_train = discretiser.fit_transform(X_train)
7 X_test = discretiser.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EqualWidthDiscretiser is fit on the full dataset, influencing bin boundaries for test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data to influence the binning process.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretised, leading to leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
79,79,80.0,Feature Creation,Data discretization,EqualWidthDiscretiser,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['age', 'chol', 'target']]
3 
4 discretiser = EqualWidthDiscretiser(bins=3, variables=['chol'])
5 df_transformed = discretiser.fit_transform(df)  # ‚ùå Leakage from full dataset
6 
7 X = df_transformed[['age', 'chol']]
8 y = df_transformed['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['age', 'chol']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretiser = EqualWidthDiscretiser(bins=3, variables=['chol'])
6 X_train = discretiser.fit_transform(X_train)
7 X_test = discretiser.transform(X_test)  # ‚úÖ No leakage
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""EqualWidthDiscretiser is applied to the full dataset before splitting it into train and test sets""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been discretised.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
80,80,81.0,Feature Creation,Data discretization,DecisionTreeDiscretiser,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 # ‚ùå Fit Discretiser before splitting ‚Äî bins use knowledge from test set
5 discretiser = DecisionTreeDiscretiser(cv=3, variables=['Fare'], scoring='accuracy')
6 df_binned = discretiser.fit_transform(df, df['Survived'])  # <-- Leakage happens here
7 
8 X = df_binned[['Fare', 'Age']]
9 y = df_binned['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fit Discretiser ONLY on training data
6 discretiser = DecisionTreeDiscretiser(cv=3, variables=['Fare'], scoring='accuracy')
7 X_train = discretiser.fit_transform(X_train, y_train)
8 X_test = discretiser.transform(X_test)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""DecisionTreeDiscretiser is fit on the entire dataset, including test set, and it uses this information to determine bin edges.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been discretised, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been influenced by the training data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
81,81,82.0,Feature Creation,Data discretization,DecisionTreeDiscretiser,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'SalePrice']]
3 
4 # ‚ùå Fit on full data (target included), so test leakage occurs
5 discretiser = DecisionTreeDiscretiser(cv=3, variables=['GrLivArea'])
6 df_binned = discretiser.fit_transform(df, df['SalePrice'])
7 
8 X = df_binned[['GrLivArea']]
9 y = df_binned['SalePrice']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['GrLivArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretiser = DecisionTreeDiscretiser(cv=3, variables=['GrLivArea'])
6 X_train = discretiser.fit_transform(X_train, y_train)
7 X_test = discretiser.transform(X_test)
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Fitting DecisionTreeDiscretiser on full dataset before split""},
            {""line_number"": 14, ""explanation"": ""Model is trained on data that has already been transformed""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Discretisation is applied to the full dataset including the target variable before train-test split, causing test data information to leak into the training process.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the data has already been discretised with information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the discretisation step.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the discretisation step.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
82,82,83.0,Feature Creation,Data discretization,DecisionTreeDiscretiser,"1 df = pd.read_csv(""diabetes.csv"")
2 df = df[['Glucose', 'BMI', 'Outcome']]
3 
4 discretiser = DecisionTreeDiscretiser(cv=2, variables=['BMI'])
5 df_binned = discretiser.fit_transform(df, df['Outcome'])  # ‚ùå Fit includes future info
6 
7 X = df_binned[['Glucose', 'BMI']]
8 y = df_binned['Outcome']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 discretiser = DecisionTreeDiscretiser(cv=2, variables=['BMI'])
6 X_train = discretiser.fit_transform(X_train, y_train)
7 X_test = discretiser.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""DecisionTreeDiscretiser is fit on the entire dataset, including the test set, which is a form of overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""The discretiser is fit on the entire dataset, including the test data, which allows information from the test set to influence the transformation applied to the training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the discretiser.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the discretiser.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
83,83,84.0,Feature Creation,Data discretization,DecisionTreeDiscretiser,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['chol', 'thalach', 'target']]
3 
4 # ‚ùå Fit on entire dataset ‚Äî bins incorporate test knowledge
5 discretiser = DecisionTreeDiscretiser(cv=3, variables=['chol'])
6 df_binned = discretiser.fit_transform(df, df['target'])
7 
8 X = df_binned[['chol', 'thalach']]
9 y = df_binned['target']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 discretiser = DecisionTreeDiscretiser(cv=3, variables=['chol'])
6 X_train = discretiser.fit_transform(X_train, y_train)
7 X_test = discretiser.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""DecisionTreeDiscretiser fit on entire dataset before splitting""},
            {""line_number"": 14, ""explanation"": ""Model is trained on data that has already been transformed""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Discretisation is applied to the full dataset before train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been discretised, leading to data leakage.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
84,84,85.0,Feature Creation,Dimensionality Reduction,LDA,"1 # Load data
2 iris = load_iris()
3 X, y = iris.data, iris.target
4 
5 # ‚ùå LDA fit on the entire dataset (includes test labels!)
6 lda = LinearDiscriminantAnalysis(n_components=2)
7 X_lda = lda.fit_transform(X, y)  # <-- Leakage
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.3)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 # ‚úÖ Fit LDA ONLY on training data
4 lda = LinearDiscriminantAnalysis(n_components=2)
5 X_train_lda = lda.fit_transform(X_train, y_train)
6 X_test_lda = lda.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_lda, y_train)
10 print(model.score(X_test_lda, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""Fit LinearDiscriminantAnalysis on the entire dataset, including test labels, and transform it.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""LDA is fit on the entire dataset before the train-test split, allowing test data to influence the transformation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after LDA transformation, which was fit on the entire dataset, contaminating both train and test sets.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior LDA transformation.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data through the LDA transformation.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
85,85,86.0,Feature Creation,Dimensionality Reduction,LDA,"1 df = pd.read_csv('winequality-red.csv', sep=';')
2 X = df.drop('quality', axis=1)
3 y = df['quality']
4 
5 # ‚ùå Leakage: LDA uses full dataset (and all labels) before split
6 lda = LinearDiscriminantAnalysis(n_components=2)
7 X_lda = lda.fit_transform(X, y)
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.2)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 # ‚úÖ Fit LDA only on training set
4 lda = LinearDiscriminantAnalysis(n_components=2)
5 X_train_lda = lda.fit_transform(X_train, y_train)
6 X_test_lda = lda.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_lda, y_train)
10 print(model.score(X_test_lda, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""LinearDiscriminantAnalysis uses full dataset (and all labels) before split""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""LDA transformation is applied to the full dataset before train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after LDA transformation, which was fit on the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been transformed using information from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been transformed using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
86,86,87.0,Feature Creation,Dimensionality Reduction,LDA,"1 df = pd.read_csv('heart.csv')
2 X = df.drop('target', axis=1)
3 y = df['target']
4 
5 lda = LinearDiscriminantAnalysis(n_components=1)
6 X_lda = lda.fit_transform(X, y)  # ‚ùå Fit on full data
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df.drop('target', axis=1)
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 lda = LinearDiscriminantAnalysis(n_components=1)
6 X_train_lda = lda.fit_transform(X_train, y_train)
7 X_test_lda = lda.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_lda, y_train)
11 print(model.score(X_test_lda, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Fitting LinearDiscriminantAnalysis model on full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Linear Discriminant Analysis is fitted on the entire dataset before the train-test split, causing data leakage as the transformation is influenced by the test data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after the LDA transformation, which was fitted on the full dataset, leading to leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the LDA transformation fitted on the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the LDA transformation fitted on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
87,87,88.0,Feature Creation,Dimensionality Reduction,LDA,"1 df = pd.read_csv('StudentsPerformance.csv')
2 df = df[['math score', 'reading score', 'writing score']]
3 df['passed'] = (df['math score'] > 50).astype(int)  # Simplified target
4 
5 X = df[['reading score', 'writing score']]
6 y = df['passed']
7 
8 # ‚ùå LDA includes label info from test set
9 lda = LinearDiscriminantAnalysis(n_components=1)
10 X_lda = lda.fit_transform(X, y)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_lda, y, test_size=0.3)
13 
14 from sklearn.linear_model import LogisticRegression
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['reading score', 'writing score']]
2 y = df['passed']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lda = LinearDiscriminantAnalysis(n_components=1)
6 X_train_lda = lda.fit_transform(X_train, y_train)
7 X_test_lda = lda.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_lda, y_train)
11 print(model.score(X_test_lda, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Label information is included in the LDA model training, which is a form of overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""LDA is applied to the entire dataset before the train-test split, using label information from the test set, which causes data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after LDA transformation, which has already been contaminated with test data information.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to improper LDA application.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to an overestimation of model performance.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
88,88,89.0,Feature Creation,Dimensionality Reduction,PCA,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Age', 'Fare', 'Pclass', 'Survived']].dropna()
3 
4 X = df[['Age', 'Fare', 'Pclass']]
5 y = df['Survived']
6 
7 # ‚ùå PCA is applied to the full dataset before splitting ‚Äî includes future test data
8 pca = PCA(n_components=2)
9 X_pca = pca.fit_transform(X)  # <-- Leakage: test data influenced PCA components
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 # ‚úÖ PCA fit only on training data
4 pca = PCA(n_components=2)
5 X_train_pca = pca.fit_transform(X_train)
6 X_test_pca = pca.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_pca, y_train)
10 print(model.score(X_test_pca, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""PCA is applied to the full dataset before splitting ‚Äî includes future test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""PCA is applied to the full dataset before train-test split, allowing test data to influence the PCA components.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after PCA transformation, which was influenced by the entire dataset including test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes test data influence from PCA.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by PCA applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
89,89,90.0,Feature Creation,Dimensionality Reduction,PCA,"1 df = pd.read_csv(""house_prices.csv"")
2 features = ['LotArea', 'GrLivArea', 'YearBuilt', 'GarageArea']
3 df = df[features + ['SalePrice']].dropna()
4 
5 X = df[features]
6 y = df['SalePrice']
7 
8 # ‚ùå PCA fit before splitting, so test data influenced the transformation
9 pca = PCA(n_components=2)
10 X_pca = pca.fit_transform(X)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.25)
13 
14 from sklearn.linear_model import Ridge
15 model = Ridge()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 # ‚úÖ Fit PCA only on training data to avoid leakage
4 pca = PCA(n_components=2)
5 X_train_pca = pca.fit_transform(X_train)
6 X_test_pca = pca.transform(X_test)
7 
8 model = Ridge()
9 model.fit(X_train_pca, y_train)
10 print(model.score(X_test_pca, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""PCA fit applied to the entire dataset before splitting, causing test data to be influenced by the train data transformation.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""PCA is fit on the entire dataset before the train-test split, allowing test data to influence the transformation.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after PCA transformation, which was influenced by the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that has been transformed using PCA fit on the entire dataset.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been transformed using PCA fit on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
90,90,91.0,Feature Creation,Dimensionality Reduction,PCA,"1 df = pd.read_csv(""heart.csv"")
2 features = ['age', 'trestbps', 'chol', 'thalach']
3 X = df[features]
4 y = df['target']
5 
6 # ‚ùå PCA is applied to the whole dataset before split
7 pca = PCA(n_components=2)
8 X_pca = pca.fit_transform(X)  # <-- Leakage: future test info used
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 # ‚úÖ PCA fit only on training data
4 pca = PCA(n_components=2)
5 X_train_pca = pca.fit_transform(X_train)
6 X_test_pca = pca.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_pca, y_train)
10 print(model.score(X_test_pca, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""PCA is applied to the whole dataset before split, future test info used""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""PCA is applied to the entire dataset before the train-test split, allowing test data to influence the transformation.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after PCA transformation, which was fitted on the entire dataset, contaminating the training and test sets.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior PCA transformation.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data through the PCA transformation.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
91,91,92.0,Feature Creation,Dimensionality Reduction,PCA,"1 # Load dataset
2 df = pd.read_csv(""diabetes.csv"")
3 features = ['Pregnancies', 'Glucose', 'BloodPressure', 'BMI', 'Age']
4 X = df[features]
5 y = df['Outcome']
6 
7 # ‚ùå PCA is fit on the entire dataset ‚Äî includes test data
8 pca = PCA(n_components=2)
9 X_pca = pca.fit_transform(X)  # <-- Leakage: future test data influences transformation
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 # Split first
2 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
3 
4 # ‚úÖ Fit PCA only on training data
5 pca = PCA(n_components=2)
6 X_train_pca = pca.fit_transform(X_train)
7 X_test_pca = pca.transform(X_test)  # ‚úÖ No leakage from test data
8 
9 model = LogisticRegression()
10 model.fit(X_train_pca, y_train)
11 print(model.score(X_test_pca, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""PCA is fit on the entire dataset, including test data, causing future test data to influence the transformation""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""PCA is fit on the entire dataset before train-test split, allowing test data to influence the transformation.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after PCA transformation, which was influenced by the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to PCA leakage.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the PCA transformation applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
92,92,93.0,Feature Creation,Text Vectorization,CountVectorizer,"1 df = pd.read_csv(""fake_or_real_news.csv"")
2 X = df['text']
3 y = df['label'].map({'FAKE': 1, 'REAL': 0})
4 
5 # ‚ùå Vocabulary is learned from entire dataset ‚Äî includes test-set vocabulary
6 vectorizer = CountVectorizer()
7 X_vectorized = vectorizer.fit_transform(X)  # <-- Leakage occurs here
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.25)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 # ‚úÖ Vocabulary is learned only from training set
4 vectorizer = CountVectorizer()
5 X_train_vec = vectorizer.fit_transform(X_train)
6 X_test_vec = vectorizer.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_vec, y_train)
10 print(model.score(X_test_vec, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""CountVectorizer is fit on the entire dataset, including test data, which leads to a shared vocabulary between train and test sets, resulting in overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""The CountVectorizer is fit on the entire dataset before the train-test split, allowing test data vocabulary to influence the training process.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the vectorization has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
93,93,94.0,Feature Creation,Text Vectorization,CountVectorizer,"1 df = pd.read_csv(""SMSSpamCollection"", sep='\t', names=['label', 'message'])
2 X = df['message']
3 y = df['label'].map({'spam': 1, 'ham': 0})
4 
5 vectorizer = CountVectorizer()
6 X_vectorized = vectorizer.fit_transform(X)  # ‚ùå Vocabulary includes test-set leakage
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2)
9 
10 from sklearn.naive_bayes import MultinomialNB
11 model = MultinomialNB()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 vectorizer = CountVectorizer()
4 X_train_vec = vectorizer.fit_transform(X_train)
5 X_test_vec = vectorizer.transform(X_test)
6 
7 model = MultinomialNB()
8 model.fit(X_train_vec, y_train)
9 print(model.score(X_test_vec, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""CountVectorizer is fit on the entire dataset, including test data, creating a vocabulary that includes test-set words, leading to overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""The CountVectorizer is fit on the entire dataset before the train-test split, causing the vocabulary to include information from the test set, leading to data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the training data that has been contaminated by test data information due to the vectorization leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by training data information due to the vectorization leakage.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
94,94,95.0,Feature Creation,Text Vectorization,CountVectorizer,"1 
2 # IMDb dataset loaded from local folder
3 reviews = load_files(""aclImdb/train/"", categories=['pos', 'neg'], encoding=""utf-8"")
4 X = reviews.data
5 y = reviews.target
6 
7 vectorizer = CountVectorizer()
8 X_vectorized = vectorizer.fit_transform(X)  # ‚ùå Leakage: test review vocabulary influences vectorizer
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.3)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 vectorizer = CountVectorizer()
4 X_train = vectorizer.fit_transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = LogisticRegression()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""CountVectorizer is fit on the full dataset, including test data, which results in shared vocabulary and leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""The CountVectorizer is fit on the entire dataset before the train-test split, allowing the test data vocabulary to influence the vectorizer.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the vectorizer has already been fit on the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training process due to prior leakage.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
95,95,96.0,Feature Creation,Text Vectorization,CountVectorizer,"1 df = pd.read_csv(""netflix_titles.csv"")
2 df = df.dropna(subset=['description', 'type'])
3 
4 X = df['description']
5 y = df['type'].map({'Movie': 0, 'TV Show': 1})
6 
7 vectorizer = CountVectorizer()
8 X_vectorized = vectorizer.fit_transform(X)  # ‚ùå Includes vocabulary from entire dataset
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.25)
11 
12 from sklearn.tree import DecisionTreeClassifier
13 model = DecisionTreeClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 vectorizer = CountVectorizer()
4 X_train = vectorizer.fit_transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""CountVectorizer is applied to the entire dataset before splitting, including the test set, leading to preprocessing leakage as it generates the vocabulary from the entire dataset.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""The CountVectorizer is fit on the entire dataset before the train-test split, allowing the test data's vocabulary to influence the training process.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the vectorization, which has already been influenced by the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
96,96,97.0,Feature Creation,Text Vectorization,HashingVectorizer,"1 df = pd.read_csv(""fake_or_real_news.csv"")
2 X = df['text']
3 y = df['label'].map({'FAKE': 1, 'REAL': 0})
4 
5 # ‚ùå Vectorize all text before split ‚Äî this includes test data content
6 vectorizer = HashingVectorizer(n_features=1000, alternate_sign=False)
7 X_vectorized = vectorizer.transform(X)  # <-- vectorized on full dataset (leakage)
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 # ‚úÖ Vectorize after splitting ‚Äî no test data is seen during transformation
4 vectorizer = HashingVectorizer(n_features=1000, alternate_sign=False)
5 X_train = vectorizer.transform(X_train_raw)
6 X_test = vectorizer.transform(X_test_raw)
7 
8 model = LogisticRegression()
9 model.fit(X_train, y_train)
10 print(model.score(X_test, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Vectorizer is applied to the full dataset before splitting it into train and test sets, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Vectorization is applied to the full dataset before train-test split, allowing test data features to influence the training process.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been vectorized, meaning the test data has influenced the feature extraction process.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior vectorization.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in the vectorization process.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
97,97,98.0,Feature Creation,Text Vectorization,HashingVectorizer,"1 df = pd.read_csv(""SMSSpamCollection"", sep='\t', names=[""label"", ""message""])
2 X = df['message']
3 y = df['label'].map({'spam': 1, 'ham': 0})
4 
5 vectorizer = HashingVectorizer(n_features=512, alternate_sign=False)
6 X_vectorized = vectorizer.transform(X)  # ‚ùå All messages vectorized before split
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.3)
9 
10 from sklearn.naive_bayes import MultinomialNB
11 model = MultinomialNB()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 vectorizer = HashingVectorizer(n_features=512, alternate_sign=False)
4 X_train = vectorizer.transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = MultinomialNB()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""All messages are vectorized before the train-test split, leading to overlap leakage as the same features are used for both training and testing data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Vectorization is applied to the full dataset before train-test split, allowing information from the test set to influence the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been vectorized, leading to data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, which has been influenced by the training data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
98,98,99.0,Feature Creation,Text Vectorization,HashingVectorizer,"1 df = pd.read_csv(""netflix_titles.csv"")
2 df = df.dropna(subset=[""description"", ""type""])
3 X = df[""description""]
4 y = df[""type""].map({""Movie"": 0, ""TV Show"": 1})
5 
6 vectorizer = HashingVectorizer(n_features=2048, alternate_sign=False)
7 X_vectorized = vectorizer.transform(X)  # ‚ùå Leakage: test descriptions seen before split
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.25)
10 
11 from sklearn.tree import DecisionTreeClassifier
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 vectorizer = HashingVectorizer(n_features=2048, alternate_sign=False)
4 X_train = vectorizer.transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""Vectorizer is applied to the entire dataset before splitting into train and test sets, resulting in overlap leakage as the test descriptions are seen during training.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""The HashingVectorizer is applied to the entire dataset before the train-test split, allowing information from the test set to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the data has already been vectorized, meaning the test data has influenced the transformation.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been influenced by the training data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
99,99,100.0,Feature Creation,Text Vectorization,HashingVectorizer,"1 reviews = load_files(""aclImdb/train/"", categories=[""pos"", ""neg""], encoding=""utf-8"")
2 X = reviews.data
3 y = reviews.target
4 
5 vectorizer = HashingVectorizer(n_features=1000, alternate_sign=False)
6 X_vectorized = vectorizer.transform(X)  # ‚ùå All review data included pre-split
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 vectorizer = HashingVectorizer(n_features=1000, alternate_sign=False)
4 X_train = vectorizer.transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = LogisticRegression()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Vectorizer is applied to the full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Vectorization is applied to the full dataset before train-test split, allowing test data characteristics to influence the training process.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been vectorized, which means the test data has influenced the vectorization process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to pre-split vectorization.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the pre-split vectorization.""
    }
  ]
}
","[Training method: fit, Training line: 11]  
[Testing method: score, Testing line: 12]"
100,100,101.0,Feature Creation,Text Vectorization,TfidfTransformer,"1 df = pd.read_csv(""fake_or_real_news.csv"")
2 X = df['text']
3 y = df['label'].map({'FAKE': 1, 'REAL': 0})
4 
5 # ‚ùå Vectorize full data first
6 vectorizer = CountVectorizer()
7 X_counts = vectorizer.fit_transform(X)
8 
9 tfidf = TfidfTransformer()
10 X_tfidf = tfidf.fit_transform(X_counts)  # <-- Leakage: includes test info in IDF
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3)
13 
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 vectorizer = CountVectorizer()
4 X_train_counts = vectorizer.fit_transform(X_train_raw)
5 X_test_counts = vectorizer.transform(X_test_raw)
6 
7 # ‚úÖ Fit TF-IDF only on training counts
8 tfidf = TfidfTransformer()
9 X_train_tfidf = tfidf.fit_transform(X_train_counts)
10 X_test_tfidf = tfidf.transform(X_test_counts)
11 
12 model = LogisticRegression()
13 model.fit(X_train_tfidf, y_train)
14 print(model.score(X_test_tfidf, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""TF-IDF transformation is applied to the full dataset before splitting it into train and test sets, leading to overlap leakage as test data is included in the IDF calculation.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""CountVectorizer is fit on the entire dataset before the train-test split, allowing test data to influence the vectorization.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""TfidfTransformer is fit on the entire dataset before the train-test split, allowing test data to influence the IDF calculation.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the data has already been vectorized and transformed with TF-IDF, contaminating the training and test sets.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
101,101,102.0,Feature Creation,Text Vectorization,TfidfTransformer,"1 df = pd.read_csv(""SMSSpamCollection"", sep='\t', names=['label', 'message'])
2 X = df['message']
3 y = df['label'].map({'spam': 1, 'ham': 0})
4 
5 vec = CountVectorizer()
6 X_counts = vec.fit_transform(X)
7 
8 tfidf = TfidfTransformer()
9 X_tfidf = tfidf.fit_transform(X_counts)  # ‚ùå IDF includes test messages
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2)
12 
13 from sklearn.naive_bayes import MultinomialNB
14 model = MultinomialNB()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 vec = CountVectorizer()
4 X_train_counts = vec.fit_transform(X_train_raw)
5 X_test_counts = vec.transform(X_test_raw)
6 
7 tfidf = TfidfTransformer()
8 X_train_tfidf = tfidf.fit_transform(X_train_counts)
9 X_test_tfidf = tfidf.transform(X_test_counts)
10 
11 model = MultinomialNB()
12 model.fit(X_train_tfidf, y_train)
13 print(model.score(X_test_tfidf, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""IDF transformation is applied to the full dataset, including test data, which results in overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""TF-IDF transformation is applied to the entire dataset before the train-test split, allowing test data to influence the IDF values used during training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the TF-IDF transformation, meaning the test data has already influenced the feature extraction process.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to the prior TF-IDF transformation.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in the TF-IDF transformation, leading to data leakage.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
102,102,103.0,Feature Creation,Text Vectorization,TfidfTransformer,"1 eviews = load_files(""aclImdb/train/"", categories=['pos', 'neg'], encoding='utf-8')
2 X = reviews.data
3 y = reviews.target
4 
5 count_vect = CountVectorizer()
6 X_counts = count_vect.fit_transform(X)
7 
8 tfidf = TfidfTransformer()
9 X_tfidf = tfidf.fit_transform(X_counts)  # ‚ùå Leakage: TF-IDF includes test terms
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2)
13 
14 from sklearn.linear_model import LogisticRegression
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 
19 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 count_vect = CountVectorizer()
4 X_train_counts = count_vect.fit_transform(X_train_raw)
5 X_test_counts = count_vect.transform(X_test_raw)
6 
7 tfidf = TfidfTransformer()
8 X_train_tfidf = tfidf.fit_transform(X_train_counts)
9 X_test_tfidf = tfidf.transform(X_test_counts)
10 
11 model = LogisticRegression()
12 model.fit(X_train_tfidf, y_train)
13 print(model.score(X_test_tfidf, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""TF-IDF transformation is applied to the full dataset before splitting it into train and test sets, causing overlap leakage by including test terms in the transformation""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""TF-IDF transformation is applied to the entire dataset before the train-test split, allowing information from the test set to influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the TF-IDF transformation, meaning the test data has already influenced the feature extraction process.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to prior TF-IDF transformation.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during the TF-IDF transformation.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
103,103,104.0,Feature Creation,Text Vectorization,TfidfTransformer,"1 df = pd.read_csv(""netflix_titles.csv"")
2 df = df.dropna(subset=[""description"", ""type""])
3 X = df[""description""]
4 y = df[""type""].map({""Movie"": 0, ""TV Show"": 1})
5 
6 count_vect = CountVectorizer()
7 X_counts = count_vect.fit_transform(X)
8 
9 tfidf = TfidfTransformer()
10 X_tfidf = tfidf.fit_transform(X_counts)  # ‚ùå IDF includes entire corpus
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25)
13 
14 from sklearn.tree import DecisionTreeClassifier
15 model = DecisionTreeClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 count_vect = CountVectorizer()
4 X_train_counts = count_vect.fit_transform(X_train_raw)
5 X_test_counts = count_vect.transform(X_test_raw)
6 
7 tfidf = TfidfTransformer()
8 X_train_tfidf = tfidf.fit_transform(X_train_counts)
9 X_test_tfidf = tfidf.transform(X_test_counts)
10 
11 model = DecisionTreeClassifier()
12 model.fit(X_train_tfidf, y_train)
13 print(model.score(X_test_tfidf, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""TF-IDF is computed based on the entire dataset, including test set, leading to overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""TF-IDF transformation is applied to the entire dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been transformed with TF-IDF using the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior TF-IDF transformation.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during TF-IDF transformation.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
104,104,105.0,Feature Creation,Text Vectorization,TfidfVectorizer,"1 df = pd.read_csv(""netflix_titles.csv"")
2 df = df.dropna(subset=[""description"", ""type""])
3 
4 X = df[""description""]
5 y = df[""type""].map({""Movie"": 0, ""TV Show"": 1})
6 
7 # ‚ùå TfidfVectorizer fit on full dataset ‚Äî includes test data
8 vectorizer = TfidfVectorizer()
9 X_tfidf = vectorizer.fit_transform(X)  # <-- Leakage
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2)
12 
13 model = DecisionTreeClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 vectorizer = TfidfVectorizer()
4 X_train = vectorizer.fit_transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)  # ‚úÖ No leakage from test set
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 8, ""explanation"": ""TfidfVectorizer is fit on the entire dataset, including test data, causing preprocessing leakage.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""TfidfVectorizer is fit on the entire dataset before the train-test split, allowing information from the test set to influence the transformation applied to the training set.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the TfidfVectorizer has been fit on the full dataset, leading to data leakage.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test data through the TfidfVectorizer.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which has been influenced by the training data through the TfidfVectorizer.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
105,105,106.0,Feature Creation,Text Vectorization,TfidfVectorizer,"1 df = pd.read_csv(""fake_or_real_news.csv"")
2 X = df[""text""]
3 y = df[""label""].map({""FAKE"": 1, ""REAL"": 0})
4 
5 # ‚ùå Vocabulary and IDF are derived from the full text corpus
6 vectorizer = TfidfVectorizer()
7 X_tfidf = vectorizer.fit_transform(X)
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 vectorizer = TfidfVectorizer()
4 X_train = vectorizer.fit_transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = LogisticRegression()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Vocabulary and IDF are derived from the full text corpus, which can lead to preprocessing leakage as the same features are used for both training and testing sets""},
            {""line_number"": 9, ""explanation"": ""X_train and X_test are not properly created by shuffling the index before splitting, which can lead to overlap leakage as the same indices are used for both training and testing sets""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""TF-IDF vectorization is applied to the full dataset before train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after TF-IDF vectorization, meaning the model is trained on data that has been influenced by the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to prior TF-IDF fitting.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during TF-IDF fitting.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
106,106,,,Text Vectorization,TfidfVectorizer,"1 # Load Amazon reviews dataset (e.g., subset with sentiment labels)
2 df = pd.read_csv(""amazon_reviews.csv"")  # Assume columns: 'review_text', 'label'
3 df = df.dropna(subset=[""review_text"", ""label""])
4 
5 X = df[""review_text""]
6 y = df[""label""].map({""positive"": 1, ""negative"": 0})
7 
8 # ‚ùå Fit on full data ‚Äî includes test set info
9 vectorizer = TfidfVectorizer()
10 X_tfidf = vectorizer.fit_transform(X)  # <-- Leakage here
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)
13 
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))","1 # Load dataset
2 df = pd.read_csv(""amazon_reviews.csv"")
3 df = df.dropna(subset=[""review_text"", ""label""])
4 
5 X = df[""review_text""]
6 y = df[""label""].map({""positive"": 1, ""negative"": 0})
7 
8 # ‚úÖ First split, then fit vectorizer only on training set
9 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
10 
11 vectorizer = TfidfVectorizer()
12 X_train = vectorizer.fit_transform(X_train_raw)
13 X_test = vectorizer.transform(X_test_raw)
14 
15 model = RandomForestClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Fit TfidfVectorizer on the entire dataset instead of only the training set""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""TF-IDF vectorization is applied to the full dataset before train-test split, allowing test data statistics to influence the transformation of training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after TF-IDF vectorization has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior TF-IDF fitting.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that was transformed using TF-IDF vectorization fitted on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
107,107,107.0,Feature Creation,Text Vectorization,TfidfVectorizer,"1 df = pd.read_csv(""SMSSpamCollection"", sep=""\t"", names=[""label"", ""message""])
2 X = df[""message""]
3 y = df[""label""].map({""spam"": 1, ""ham"": 0})
4 
5 # ‚ùå Test data influences vocabulary and term weights
6 vectorizer = TfidfVectorizer()
7 X_tfidf = vectorizer.fit_transform(X)
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25)
10 
11 from sklearn.naive_bayes import MultinomialNB
12 model = MultinomialNB()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 vectorizer = TfidfVectorizer()
4 X_train = vectorizer.fit_transform(X_train_raw)
5 X_test = vectorizer.transform(X_test_raw)
6 
7 model = MultinomialNB()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""TfidfVectorizer is fit on the entire dataset (X), and train-test split is applied to the transformed features (X_tfidf) instead of the original features (X). This can lead to preprocessing leakage as the term weights and vocabulary are influenced by the test data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""The TfidfVectorizer is fit on the entire dataset before the train-test split, allowing test data to influence the vocabulary and term weights.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the TfidfVectorizer has been fit on the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to the TfidfVectorizer being fit on the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the TfidfVectorizer being fit on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
108,108,108.0,Feature Creation,group by aggregation,df.groupby().agg().to_dict() ‚Üímap(),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå Aggregation done on full dataset ‚Äî test set influences mean fare
5 fare_map = df.groupby('Pclass')['Fare'].mean().to_dict()
6 df['avg_fare_by_class'] = df['Pclass'].map(fare_map)  # <-- Leakage here
7 
8 X = df[['avg_fare_by_class']]
9 y = df['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Pclass', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Compute group mean only on training data
6 fare_map = X_train.groupby('Pclass')['Fare'].mean().to_dict()
7 X_train['avg_fare_by_class'] = X_train['Pclass'].map(fare_map)
8 X_test['avg_fare_by_class'] = X_test['Pclass'].map(fare_map)
9 
10 X_train = X_train[['avg_fare_by_class']]
11 X_test = X_test[['avg_fare_by_class']]
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Mean fare is calculated based on the full dataset including the test set, and then the mean is assigned to each row in the dataset, including the test set, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Aggregation is performed on the entire dataset before the train-test split, allowing test data statistics to influence the feature engineering process.""
    },
    {
      ""line_number"": 6,
      ""explanation"": ""The feature 'avg_fare_by_class' is created using the mean fare calculated from the entire dataset, which includes information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been contaminated with information from the test set due to the leakage in feature engineering.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by the leakage in feature engineering.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
109,109,109.0,Feature Creation,group by aggregation,df.groupby().agg().to_dict() ‚Üímap(),"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['Neighborhood', 'SalePrice']]
3 
4 # ‚ùå Median includes future test houses
5 median_map = df.groupby('Neighborhood')['SalePrice'].median().to_dict()
6 df['neighborhood_median_price'] = df['Neighborhood'].map(median_map)
7 
8 X = df[['neighborhood_median_price']]
9 y = df['SalePrice']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Neighborhood']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Compute median from training data only
6 temp_train = pd.concat([X_train, y_train], axis=1)
7 median_map = temp_train.groupby('Neighborhood')['SalePrice'].median().to_dict()
8 
9 X_train['neighborhood_median_price'] = X_train['Neighborhood'].map(median_map)
10 X_test['neighborhood_median_price'] = X_test['Neighborhood'].map(median_map)
11 
12 X_train = X_train[['neighborhood_median_price']]
13 X_test = X_test[['neighborhood_median_price']]
14 
15 model = Ridge()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Median is calculated on the full dataset, which includes test houses, and then applied to the test set as a feature.""},
            {""line_number"": 10, ""explanation"": ""X_train and X_test should be disjoint, but they are created by splitting the same DataFrame.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""The median house price by neighborhood is calculated on the entire dataset before the train-test split, causing data leakage as test data statistics influence the training data.""
    },
    {
      ""line_number"": 6,
      ""explanation"": ""The feature 'neighborhood_median_price' is created using the contaminated median values, leading to leakage in both training and test sets.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the training data that includes the leaked 'neighborhood_median_price' feature.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the test data that includes the leaked 'neighborhood_median_price' feature.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
110,110,110.0,Feature Creation,group by aggregation,df.groupby().agg().to_dict() ‚Üímap(),"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 
4 # ‚ùå Includes loan amounts from test rows
5 loan_map = df.groupby('Education')['LoanAmount'].mean().to_dict()
6 df['avg_loan_by_edu'] = df['Education'].map(loan_map)
7 
8 X = df[['avg_loan_by_edu']]
9 y = df['Loan_Status'].map({'Y': 1, 'N': 0})
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 from sklearn.linear_model import LogisticRegression
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status'].map({'Y': 1, 'N': 0})
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 loan_map = X_train.groupby('Education')['LoanAmount'].mean().to_dict()
6 X_train['avg_loan_by_edu'] = X_train['Education'].map(loan_map)
7 X_test['avg_loan_by_edu'] = X_test['Education'].map(loan_map)
8 
9 X_train = X_train[['avg_loan_by_edu']]
10 X_test = X_test[['avg_loan_by_edu']]
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""The mean loan amounts for each education level are computed using the entire dataset, including test data, and then applied to the test data through mapping.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the feature engineering step, which has already contaminated the data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
111,111,111.0,Feature Creation,group by aggregation,df.groupby().agg().to_dict() ‚Üímap(),"1 df = pd.read_csv(""stroke_data.csv"")
2 df = df[['work_type', 'bmi', 'stroke']].dropna()
3 
4 # ‚ùå Average BMI includes future (test) patients
5 bmi_map = df.groupby('work_type')['bmi'].mean().to_dict()
6 df['avg_bmi_by_work'] = df['work_type'].map(bmi_map)
7 
8 X = df[['avg_bmi_by_work']]
9 y = df['stroke']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.tree import DecisionTreeClassifier
13 model = DecisionTreeClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['work_type', 'bmi']]
2 y = df['stroke']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 bmi_map = X_train.groupby('work_type')['bmi'].mean().to_dict()
6 X_train['avg_bmi_by_work'] = X_train['work_type'].map(bmi_map)
7 X_test['avg_bmi_by_work'] = X_test['work_type'].map(bmi_map)
8 
9 X_train = X_train[['avg_bmi_by_work']]
10 X_test = X_test[['avg_bmi_by_work']]
11 
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Average BMI for each work_type is calculated using the entire dataset, including test data, and then applied to the test set.""},
            {""line_number"": 10, ""explanation"": ""The data is split, but the `avg_bmi_by_work` feature is not recalculated for the test set. This results in the test set having features derived from the full dataset, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering is applied to the full dataset before train-test split, allowing test data statistics to influence training. The average BMI is calculated using the entire dataset, including future test data.""
    },
    {
      ""line_number"": 6,
      ""explanation"": ""The 'avg_bmi_by_work' feature is created using the contaminated average BMI values, which include information from the test set.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the 'avg_bmi_by_work' feature has already been contaminated with test data information.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to the leakage in feature engineering.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the leakage in feature engineering.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
112,112,112.0,Feature Creation,group by aggregation,df.groupby().transform(),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå Transformation applied before splitting ‚Äî test data influences the mean
5 df['pclass_fare_mean'] = df.groupby('Pclass')['Fare'].transform('mean')  # <-- leakage
6 
7 X = df[['pclass_fare_mean']]
8 y = df['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['Pclass', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 # ‚úÖ Calculate mean only on training data
6 group_means = X_train.groupby('Pclass')['Fare'].mean().to_dict()
7 X_train['pclass_fare_mean'] = X_train['Pclass'].map(group_means)
8 X_test['pclass_fare_mean'] = X_test['Pclass'].map(group_means)
9 
10 X_train = X_train[['pclass_fare_mean']]
11 X_test = X_test[['pclass_fare_mean']]
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Mean of Fare per Pclass is calculated over the entire dataset, including test data, and then assigned to the training set as a new feature, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering is applied to the full dataset before train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
113,113,113.0,Feature Creation,group by aggregation,df.groupby().transform(),"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['Neighborhood', 'LotArea', 'SalePrice']]
3 
4 # ‚ùå Includes test data in group statistics
5 df['neigh_lotarea_median'] = df.groupby('Neighborhood')['LotArea'].transform('median')
6 
7 X = df[['neigh_lotarea_median']]
8 y = df['SalePrice']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Neighborhood', 'LotArea']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 group_medians = X_train.groupby('Neighborhood')['LotArea'].median().to_dict()
6 X_train['neigh_lotarea_median'] = X_train['Neighborhood'].map(group_medians)
7 X_test['neigh_lotarea_median'] = X_test['Neighborhood'].map(group_medians)
8 
9 X_train = X_train[['neigh_lotarea_median']]
10 X_test = X_test[['neigh_lotarea_median']]
11 
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Group statistics (median) are calculated on the full dataset before train-test split, which introduces preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering using group statistics is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the feature engineering step, which has already contaminated the data with test set information.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to potentially inflated performance metrics.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
114,114,114.0,Feature Creation,group by aggregation,df.groupby().transform(),"1 df = pd.read_csv(""stroke_data.csv"")
2 df = df[['work_type', 'age', 'stroke']].dropna()
3 
4 # ‚ùå Group stats include test patients
5 df['worktype_age_mean'] = df.groupby('work_type')['age'].transform('mean')
6 
7 X = df[['worktype_age_mean']]
8 y = df['stroke']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.tree import DecisionTreeClassifier
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['work_type', 'age']]
2 y = df['stroke']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 group_means = X_train.groupby('work_type')['age'].mean().to_dict()
6 X_train['worktype_age_mean'] = X_train['work_type'].map(group_means)
7 X_test['worktype_age_mean'] = X_test['work_type'].map(group_means)
8 
9 X_train = X_train[['worktype_age_mean']]
10 X_test = X_test[['worktype_age_mean']]
11 
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Mean age per work_type is calculated on the entire dataset, including test data, before splitting.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering is applied to the full dataset before train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the feature engineering step, which has already contaminated the data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
115,115,115.0,Feature Creation,group by aggregation,df.groupby().transform(),"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Property_Area', 'LoanAmount', 'Loan_Status']].dropna()
3 
4 # ‚ùå Includes future (test) loan data in the group mean
5 df['loanmean_by_area'] = df.groupby('Property_Area')['LoanAmount'].transform('mean')
6 
7 X = df[['loanmean_by_area']]
8 y = df['Loan_Status'].map({'Y': 1, 'N': 0})
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Property_Area', 'LoanAmount']]
2 y = df['Loan_Status'].map({'Y': 1, 'N': 0})
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 group_means = X_train.groupby('Property_Area')['LoanAmount'].mean().to_dict()
6 X_train['loanmean_by_area'] = X_train['Property_Area'].map(group_means)
7 X_test['loanmean_by_area'] = X_test['Property_Area'].map(group_means)
8 
9 X_train = X_train[['loanmean_by_area']]
10 X_test = X_test[['loanmean_by_area']]
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""The mean of 'LoanAmount' for each 'Property_Area' is calculated on the entire dataset, including test data, which leads to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Feature engineering is applied to the full dataset before train-test split, allowing test data statistics to influence the training data through the group mean calculation.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after the feature engineering step, which has already contaminated the data with information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which has been influenced by the training data through the group mean calculation.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
116,116,116.0,Feature Selection,Filter Methods,SelectKBest,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Age', 'Fare', 'SibSp', 'Survived']].dropna()
3 
4 X = df.drop(""Survived"", axis=1)
5 y = df[""Survived""]
6 
7 # ‚ùå Feature selection is done before train-test split (leakage)
8 selector = SelectKBest(score_func=f_classif, k=2)
9 X_selected = selector.fit_transform(X, y)  # <-- Test data influences selected features
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = SelectKBest(score_func=f_classif, k=2)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)  # ‚úÖ Test data transformed using training-only selected features
6 
7 model = LogisticRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Feature selection is done before train-test split, allowing test data to influence selected features""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Feature selection is applied to the entire dataset before train-test split, allowing test data to influence which features are selected.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after feature selection, meaning the test data has already influenced the feature selection process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the training data that has been influenced by the test data through feature selection.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
117,117,117.0,Feature Selection,Filter Methods,SelectKBest,"1 df = pd.read_csv(""winequality-red.csv"", sep="";"")
2 X = df.drop(""quality"", axis=1)
3 y = df[""quality""]
4 
5 selector = SelectKBest(score_func=f_classif, k=4)
6 X_selected = selector.fit_transform(X, y)  # ‚ùå Leakage: test data influences scoring
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
9 
10 from sklearn.linear_model import Ridge
11 model = Ridge()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 selector = SelectKBest(score_func=f_classif, k=4)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = Ridge()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""SelectKBest selects features based on the entire dataset, including test data, leading to a preprocessing leakage.""},
            {""line_number"": 8, ""explanation"": ""train_test_split is called after the SelectKBest, so the indices of the selected features are already present in X_train and X_test, leading to an overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Feature selection is applied to the full dataset before train-test split, allowing test data to influence the selection of features.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after feature selection, meaning the test data has already influenced which features are selected.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through feature selection.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been influenced by the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
118,118,118.0,Feature Selection,Filter Methods,SelectKBest,"1 df = pd.read_csv(""heart.csv"")
2 X = df.drop(""target"", axis=1)
3 y = df[""target""]
4 
5 selector = SelectKBest(score_func=f_classif, k=3)
6 X_selected = selector.fit_transform(X, y)  # ‚ùå Test labels influence selection
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
9 
10 from sklearn.tree import DecisionTreeClassifier
11 model = DecisionTreeClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = SelectKBest(score_func=f_classif, k=3)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Test labels are used during feature selection, introducing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Feature selection is applied to the entire dataset before train-test split, allowing test data labels to influence the selection of features.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after feature selection, which has already been influenced by the test data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test data during feature selection.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
119,119,119.0,Feature Selection,Filter Methods,SelectKBest,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['reading score', 'writing score']]
3 y = df['math score']
4 
5 from sklearn.feature_selection import SelectKBest, f_regression
6 selector = SelectKBest(score_func=f_regression, k=1)
7 X_selected = selector.fit_transform(X, y)  # ‚ùå Entire dataset used
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
10 
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 selector = SelectKBest(score_func=f_regression, k=1)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = LinearRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""SelectKBest applies feature selection on the entire dataset before splitting it into train and test sets""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Feature selection is applied to the entire dataset before the train-test split, allowing information from the test set to influence the selected features.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after feature selection, meaning the test set has already influenced the feature selection process.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been influenced by the test data through the feature selection process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that was used in the feature selection process, leading to data leakage.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
120,120,120.0,Feature Selection,Filter Methods,VarianceThreshold,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Sex', 'SibSp', 'Survived']].dropna()
3 df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})
4 
5 X = df.drop('Survived', axis=1)
6 y = df['Survived']
7 
8 # ‚ùå VarianceThreshold fit on full dataset ‚Äî includes test data
9 selector = VarianceThreshold(threshold=0.01)
10 X_selected = selector.fit_transform(X)  # <-- Leakage: variance calc includes test set
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
13 
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 # ‚úÖ Fit selector only on training data
4 selector = VarianceThreshold(threshold=0.01)
5 X_train_selected = selector.fit_transform(X_train)
6 X_test_selected = selector.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_selected, y_train)
10 print(model.score(X_test_selected, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""VarianceThreshold fit on full dataset ‚Äî includes test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""VarianceThreshold is fit on the entire dataset before train-test split, causing test data to influence the feature selection process.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the feature selection process that included test data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the feature selection process that included test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
121,121,121.0,Feature Selection,Filter Methods,VarianceThreshold,"1 df = pd.read_csv(""winequality-red.csv"", sep="";"")
2 X = df.drop(""quality"", axis=1)
3 y = df[""quality""]
4 
5 # ‚ùå Selector sees full dataset when removing near-constant features
6 selector = VarianceThreshold(threshold=0.0)
7 X_selected = selector.fit_transform(X)  # Leakage: test influences what features are dropped
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 selector = VarianceThreshold(threshold=0.0)
4 X_train_selected = selector.fit_transform(X_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = Ridge()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""Variable selection is performed on the full dataset before splitting, leading to overlap leakage since the test set can influence which features are selected and thus affecting the model performance""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""VarianceThreshold is applied to the full dataset before train-test split, allowing test data to influence which features are selected.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data with features selected based on the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data with features selected based on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
122,122,122.0,Feature Selection,Filter Methods,VarianceThreshold,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['gender', 'math score', 'reading score', 'writing score']]
3 
4 df['gender'] = df['gender'].map({'male': 1, 'female': 0})
5 
6 X = df.drop(columns='math score')
7 y = df['math score']
8 
9 # ‚ùå Full dataset passed to selector
10 selector = VarianceThreshold(threshold=1.0)
11 X_selected = selector.fit_transform(X)  # <-- Test set affects variance threshold decision
12 
13 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
14 
15 from sklearn.linear_model import LinearRegression
16 model = LinearRegression()
17 model.fit(X_train, y_train)
18 print(model.score(X_test, y_test))
19 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 selector = VarianceThreshold(threshold=1.0)
4 X_train_selected = selector.fit_transform(X_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = LinearRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""VarianceThreshold is computed using the full dataset, affecting the selection of features, which is a form of preprocessing leakage.""},
            {""line_number"": 11, ""explanation"": ""X_selected is computed based on the full dataset, which is then used for splitting into train and test sets, causing overlap leakage since the test set affects the selection of features.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 11,
      ""explanation"": ""VarianceThreshold is applied to the full dataset before train-test split, allowing test data to influence the variance threshold decision.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is trained on the contaminated training data that has been affected by test data through the variance threshold selection.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the variance threshold selection.""
    }
  ]
}
","[Training method: fit, Training line: 17]  
[Testing method: score, Testing line: 18]"
123,123,123.0,Feature Selection,Filter Methods,VarianceThreshold,"1 # Load dataset
2 df = pd.read_csv(""diabetes.csv"")
3 
4 X = df.drop(""Outcome"", axis=1)
5 y = df[""Outcome""]
6 
7 # ‚ùå Variance filter applied before train-test split ‚Äî test data influences feature removal
8 selector = VarianceThreshold(threshold=0.01)
9 X_selected = selector.fit_transform(X)  # <-- Leakage: test variance included
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 # ‚úÖ Fit VarianceThreshold only on training data to avoid leakage
4 selector = VarianceThreshold(threshold=0.01)
5 X_train_selected = selector.fit_transform(X_train)
6 X_test_selected = selector.transform(X_test)
7 
8 model = LogisticRegression()
9 model.fit(X_train_selected, y_train)
10 print(model.score(X_test_selected, y_test))
11 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""VarianceThreshold is applied to full dataset before splitting, test variance is included in feature selection""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""VarianceThreshold is applied to the full dataset before train-test split, allowing test data variance to influence feature selection.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data with features selected using test data variance.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data with features selected using test data variance.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
124,124,124.0,Feature Selection,Wrapper Methods,RFE,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Age', 'Fare', 'SibSp', 'Survived']].dropna()
3 
4 X = df.drop('Survived', axis=1)
5 y = df['Survived']
6 
7 # ‚ùå RFE fit on full data ‚Äî includes test label info
8 model = LogisticRegression(max_iter=1000)
9 selector = RFE(estimator=model, n_features_to_select=2)
10 X_selected = selector.fit_transform(X, y)  # <-- Leakage happens here
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
13 
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 model = LogisticRegression(max_iter=1000)
4 selector = RFE(estimator=model, n_features_to_select=2)
5 X_train_selected = selector.fit_transform(X_train, y_train)
6 X_test_selected = selector.transform(X_test)  # ‚úÖ Transform test set using selector fit on training only
7 
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""RFE is applied on the full dataset before train-test split, which includes test labels, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""RFE is applied to the full dataset before train-test split, allowing test data to influence feature selection.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data with features selected using the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data with features selected using the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
125,125,125.0,Feature Selection,Wrapper Methods,RFE,"1 df = pd.read_csv(""winequality-red.csv"", sep="";"")
2 X = df.drop(""quality"", axis=1)
3 y = df[""quality""]
4 
5 from sklearn.linear_model import Ridge
6 from sklearn.feature_selection import RFE
7 
8 model = Ridge()
9 selector = RFE(model, n_features_to_select=5)
10 X_selected = selector.fit_transform(X, y)  # ‚ùå Full data used ‚Äî future labels included
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
13 
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 model = Ridge()
4 selector = RFE(model, n_features_to_select=5)
5 X_train_selected = selector.fit_transform(X_train, y_train)
6 X_test_selected = selector.transform(X_test)
7 
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""Future labels (y) are included when selecting features, leading to overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection using RFE is applied to the full dataset before train-test split, allowing test data to influence the selection of features.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data with features selected using information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in feature selection.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
126,126,126.0,Feature Selection,Wrapper Methods,RFE,"1 df = pd.read_csv(""heart.csv"")
2 X = df.drop(""target"", axis=1)
3 y = df[""target""]
4 
5 from sklearn.tree import DecisionTreeClassifier
6 
7 selector = RFE(DecisionTreeClassifier(), n_features_to_select=4)
8 X_selected = selector.fit_transform(X, y)  # ‚ùå Uses all label info, including test labels
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
11 
12 model = DecisionTreeClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 selector = RFE(DecisionTreeClassifier(), n_features_to_select=4)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""RFE is applied to the full dataset, including test labels, which can lead to feature selection based on test data and thus leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Feature selection using RFE is applied to the entire dataset before the train-test split, allowing test data information to influence the feature selection process.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the full dataset, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through the feature selection process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been influenced by the feature selection process applied to the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
127,127,127.0,Feature Selection,Wrapper Methods,RFE,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df.drop(""Outcome"", axis=1)
3 y = df[""Outcome""]
4 
5 from sklearn.ensemble import RandomForestClassifier
6 selector = RFE(RandomForestClassifier(n_estimators=10), n_features_to_select=5)
7 
8 # ‚ùå Fit before train-test split ‚Äî test data influences selected features
9 X_selected = selector.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
12 
13 model = RandomForestClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = RFE(RandomForestClassifier(n_estimators=10), n_features_to_select=5)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = RandomForestClassifier()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Fitting RandomForestClassifier with all features including the target variable, and then using RecursiveFeatureElimination to select features based on the fitted model. This leads to overlap leakage as the test set features are selected based on the training set performance.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Feature selection is applied to the full dataset before train-test split, allowing test data characteristics to influence the selection process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after feature selection, which has already been influenced by the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data during feature selection.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
128,128,128.0,Feature Selection,Wrapper Methods,Sequential Feature Selection,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Age', 'Fare', 'SibSp', 'Survived']].dropna()
3 
4 X = df.drop(""Survived"", axis=1)
5 y = df[""Survived""]
6 
7 # ‚ùå SFS is fit on the full dataset ‚Äî includes test data
8 selector = SequentialFeatureSelector(LogisticRegression(), n_features_to_select=2, direction='forward')
9 X_selected = selector.fit_transform(X, y)  # <-- Leakage here
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = SequentialFeatureSelector(LogisticRegression(), n_features_to_select=2, direction='forward')
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = LogisticRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""SequentialFeatureSelector is fit on the full dataset, including test data, which can lead to leakage of information from the test set to the model.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""SequentialFeatureSelector is fit on the entire dataset before the train-test split, causing feature selection to be influenced by the test data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after feature selection, which has already been influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the training data that has been contaminated by feature selection leakage.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by feature selection leakage.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
129,129,129.0,Feature Selection,Wrapper Methods,Sequential Feature Selection,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'TotalBsmtSF', 'GarageArea', 'YearBuilt', 'SalePrice']].dropna()
3 
4 X = df.drop(""SalePrice"", axis=1)
5 y = df[""SalePrice""]
6 
7 from sklearn.linear_model import LinearRegression
8 from sklearn.feature_selection import SequentialFeatureSelector
9 
10 # ‚ùå Full dataset is used to select features
11 selector = SequentialFeatureSelector(LinearRegression(), n_features_to_select=3)
12 X_selected = selector.fit_transform(X, y)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
15 
16 model = LinearRegression()
17 model.fit(X_train, y_train)
18 print(model.score(X_test, y_test))
19 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 selector = SequentialFeatureSelector(LinearRegression(), n_features_to_select=3)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = LinearRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""Feature selection is performed on the full dataset before splitting it into train and test sets""},
            {""line_number"": 14, ""explanation"": ""Train-test split is performed after feature selection, which introduces overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""Feature selection is applied to the full dataset before train-test split, allowing test data to influence the selection of features.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after feature selection, meaning the test set has already influenced the feature selection process.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is trained on the training data that has been influenced by the test data through feature selection.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is evaluated on the test data that was used in the feature selection process, leading to biased evaluation results.""
    }
  ]
}
","[Training method: fit, Training line: 17]  
[Testing method: score, Testing line: 18]"
130,130,130.0,Feature Selection,Wrapper Methods,Sequential Feature Selection,"1 df = pd.read_csv(""heart.csv"")
2 X = df.drop(""target"", axis=1)
3 y = df[""target""]
4 
5 from sklearn.tree import DecisionTreeClassifier
6 from sklearn.feature_selection import SequentialFeatureSelector
7 
8 # ‚ùå SFS includes test data during feature selection
9 selector = SequentialFeatureSelector(DecisionTreeClassifier(), n_features_to_select=4)
10 X_selected = selector.fit_transform(X, y)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
13 
14 model = DecisionTreeClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 selector = SequentialFeatureSelector(DecisionTreeClassifier(), n_features_to_select=4)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""SequentialFeatureSelector includes test data during feature selection""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection is applied to the entire dataset before the train-test split, allowing test data to influence the selected features.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data with features selected using the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data with features selected using the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
131,131,131.0,Feature Selection,Wrapper Methods,Sequential Feature Selection,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df.drop(""Outcome"", axis=1)
3 y = df[""Outcome""]
4 
5 from sklearn.ensemble import RandomForestClassifier
6 from sklearn.feature_selection import SequentialFeatureSelector
7 
8 # ‚ùå Fit SFS before splitting ‚Äî includes future labels
9 selector = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=5)
10 X_selected = selector.fit_transform(X, y)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
13 
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = SequentialFeatureSelector(RandomForestClassifier(), n_features_to_select=5)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = RandomForestClassifier()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 9, ""explanation"": ""SequentialFeatureSelector fits the model on the full dataset, including future labels, before splitting.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection is applied to the full dataset before train-test split, allowing test data to influence the selection of features.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data with features selected using information from the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data with features selected using information from the test set.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
132,132,132.0,Feature Selection,Wrapper Methods,SelectFromModel(prefit=False),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Fare', 'Age', 'SibSp', 'Survived']].dropna()
3 
4 X = df.drop(""Survived"", axis=1)
5 y = df[""Survived""]
6 
7 # ‚ùå SelectFromModel applied before splitting ‚Äî uses full data
8 selector = SelectFromModel(LogisticRegression(), threshold=""mean"", prefit=False)
9 X_selected = selector.fit_transform(X, y)  # <-- Leakage: test data influences selection
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = SelectFromModel(LogisticRegression(), threshold=""mean"", prefit=False)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = LogisticRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 8, ""explanation"": ""SelectFromModel is applied to the full dataset before splitting, making test data influence the selection of features.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Feature selection is applied to the full dataset before train-test split, allowing test data to influence the feature selection process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data during feature selection.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
133,133,133.0,Feature Selection,Wrapper Methods,SelectFromModel(prefit=False),"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'TotalBsmtSF', 'GarageArea', 'SalePrice']].dropna()
3 
4 X = df.drop(""SalePrice"", axis=1)
5 y = df[""SalePrice""]
6 
7 from sklearn.linear_model import Ridge
8 selector = SelectFromModel(Ridge(alpha=1.0), threshold=""median"", prefit=False)
9 X_selected = selector.fit_transform(X, y)  # ‚ùå Includes test info
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
12 
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 selector = SelectFromModel(Ridge(alpha=1.0), threshold=""median"", prefit=False)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = Ridge()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""SelectFromModel method fits the model on the entire dataset (X, y), including test data, and returns the feature indices to be selected. This results in the selected features being contaminated with test data, and therefore, causing overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Feature selection is applied to the entire dataset before the train-test split, allowing test data information to influence the selection process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after feature selection, which has already been influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior feature selection.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
134,134,134.0,Feature Selection,Wrapper Methods,SelectFromModel(prefit=False),"1 df = pd.read_csv(""heart.csv"")
2 X = df.drop(""target"", axis=1)
3 y = df[""target""]
4 
5 from sklearn.ensemble import RandomForestClassifier
6 selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold=""mean"", prefit=False)
7 X_selected = selector.fit_transform(X, y)  # ‚ùå Fit includes test set
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
10 
11 model = RandomForestClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 selector = SelectFromModel(RandomForestClassifier(n_estimators=100), threshold=""mean"", prefit=False)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = RandomForestClassifier()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""SelectFromModel fits the model on the entire dataset, including test set, leading to overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Feature selection is applied to the entire dataset before train-test split, allowing test data to influence the feature selection process.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after feature selection has already been applied to the full dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data during feature selection.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
135,135,135.0,Feature Selection,Wrapper Methods,SelectFromModel(prefit=False),"1 df = pd.read_csv(""diabetes.csv"")
2 X = df.drop(""Outcome"", axis=1)
3 y = df[""Outcome""]
4 
5 from sklearn.linear_model import LogisticRegression
6 selector = SelectFromModel(LogisticRegression(max_iter=500), threshold=""mean"", prefit=False)
7 X_selected = selector.fit_transform(X, y)  # ‚ùå Test data influences which features are selected
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 selector = SelectFromModel(LogisticRegression(max_iter=500), threshold=""mean"", prefit=False)
4 X_train_selected = selector.fit_transform(X_train, y_train)
5 X_test_selected = selector.transform(X_test)
6 
7 model = LogisticRegression()
8 model.fit(X_train_selected, y_train)
9 print(model.score(X_test_selected, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""Test data is used to select features, leading to overlap leakage""},
            {""line_number"": 9, ""explanation"": ""X_selected is created using both train and test data, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Feature selection is applied to the entire dataset before train-test split, allowing test data to influence which features are selected.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after feature selection, meaning the test data has already influenced the feature selection process.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data with features selected using the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data with features selected using the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
136,136,136.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",SelectFromModel(prefit=True),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Fare', 'Age', 'SibSp', 'Survived']].dropna()
3 
4 X = df.drop(""Survived"", axis=1)
5 y = df[""Survived""]
6 
7 # ‚ùå Model is fit on full data, including test set
8 full_model = LogisticRegression(max_iter=500).fit(X, y)
9 selector = SelectFromModel(full_model, prefit=True, threshold=""mean"")
10 X_selected = selector.transform(X)  # <-- Leakage: test labels influence selected features
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
13 
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 # ‚úÖ Fit model on training data only
4 model_for_selection = LogisticRegression(max_iter=500).fit(X_train, y_train)
5 selector = SelectFromModel(model_for_selection, prefit=True, threshold=""mean"")
6 
7 X_train_sel = selector.transform(X_train)
8 X_test_sel = selector.transform(X_test)
9 
10 final_model = LogisticRegression()
11 final_model.fit(X_train_sel, y_train)
12 print(final_model.score(X_test_sel, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""Test labels are used to select features, introducing preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""The model is fit on the full dataset, including the test set, which means the test data influences the feature selection process.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection is performed using the full dataset, allowing test data to influence which features are selected.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by the test data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the test data through feature selection.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the test data that was used in the feature selection process, leading to biased evaluation results.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
137,137,137.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",SelectFromModel(prefit=True),"1 df = pd.read_csv(""winequality-red.csv"", sep="";"")
2 X = df.drop(""quality"", axis=1)
3 y = df[""quality""]
4 
5 from sklearn.ensemble import RandomForestRegressor
6 from sklearn.feature_selection import SelectFromModel
7 
8 # ‚ùå Random forest fit on entire dataset before splitting
9 full_model = RandomForestRegressor().fit(X, y)
10 selector = SelectFromModel(full_model, prefit=True, threshold=""median"")
11 X_selected = selector.transform(X)
12 
13 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
14 
15 model = RandomForestRegressor()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 rf_model = RandomForestRegressor().fit(X_train, y_train)
4 selector = SelectFromModel(rf_model, prefit=True, threshold=""median"")
5 
6 X_train_sel = selector.transform(X_train)
7 X_test_sel = selector.transform(X_test)
8 
9 model = RandomForestRegressor()
10 model.fit(X_train_sel, y_train)
11 print(model.score(X_test_sel, y_test))
12 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 9, ""explanation"": ""Random forest model is fit on the entire dataset before splitting, leading to overlap leakage as the test set is a subset of the full dataset.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Random forest model is fit on the entire dataset before the train-test split, causing data leakage as the feature selection is influenced by the test data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection is performed using a model that was fit on the entire dataset, leading to leakage since test data influences which features are selected.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by the entire dataset, including the test data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the training data that has been contaminated by feature selection influenced by the test data.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by feature selection influenced by the test data.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
138,138,138.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",SelectFromModel(prefit=True),"1 df = pd.read_csv(""heart.csv"")
2 X = df.drop(""target"", axis=1)
3 y = df[""target""]
4 
5 from sklearn.tree import DecisionTreeClassifier
6 from sklearn.feature_selection import SelectFromModel
7 
8 # ‚ùå Model trained on full data used to pick features
9 clf = DecisionTreeClassifier().fit(X, y)
10 selector = SelectFromModel(clf, prefit=True, threshold=""mean"")
11 X_selected = selector.transform(X)
12 
13 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
14 
15 model = DecisionTreeClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 tree_model = DecisionTreeClassifier().fit(X_train, y_train)
4 selector = SelectFromModel(tree_model, prefit=True, threshold=""mean"")
5 
6 X_train_sel = selector.transform(X_train)
7 X_test_sel = selector.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_sel, y_train)
11 print(model.score(X_test_sel, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Model trained on full dataset before splitting it into train and test sets""},
            {""line_number"": 11, ""explanation"": ""Features selected based on the model trained on full dataset""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""The DecisionTreeClassifier is fit on the entire dataset, which means the feature selection process has access to the test data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""SelectFromModel uses the model trained on the full dataset to select features, causing data leakage as it includes information from the test set.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Feature selection is applied to the entire dataset before the train-test split, leading to leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by the entire dataset, including the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on data that has been contaminated by test set information due to prior feature selection.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on test data that was used in the feature selection process, leading to overly optimistic performance estimates.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
139,139,139.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",SelectFromModel(prefit=True),"1 df = pd.read_csv(""diabetes.csv"")
2 X = df.drop(""Outcome"", axis=1)
3 y = df[""Outcome""]
4 
5 from sklearn.linear_model import LogisticRegression
6 from sklearn.feature_selection import SelectFromModel
7 
8 # ‚ùå Model trained on full data before split
9 lr = LogisticRegression(max_iter=1000).fit(X, y)
10 selector = SelectFromModel(lr, prefit=True, threshold=""mean"")
11 X_selected = selector.transform(X)
12 
13 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
14 
15 model = LogisticRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 lr = LogisticRegression(max_iter=1000).fit(X_train, y_train)
4 selector = SelectFromModel(lr, prefit=True, threshold=""mean"")
5 
6 X_train_sel = selector.transform(X_train)
7 X_test_sel = selector.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_sel, y_train)
11 print(model.score(X_test_sel, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Model trained on full data before split""},
            {""line_number"": 15, ""explanation"": ""Model is trained again on the same preprocessed data (X_selected) as before""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Logistic Regression model is trained on the entire dataset before the train-test split, which contaminates the feature selection process.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection is performed using a model that was fit on the entire dataset, leading to data leakage as test data influences the feature selection.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by the entire dataset, including the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the feature selection process.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the feature selection process.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
140,140,140.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",ELI5,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Pclass', 'Age', 'Fare', 'SibSp', 'Survived']].dropna()
3 
4 X = df.drop(""Survived"", axis=1)
5 y = df[""Survived""]
6 
7 # ‚ùå PermutationImportance is fit on full data before splitting
8 model = LogisticRegression(max_iter=500).fit(X, y)
9 perm = PermutationImportance(model, random_state=42).fit(X, y)  # <-- Leakage
10 eli5.show_weights(perm, feature_names=list(X.columns))
11 
12 important_features = [X.columns[i] for i, s in enumerate(perm.feature_importances_) if s > 0]
13 X_filtered = X[important_features]
14 
15 X_train, X_test, y_train, y_test = train_test_split(X_filtered, y, test_size=0.3)
16 final_model = LogisticRegression().fit(X_train, y_train)
17 print(final_model.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 model = LogisticRegression(max_iter=500).fit(X_train, y_train)
4 perm = PermutationImportance(model, random_state=42).fit(X_train, y_train)
5 eli5.show_weights(perm, feature_names=list(X.columns))
6 
7 important_features = [X.columns[i] for i, s in enumerate(perm.feature_importances_) if s > 0]
8 X_train_filtered = X_train[important_features]
9 X_test_filtered = X_test[important_features]
10 
11 final_model = LogisticRegression().fit(X_train_filtered, y_train)
12 print(final_model.score(X_test_filtered, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Model is fit on full dataset before splitting""},
            {""line_number"": 9, ""explanation"": ""PermutationImportance is fit on full data before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""PermutationImportance is fit on the entire dataset before train-test split, causing data leakage as it uses test data information to determine feature importances.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Train-test split is performed after feature selection based on the entire dataset, leading to leakage as the test data influenced the feature selection process.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the training data that has been contaminated by prior leakage from feature selection.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by leakage from feature selection.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
141,141,141.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",ELI5,"1 df = pd.read_csv(""winequality-red.csv"", sep=';')
2 X = df.drop(""quality"", axis=1)
3 y = df[""quality""]
4 
5 from sklearn.linear_model import Ridge
6 from eli5.sklearn import PermutationImportance
7 
8 model = Ridge().fit(X, y)
9 perm = PermutationImportance(model, random_state=0).fit(X, y)  # ‚ùå Includes test set
10 eli5.show_weights(perm, feature_names=X.columns.tolist())
11 
12 selected = [i for i, v in enumerate(perm.feature_importances_) if v > 0]
13 X_selected = X.iloc[:, selected]
14 
15 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 model = Ridge().fit(X_train, y_train)
4 perm = PermutationImportance(model, random_state=0).fit(X_train, y_train)
5 eli5.show_weights(perm, feature_names=X.columns.tolist())
6 
7 selected = [i for i, v in enumerate(perm.feature_importances_) if v > 0]
8 X_train_sel = X_train.iloc[:, selected]
9 X_test_sel = X_test.iloc[:, selected]
10 
11 model.fit(X_train_sel, y_train)
12 print(model.score(X_test_sel, y_test))
13 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 9, ""explanation"": ""The PermutationImportance method is called with the whole dataset, including the test set. This leads to overlap leakage, as the feature importances are calculated based on the entire dataset, including the test set.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Permutation importance is calculated on the entire dataset before train-test split, allowing test data to influence feature selection.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Feature selection is performed using the contaminated permutation importance results, affecting both training and test data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the training data that has been influenced by the test data through feature selection.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by the feature selection process using the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
142,142,142.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",ELI5,"1 df = pd.read_csv(""heart.csv"")
2 X = df.drop(""target"", axis=1)
3 y = df[""target""]
4 
5 from sklearn.tree import DecisionTreeClassifier
6 from eli5.sklearn import PermutationImportance
7 
8 tree = DecisionTreeClassifier().fit(X, y)
9 perm = PermutationImportance(tree, random_state=42).fit(X, y)  # ‚ùå Includes full dataset
10 eli5.show_weights(perm, feature_names=X.columns.tolist())
11 
12 selected = [X.columns[i] for i, imp in enumerate(perm.feature_importances_) if imp > 0]
13 X_filtered = X[selected]
14 
15 X_train, X_test, y_train, y_test = train_test_split(X_filtered, y, test_size=0.2)
16 tree.fit(X_train, y_train)
17 print(tree.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 tree = DecisionTreeClassifier().fit(X_train, y_train)
4 perm = PermutationImportance(tree, random_state=42).fit(X_train, y_train)
5 eli5.show_weights(perm, feature_names=X.columns.tolist())
6 
7 selected = [X.columns[i] for i, imp in enumerate(perm.feature_importances_) if imp > 0]
8 X_train_filtered = X_train[selected]
9 X_test_filtered = X_test[selected]
10 
11 tree.fit(X_train_filtered, y_train)
12 print(tree.score(X_test_filtered, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Model is trained and evaluated on the full dataset, not on the filtered dataset used for feature selection.""},
            {""line_number"": 15, ""explanation"": ""train_test_split is applied only to the filtered dataset, not to the original dataset. However, the model is trained and evaluated on the original dataset, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Permutation importance is calculated on the full dataset, allowing test data to influence feature selection.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Features are selected based on permutation importance calculated on the full dataset, leading to data leakage.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the training data that has been contaminated by leakage from the test data.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by leakage during feature selection.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
143,143,143.0,Feature Selection,"Post-Training Wrapper/Explainer-Based 
Selection ",ELI5,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df.drop(""Outcome"", axis=1)
3 y = df[""Outcome""]
4 
5 from sklearn.linear_model import LogisticRegression
6 from eli5.sklearn import PermutationImportance
7 
8 model = LogisticRegression(max_iter=500).fit(X, y)
9 perm = PermutationImportance(model, random_state=1).fit(X, y)  # ‚ùå Test data leaked
10 eli5.show_weights(perm, feature_names=X.columns.tolist())
11 
12 important = [X.columns[i] for i, imp in enumerate(perm.feature_importances_) if imp > 0]
13 X_filtered = X[important]
14 
15 X_train, X_test, y_train, y_test = train_test_split(X_filtered, y, test_size=0.2)
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 model = LogisticRegression(max_iter=500).fit(X_train, y_train)
4 perm = PermutationImportance(model, random_state=1).fit(X_train, y_train)
5 eli5.show_weights(perm, feature_names=X.columns.tolist())
6 
7 important = [X.columns[i] for i, imp in enumerate(perm.feature_importances_) if imp > 0]
8 X_train_filtered = X_train[important]
9 X_test_filtered = X_test[important]
10 
11 model.fit(X_train_filtered, y_train)
12 print(model.score(X_test_filtered, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""PermutationImportance is applied to the full dataset, including test data, before splitting it into train and test sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Permutation importance is calculated on the entire dataset, including test data, which allows test data information to influence feature selection.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Feature selection is based on permutation importance calculated on the entire dataset, leading to leakage of test data information into the training process.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Train-test split is performed after feature selection, which was influenced by test data, contaminating the training set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data, which includes information from the test set due to prior leakage.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the test data that was indirectly used during feature selection, leading to an overestimated performance.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
144,144,144.0,Feature Selection,Post-Training Manual,"""(LogisticRegression, Lasso, 
Ridge|ElasticNet|LinearSVC|
 SVC(kernel=""""linear"""")).coef_, 
(DecisionTreeClassifier|Rand
 omForestClassifier|XGBoostC
 lassifier).feature_importanc
 es_""","1 import pandas as pd
2 from sklearn.linear_model import LogisticRegression
3 from sklearn.model_selection import train_test_split
4 
5 df = pd.read_csv(""titanic.csv"")
6 df = df[['Pclass', 'Age', 'Fare', 'SibSp', 'Survived']].dropna()
7 
8 X = df.drop(""Survived"", axis=1)
9 y = df[""Survived""]
10 
11 # ‚ùå Fit model before split and select features manually
12 model = LogisticRegression(max_iter=500)
13 model.fit(X, y)
14 coefs = model.coef_[0]
15 
16 # Select features with non-zero coefficients
17 selected = X.columns[coefs != 0]
18 X_selected = X[selected]
19 
20 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
21 final_model = LogisticRegression()
22 final_model.fit(X_train, y_train)
23 print(final_model.score(X_test, y_test))
24 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 model = LogisticRegression(max_iter=500)
4 model.fit(X_train, y_train)
5 coefs = model.coef_[0]
6 
7 selected = X_train.columns[coefs != 0]
8 X_train_sel = X_train[selected]
9 X_test_sel = X_test[selected]
10 
11 final_model = LogisticRegression()
12 final_model.fit(X_train_sel, y_train)
13 print(final_model.score(X_test_sel, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 11, ""explanation"": ""Model is trained and evaluated on data that has already been transformed, leading to overlap leakage.""},
            {""line_number"": 17, ""explanation"": ""Features are selected based on coefficients from a model trained on the full dataset, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 13,
      ""explanation"": ""The model is fit on the entire dataset before the train-test split, which allows information from the test set to influence feature selection.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Feature selection is performed using coefficients from a model trained on the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 20,
      ""explanation"": ""Train-test split is performed after the model has been fit on the entire dataset, leading to a contaminated training and test set.""
    },
    {
      ""line_number"": 22,
      ""explanation"": ""The final model is trained on data that has been influenced by the test set due to prior feature selection leakage.""
    },
    {
      ""line_number"": 23,
      ""explanation"": ""The model is evaluated on a test set that has been influenced by prior leakage during feature selection.""
    }
  ]
}
","[Training method: fit, Training line: 22]  
[Testing method: score, Testing line: 23]"
145,145,145.0,Feature Selection,Post-Training Manual,"""(LogisticRegression, Lasso, 
Ridge|ElasticNet|LinearSVC|
 SVC(kernel=""""linear"""")).coef_, 
(DecisionTreeClassifier|Rand
 omForestClassifier|XGBoostC
 lassifier).feature_importanc
 es_""","1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['GrLivArea', 'GarageArea', 'TotalBsmtSF', 'YearBuilt', 'SalePrice']].dropna()
3 
4 X = df.drop(""SalePrice"", axis=1)
5 y = df[""SalePrice""]
6 
7 from sklearn.linear_model import Lasso
8 
9 # ‚ùå Model trained before split; used to select features
10 lasso = Lasso(alpha=1.0)
11 lasso.fit(X, y)
12 selected = X.columns[lasso.coef_ != 0]
13 X_selected = X[selected]
14 
15 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2)
16 
17 model = Lasso()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 lasso = Lasso(alpha=1.0)
4 lasso.fit(X_train, y_train)
5 selected = X_train.columns[lasso.coef_ != 0]
6 X_train_sel = X_train[selected]
7 X_test_sel = X_test[selected]
8 
9 model = Lasso()
10 model.fit(X_train_sel, y_train)
11 print(model.score(X_test_sel, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""Model is trained before split; used to select features, leading to preprocessing leakage""},
            {""line_number"": 15, ""explanation"": ""X_selected is created based on the coefficients obtained from a model trained on the full dataset, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 11,
      ""explanation"": ""Lasso model is fit on the entire dataset before the train-test split, which means feature selection is influenced by the test data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Features are selected based on the Lasso model that was fit on the entire dataset, causing data leakage.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the feature selection process which included test data.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by the feature selection process which included test data.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
146,146,146.0,Feature Selection,Post-Training Manual,"""(LogisticRegression, Lasso, 
Ridge|ElasticNet|LinearSVC|
 SVC(kernel=""""linear"""")).coef_, 
(DecisionTreeClassifier|Rand
 omForestClassifier|XGBoostC
 lassifier).feature_importanc
 es_""","1 df = pd.read_csv(""diabetes.csv"")
2 X = df.drop(""Outcome"", axis=1)
3 y = df[""Outcome""]
4 
5 from sklearn.ensemble import RandomForestClassifier
6 
7 # ‚ùå Train full model before split and select features
8 rf = RandomForestClassifier(random_state=0)
9 rf.fit(X, y)
10 important = X.columns[rf.feature_importances_ > 0.05]
11 X_selected = X[important]
12 
13 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.25)
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 rf = RandomForestClassifier(random_state=0)
4 rf.fit(X_train, y_train)
5 important = X_train.columns[rf.feature_importances_ > 0.05]
6 X_train_sel = X_train[important]
7 X_test_sel = X_test[important]
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_sel, y_train)
11 print(model.score(X_test_sel, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Model is trained and evaluated on data that has already been selected based on feature importances from the full dataset""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""The RandomForestClassifier is fit on the entire dataset before the train-test split, allowing the model to learn from the test data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Feature selection is performed using the entire dataset, which means the test data influences the selection of features.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after the model has been trained and features have been selected using the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the training data that has been contaminated by prior feature selection using the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the test data that has been influenced by prior feature selection using the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
147,147,147.0,Feature Selection,Post-Training Manual,"""(LogisticRegression, Lasso, 
Ridge|ElasticNet|LinearSVC|
 SVC(kernel=""""linear"""")).coef_, 
(DecisionTreeClassifier|Rand
 omForestClassifier|XGBoostC
 lassifier).feature_importanc
 es_""","1 # Load dataset
2 iris = load_iris(as_frame=True)
3 X = iris.data
4 y = iris.target
5 
6 # ‚ùå Model trained on full dataset before split
7 svc = SVC(kernel=""linear"")
8 svc.fit(X, y)
9 coefs = svc.coef_.sum(axis=0)  # Sum across classes for multi-class
10 
11 # Select features with non-zero coefficients
12 selected_features = X.columns[coefs != 0]
13 X_selected = X[selected_features]
14 
15 # Splitting after feature selection ‚Äî test info leaked
16 X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3)
17 
18 model = SVC(kernel=""linear"")
19 model.fit(X_train, y_train)
20 print(model.score(X_test, y_test))
21 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 svc = SVC(kernel=""linear"")
4 svc.fit(X_train, y_train)
5 coefs = svc.coef_.sum(axis=0)
6 selected_features = X_train.columns[coefs != 0]
7 
8 X_train_sel = X_train[selected_features]
9 X_test_sel = X_test[selected_features]
10 
11 model = SVC(kernel=""linear"")
12 model.fit(X_train_sel, y_train)
13 print(model.score(X_test_sel, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""Model is trained on the full dataset before splitting""},
            {""line_number"": 16, ""explanation"": ""Data is split after feature selection, allowing test information to leak into training""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""The model is trained on the full dataset before the train-test split, which means the feature selection is influenced by the entire dataset, including the test set.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Feature selection is performed using coefficients from a model trained on the full dataset, causing test data information to influence which features are selected.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Train-test split is performed after feature selection, which was based on the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""The model is trained on training data that has been contaminated by test data information due to prior feature selection.""
    },
    {
      ""line_number"": 20,
      ""explanation"": ""The model is evaluated on test data that has been influenced by feature selection based on the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 19]  
[Testing method: score, Testing line: 20]"
148,148,148.0,Categorical Encoding,Nominal data,OneHotEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå OneHotEncoder fit on entire data ‚Äî includes test info
8 encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
9 X_encoded = encoder.fit_transform(X[['Embarked']])  # Leakage
10 X_final = pd.concat([pd.DataFrame(X_encoded), X[['Fare']].reset_index(drop=True)], axis=1)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2)
13 
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
4 X_train_encoded = encoder.fit_transform(X_train_raw[['Embarked']])
5 X_test_encoded = encoder.transform(X_test_raw[['Embarked']])
6 
7 X_train = pd.concat([pd.DataFrame(X_train_encoded), X_train_raw[['Fare']].reset_index(drop=True)], axis=1)
8 X_test = pd.concat([pd.DataFrame(X_test_encoded), X_test_raw[['Fare']].reset_index(drop=True)], axis=1)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""OneHotEncoder fit is applied on the entire dataset (X), including test data, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""OneHotEncoder is fit on the entire dataset before the train-test split, allowing information from the test set to influence the encoding.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the data has already been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
149,149,149.0,Categorical Encoding,Nominal data,OneHotEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 
4 X = df[['Education', 'LoanAmount']]
5 y = df['Loan_Status'].map({'Y': 1, 'N': 0})
6 
7 # ‚ùå Encoder learns all categories, including unseen ones from test set
8 encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
9 X_encoded = encoder.fit_transform(X[['Education']])
10 X_final = pd.concat([pd.DataFrame(X_encoded), X[['LoanAmount']].reset_index(drop=True)], axis=1)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.25)
13 
14 from sklearn.tree import DecisionTreeClassifier
15 model = DecisionTreeClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
4 X_train_encoded = encoder.fit_transform(X_train_raw[['Education']])
5 X_test_encoded = encoder.transform(X_test_raw[['Education']])
6 
7 X_train = pd.concat([pd.DataFrame(X_train_encoded), X_train_raw[['LoanAmount']].reset_index(drop=True)], axis=1)
8 X_test = pd.concat([pd.DataFrame(X_test_encoded), X_test_raw[['LoanAmount']].reset_index(drop=True)], axis=1)
9 
10 model = DecisionTreeClassifier()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }

This code snippet does not contain any leakage. The OneHotEncoder is applied only to the training set, as X_final is assigned to X_train before the model is fit."," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""OneHotEncoder is fit on the entire dataset before the train-test split, allowing test data categories to influence the encoding.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the data has already been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
150,150,150.0,Categorical Encoding,Nominal data,OneHotEncoder,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['cp', 'thalach', 'target']]
3 
4 X = df[['cp', 'thalach']]
5 y = df['target']
6 
7 from sklearn.svm import SVC
8 encoder = OneHotEncoder(sparse=False)
9 X_encoded = encoder.fit_transform(X[['cp']])  # ‚ùå Includes test categories
10 X_final = pd.concat([pd.DataFrame(X_encoded), X[['thalach']].reset_index(drop=True)], axis=1)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2)
13 
14 model = SVC()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 encoder = OneHotEncoder(sparse=False)
4 X_train_encoded = encoder.fit_transform(X_train_raw[['cp']])
5 X_test_encoded = encoder.transform(X_test_raw[['cp']])
6 
7 X_train = pd.concat([pd.DataFrame(X_train_encoded), X_train_raw[['thalach']].reset_index(drop=True)], axis=1)
8 X_test = pd.concat([pd.DataFrame(X_test_encoded), X_test_raw[['thalach']].reset_index(drop=True)], axis=1)
9 
10 model = SVC()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""OneHotEncoder is applied to the entire feature set (X), including test data, and the encoded features are concatenated with X_thalach before splitting the data, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""OneHotEncoder is fit on the entire dataset before train-test split, allowing test data categories to influence the encoding.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that includes test data information from encoding.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
151,151,151.0,Categorical Encoding,Nominal data,OneHotEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['parental level of education', 'math score']]
3 
4 X = df[['parental level of education']]
5 y = df['math score']
6 
7 from sklearn.linear_model import LinearRegression
8 encoder = OneHotEncoder(sparse=False)
9 X_encoded = encoder.fit_transform(X)  # ‚ùå Categories from full data
10 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
11 
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 encoder = OneHotEncoder(sparse=False)
4 X_train_encoded = encoder.fit_transform(X_train_raw)
5 X_test_encoded = encoder.transform(X_test_raw)
6 
7 model = LinearRegression()
8 model.fit(X_train_encoded, y_train)
9 print(model.score(X_test_encoded, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""OneHotEncoder is applied to the full dataset before splitting it into train and test sets, causing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data categories to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been encoded.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
152,152,152.0,Categorical Encoding,Nominal data,get_dummies,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå Dummies created before split ‚Äî test categories influence training
5 df_encoded = pd.get_dummies(df, columns=['Embarked'])
6 
7 X = df_encoded.drop('Survived', axis=1)
8 y = df_encoded['Survived']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 X_train = pd.get_dummies(X_train_raw, columns=['Embarked'])
6 X_test = pd.get_dummies(X_test_raw, columns=['Embarked'])
7 
8 # ‚úÖ Align columns to handle any mismatch
9 X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Dummies created before split ‚Äî test categories influence training""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data categories to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been encoded.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
153,153,153.0,Categorical Encoding,Nominal data,get_dummies,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 # ‚ùå Full-data dummies ‚Äî test values leak into training
6 df_encoded = pd.get_dummies(df, columns=['Education'])
7 
8 X = df_encoded.drop('Loan_Status', axis=1)
9 y = df_encoded['Loan_Status']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
11 
12 from sklearn.tree import DecisionTreeClassifier
13 model = DecisionTreeClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 X_train = pd.get_dummies(X_train_raw, columns=['Education'])
6 X_test = pd.get_dummies(X_test_raw, columns=['Education'])
7 
8 X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)
9 
10 model = DecisionTreeClassifier()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Full-data dummies are created and stored before train-test split, causing test values to leak into training""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data due to prior encoding.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
154,154,154.0,Categorical Encoding,Nominal data,get_dummies,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['cp', 'thalach', 'target']]
3 
4 # ‚ùå Dummies before split = leakage
5 df_encoded = pd.get_dummies(df, columns=['cp'])
6 
7 X = df_encoded.drop('target', axis=1)
8 y = df_encoded['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.svm import SVC
12 model = SVC()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['cp', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 X_train = pd.get_dummies(X_train_raw, columns=['cp'])
6 X_test = pd.get_dummies(X_test_raw, columns=['cp'])
7 
8 X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)
9 
10 model = SVC()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""One-hot encoding applied to the full dataset before split""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""One-hot encoding is applied to the full dataset before train-test split, allowing test data information to influence the training process.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been one-hot encoded, which means the encoding was influenced by the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that was influenced by the test data during encoding.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during encoding.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
155,155,155.0,Categorical Encoding,Nominal data,get_dummies,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['race/ethnicity', 'math score']]
3 
4 # ‚ùå Dummy encoding before split = test data influences columns
5 df_encoded = pd.get_dummies(df, columns=['race/ethnicity'])
6 
7 X = df_encoded.drop('math score', axis=1)
8 y = df_encoded['math score']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 X_train = pd.get_dummies(X_train_raw, columns=['race/ethnicity'])
6 X_test = pd.get_dummies(X_test_raw, columns=['race/ethnicity'])
7 
8 X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)
9 
10 model = LinearRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Dummy encoding applied to the full dataset before splitting, affecting test data columns.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Dummy encoding is applied to the full dataset before train-test split, allowing test data to influence the encoding process.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been encoded, which means the test data influenced the encoding.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that was influenced by the test data during encoding.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding process applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
156,156,156.0,Categorical Encoding,Nominal data,LabelEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Sex', 'Fare', 'Survived']].dropna()
3 
4 # ‚ùå LabelEncoder sees the whole dataset ‚Äî test labels influence encoding
5 le = LabelEncoder()
6 df['Sex'] = le.fit_transform(df['Sex'])  # LEAKAGE: uses both train and test data
7 
8 X = df[['Sex', 'Fare']]
9 y = df['Survived']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Sex', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 le = LabelEncoder()
6 X_train['Sex'] = le.fit_transform(X_train['Sex'])
7 X_test['Sex'] = le.transform(X_test['Sex'])  # ‚úÖ Transform test set based on train labels only
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""LabelEncoder sees the whole dataset ‚Äî test labels influence encoding""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Label encoding is applied to the entire dataset before the train-test split, allowing test data to influence the encoding.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the data has already been label encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes label encoding influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the label encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
157,157,157.0,Categorical Encoding,Nominal data,LabelEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Married', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 le = LabelEncoder()
6 df['Married'] = le.fit_transform(df['Married'])  # ‚ùå Applied before split
7 
8 X = df[['Married', 'LoanAmount']]
9 y = df['Loan_Status']
10 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
11 
12 from sklearn.tree import DecisionTreeClassifier
13 model = DecisionTreeClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Married', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 le = LabelEncoder()
6 X_train['Married'] = le.fit_transform(X_train['Married'])
7 X_test['Married'] = le.transform(X_test['Married'])
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""LabelEncoder is applied to the full dataset before the train-test split.""},
            {""line_number"": 6, ""explanation"": ""The encoded 'Married' feature is assigned to the full dataset before the train-test split.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Label encoding is applied to the 'Married' column before the train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the label encoding applied before the split.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the label encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
158,158,158.0,Categorical Encoding,Nominal data,LabelEncoder,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['thal', 'age', 'target']].dropna()
3 
4 le = LabelEncoder()
5 df['thal'] = le.fit_transform(df['thal'])  # ‚ùå Includes test categories in mapping
6 
7 X = df[['thal', 'age']]
8 y = df['target']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
10 
11 from sklearn.svm import SVC
12 model = SVC()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 le = LabelEncoder()
6 X_train['thal'] = le.fit_transform(X_train['thal'])
7 X_test['thal'] = le.transform(X_test['thal'])
8 
9 model = SVC()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""LabelEncoder fit is performed on the entire dataset, including test data, which can lead to preprocessing leakage as test labels are included in the mapping""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Label encoding is applied to the full dataset before train-test split, allowing test data categories to influence the encoding.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
159,159,159.0,Categorical Encoding,Nominal data,LabelEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['gender', 'reading score']]
3 
4 le = LabelEncoder()
5 df['gender'] = le.fit_transform(df['gender'])  # ‚ùå Leakage: fit on entire dataset
6 
7 X = df[['gender']]
8 y = df['reading score']
9 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
10 
11 from sklearn.linear_model import LinearRegression
12 model = LinearRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['gender']]
2 y = df['reading score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 le = LabelEncoder()
6 X_train['gender'] = le.fit_transform(X_train['gender'])
7 X_test['gender'] = le.transform(X_test['gender'])
8 
9 model = LinearRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 4, ""explanation"": ""LabelEncoder's fit method is called on the entire dataset, encoding the labels before the split.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Label encoding is applied to the entire dataset before the train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the label encoding.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the label encoding.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
160,160,160.0,Categorical Encoding,Nominal data,CountFrequencyEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Count encoder fit on full dataset ‚Äî test data affects counts
8 encoder = CountFrequencyEncoder(encoding_method='count', variables=['Embarked'])
9 X_encoded = encoder.fit_transform(X)  # Leakage
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 encoder = CountFrequencyEncoder(encoding_method='count', variables=['Embarked'])
4 X_train_encoded = encoder.fit_transform(X_train)
5 X_test_encoded = encoder.transform(X_test)
6 
7 model = LogisticRegression()
8 model.fit(X_train_encoded, y_train)
9 print(model.score(X_test_encoded, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""CountFrequencyEncoder fit on full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
161,161,161.0,Categorical Encoding,Nominal data,CountFrequencyEncoder,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['Neighborhood', 'GrLivArea', 'SalePrice']].dropna()
3 
4 X = df[['Neighborhood', 'GrLivArea']]
5 y = df['SalePrice']
6 
7 from feature_engine.encoding import CountFrequencyEncoder
8 encoder = CountFrequencyEncoder(encoding_method='frequency', variables=['Neighborhood'])
9 
10 # ‚ùå Fit before split ‚Äî includes test frequencies
11 X_encoded = encoder.fit_transform(X)
12 
13 from sklearn.model_selection import train_test_split
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
15 
16 from sklearn.linear_model import Ridge
17 model = Ridge()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
2 
3 encoder = CountFrequencyEncoder(encoding_method='frequency', variables=['Neighborhood'])
4 X_train_encoded = encoder.fit_transform(X_train)
5 X_test_encoded = encoder.transform(X_test)
6 
7 model = Ridge()
8 model.fit(X_train_encoded, y_train)
9 print(model.score(X_test_encoded, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 11, ""explanation"": ""CountFrequencyEncoder is fit on the entire dataset before splitting it into train and test sets, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 11,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data frequencies to influence training.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
162,162,162.0,Categorical Encoding,Nominal data,CountFrequencyEncoder,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['cp', 'thalach', 'target']]
3 
4 X = df[['cp', 'thalach']]
5 y = df['target']
6 
7 from feature_engine.encoding import CountFrequencyEncoder
8 encoder = CountFrequencyEncoder(encoding_method='count', variables=['cp'])
9 
10 # ‚ùå Test values influence frequency mapping
11 X_encoded = encoder.fit_transform(X)
12 
13 from sklearn.model_selection import train_test_split
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
15 
16 from sklearn.ensemble import RandomForestClassifier
17 model = RandomForestClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 encoder = CountFrequencyEncoder(encoding_method='count', variables=['cp'])
4 X_train_encoded = encoder.fit_transform(X_train)
5 X_test_encoded = encoder.transform(X_test)
6 
7 model = RandomForestClassifier()
8 model.fit(X_train_encoded, y_train)
9 print(model.score(X_test_encoded, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 11, ""explanation"": ""CountFrequencyEncoder is applied to the entire dataset (X) before the train-test split, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 11,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data frequency to influence the encoding of training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded with test data information.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
163,163,163.0,Categorical Encoding,Nominal data,CountFrequencyEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['race/ethnicity', 'math score']]
3 
4 X = df[['race/ethnicity']]
5 y = df['math score']
6 
7 from feature_engine.encoding import CountFrequencyEncoder
8 encoder = CountFrequencyEncoder(encoding_method='frequency', variables=['race/ethnicity'])
9 
10 # ‚ùå Fit before split ‚Äî test data skews frequency
11 X_encoded = encoder.fit_transform(X)
12 
13 from sklearn.model_selection import train_test_split
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
15 
16 from sklearn.linear_model import LinearRegression
17 model = LinearRegression()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 encoder = CountFrequencyEncoder(encoding_method='frequency', variables=['race/ethnicity'])
4 X_train_encoded = encoder.fit_transform(X_train)
5 X_test_encoded = encoder.transform(X_test)
6 
7 model = LinearRegression()
8 model.fit(X_train_encoded, y_train)
9 print(model.score(X_test_encoded, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 11, ""explanation"": ""Fitting the encoder on the full dataset before splitting leads to preprocessing leakage as the encoded features in X_train and X_test are not identical due to the skewed frequencies in the test set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 11,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data frequency to influence training.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded with test data information.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
164,164,164.0,Categorical Encoding,Nominal data,RareLabelEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Applied before split ‚Äî test categories influence grouping
8 encoder = RareLabelEncoder(tol=0.05, n_categories=4, variables=['Embarked'])
9 X_encoded = encoder.fit_transform(X)  # LEAKAGE
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 encoder = RareLabelEncoder(tol=0.05, n_categories=4, variables=['Embarked'])
4 X_train = encoder.fit_transform(X_train_raw)
5 X_test = encoder.transform(X_test_raw)
6 
7 model = LogisticRegression()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 9, ""explanation"": ""RareLabelEncoder is applied to the entire dataset before train-test split, causing preprocessing leakage.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data categories to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded, leading to leakage.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
165,165,165.0,Categorical Encoding,Nominal data,RareLabelEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Property_Area', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Property_Area', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 from feature_engine.encoding import RareLabelEncoder
9 encoder = RareLabelEncoder(tol=0.05, n_categories=3, variables=['Property_Area'])
10 
11 # ‚ùå Rare labels encoded across full dataset
12 X_encoded = encoder.fit_transform(X)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
15 
16 from sklearn.tree import DecisionTreeClassifier
17 model = DecisionTreeClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 encoder = RareLabelEncoder(tol=0.05, n_categories=3, variables=['Property_Area'])
4 X_train = encoder.fit_transform(X_train_raw)
5 X_test = encoder.transform(X_test_raw)
6 
7 model = DecisionTreeClassifier()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 11, ""explanation"": ""Rare labels encoded across full dataset, which can lead to information leakage during training.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""RareLabelEncoder is applied to the full dataset before train-test split, allowing test data statistics to influence the encoding of the training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded, leading to potential data leakage.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data that has been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been encoded using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
166,166,166.0,Categorical Encoding,Nominal data,RareLabelEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 from feature_engine.encoding import RareLabelEncoder
6 encoder = RareLabelEncoder(tol=0.1, variables=['thal'])
7 
8 # ‚ùå Includes all data ‚Äî test frequencies affect training encoding
9 X_encoded = encoder.fit_transform(X)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
13 
14 from sklearn.ensemble import RandomForestClassifier
15 model = RandomForestClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
2 
3 encoder = RareLabelEncoder(tol=0.1, variables=['thal'])
4 X_train = encoder.fit_transform(X_train_raw)
5 X_test = encoder.transform(X_test_raw)
6 
7 model = RandomForestClassifier()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""RareLabelEncoder is fit on the entire dataset X, which includes test data, leading to leakage.""},
            {""line_number"": 12, ""explanation"": ""train_test_split is not applied to the encoded data X_encoded, causing overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""RareLabelEncoder is fit on the entire dataset before the train-test split, allowing test data frequencies to influence the encoding applied to the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
167,167,167.0,Categorical Encoding,Nominal data,RareLabelEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['parental level of education']]
3 y = df['math score']
4 
5 from feature_engine.encoding import RareLabelEncoder
6 encoder = RareLabelEncoder(tol=0.05, variables=['parental level of education'])
7 
8 # ‚ùå Fit before split ‚Äî full data impacts what's considered ""rare""
9 X_encoded = encoder.fit_transform(X)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.linear_model import LinearRegression
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
2 
3 encoder = RareLabelEncoder(tol=0.05, variables=['parental level of education'])
4 X_train = encoder.fit_transform(X_train_raw)
5 X_test = encoder.transform(X_test_raw)
6 
7 model = LinearRegression()
8 model.fit(X_train, y_train)
9 print(model.score(X_test, y_test))
10 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""RareLabelEncoder is fit on the full dataset, which can result in different encodings for the training and test sets due to different distributions of rare labels in each set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""RareLabelEncoder is fit on the entire dataset before the train-test split, causing the encoding to be influenced by the test data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the data has already been encoded, leading to data leakage.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
168,168,168.0,Categorical Encoding,Nominal data,DecisionTreeEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Fit encoder on full dataset ‚Äî test labels influence encoding
8 encoder = DecisionTreeEncoder(variables=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)  # LEAKAGE here
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = DecisionTreeEncoder(variables=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
"," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 9, ""explanation"": ""Encoder is fit on the full dataset with both features and target, leading to overlap leakage as the encoded features are used for train-test split""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been encoded with test data information.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been encoded with training data information.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
169,169,169.0,Categorical Encoding,Nominal data,DecisionTreeEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 from feature_engine.encoding import DecisionTreeEncoder
9 encoder = DecisionTreeEncoder(variables=['Education'])
10 
11 # ‚ùå Encoder fit on entire dataset ‚Äî test target used during training
12 X_encoded = encoder.fit_transform(X, y)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
15 
16 from sklearn.tree import DecisionTreeClassifier
17 model = DecisionTreeClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = DecisionTreeEncoder(variables=['Education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 12, ""explanation"": ""Encoder fit on entire dataset before splitting, which is a preprocessing leakage as it uses target information during training.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the training process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
170,170,170.0,Categorical Encoding,Nominal data,DecisionTreeEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 from feature_engine.encoding import DecisionTreeEncoder
6 encoder = DecisionTreeEncoder(variables=['thal'])
7 
8 # ‚ùå Test labels included in fit
9 X_encoded = encoder.fit_transform(X, y)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
13 
14 from sklearn.ensemble import RandomForestClassifier
15 model = RandomForestClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = DecisionTreeEncoder(variables=['thal'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""DecisionTreeEncoder is fit on the full dataset with target labels, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data to influence the encoding process.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been encoded with test data included.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
171,171,171.0,Categorical Encoding,Nominal data,DecisionTreeEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['parental level of education']]
3 y = df['math score']
4 
5 from feature_engine.encoding import DecisionTreeEncoder
6 encoder = DecisionTreeEncoder(variables=['parental level of education'])
7 
8 # ‚ùå All data used in fitting ‚Äî test info leaks
9 X_encoded = encoder.fit_transform(X, y)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.linear_model import LinearRegression
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['parental level of education']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = DecisionTreeEncoder(variables=['parental level of education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""DecisionTreeEncoder fit_transform method applies encoding to the full dataset, including test data, before train-test split. This is an example of preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been encoded, meaning the test data was used in the encoding process.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding process applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
172,172,172.0,Categorical Encoding,Nominal data,CatBoostEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Sex', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Sex', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Encoder fit on the entire dataset ‚Äî test target influences encoding
8 encoder = CatBoostEncoder(cols=['Sex'])
9 X_encoded = encoder.fit_transform(X, y)  # LEAKAGE
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Sex', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = CatBoostEncoder(cols=['Sex'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 9, ""explanation"": ""Encoder fit on the entire dataset, y is passed as argument, leading to target leakage in encoding process.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test target information to influence the encoding of the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with leakage from the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the encoding process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
173,173,173.0,Categorical Encoding,Nominal data,CatBoostEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Married', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Married', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 from category_encoders import CatBoostEncoder
9 encoder = CatBoostEncoder(cols=['Married'])
10 
11 # ‚ùå Fit on full data ‚Äî test labels influence transformation
12 X_encoded = encoder.fit_transform(X, y)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
15 
16 from sklearn.tree import DecisionTreeClassifier
17 model = DecisionTreeClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X = df[['Married', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = CatBoostEncoder(cols=['Married'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 12, ""explanation"": ""CatBoostEncoder is fit on the entire dataset including test labels, which can lead to information leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data labels to influence the transformation.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during encoding.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
174,174,174.0,Categorical Encoding,Nominal data,CatBoostEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['cp', 'thalach']]
3 y = df['target']
4 
5 from category_encoders import CatBoostEncoder
6 encoder = CatBoostEncoder(cols=['cp'])
7 
8 # ‚ùå Fit on entire dataset ‚Äî leakage
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 from sklearn.ensemble import RandomForestClassifier
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['cp', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = CatBoostEncoder(cols=['cp'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""CatBoostEncoder is fit on the entire dataset, including test data, causing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded, which means the training data has been contaminated with information from the test data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data, which has been influenced by the test data due to prior encoding.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the encoding applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
175,175,175.0,Categorical Encoding,Nominal data,CatBoostEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['parental level of education']]
3 y = df['math score']
4 
5 from category_encoders import CatBoostEncoder
6 encoder = CatBoostEncoder(cols=['parental level of education'])
7 
8 # ‚ùå Fit before split = test leakage
9 X_encoded = encoder.fit_transform(X, y)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.linear_model import LinearRegression
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['parental level of education']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = CatBoostEncoder(cols=['parental level of education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Fitting the encoder on the full dataset (X, y) is test leakage as the encoded features are used for both training and testing.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been encoded, which means the test data has influenced the encoding process.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the encoding process.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
176,176,176.0,Categorical Encoding,Nominal data,CountEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå CountEncoder fitted on entire dataset ‚Äî test data influences counts
8 encoder = CountEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = CountEncoder(cols=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""CountEncoder fitted on entire dataset ‚Äî test data influences counts""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""CountEncoder is fitted on the entire dataset before the train-test split, allowing test data statistics to influence the encoding of the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
177,177,177.0,Categorical Encoding,Nominal data,CountEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 from category_encoders import CountEncoder
9 encoder = CountEncoder(cols=['Education'])
10 
11 # ‚ùå Fitted before split ‚Äî introduces leakage
12 X_encoded = encoder.fit_transform(X)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
15 
16 from sklearn.tree import DecisionTreeClassifier
17 model = DecisionTreeClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = CountEncoder(cols=['Education'])
6 X_train_encoded = encoder.fit_transform(X_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 12, ""explanation"": ""CountEncoder is fitted on the entire dataset before splitting it into train and test sets, which introduces preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
178,178,178.0,Categorical Encoding,Nominal data,CountEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 from category_encoders import CountEncoder
6 encoder = CountEncoder(cols=['thal'])
7 
8 # ‚ùå CountEncoder fit on full data ‚Äî test frequencies leak
9 X_encoded = encoder.fit_transform(X)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.ensemble import RandomForestClassifier
15 model = RandomForestClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = CountEncoder(cols=['thal'])
6 X_train_encoded = encoder.fit_transform(X_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""CountEncoder fit on full data ‚Äî test frequencies leak""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""CountEncoder is fit on the entire dataset before the train-test split, causing test data frequencies to influence the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after encoding, meaning the test data has already influenced the encoding applied to the training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the encoding step applied before the train-test split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
179,179,179.0,Categorical Encoding,Nominal data,CountEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 from category_encoders import CountEncoder
6 encoder = CountEncoder(cols=['race/ethnicity'])
7 
8 # ‚ùå Fit before split ‚Äî test influences frequency mapping
9 X_encoded = encoder.fit_transform(X)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.linear_model import LinearRegression
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = CountEncoder(cols=['race/ethnicity'])
6 X_train_encoded = encoder.fit_transform(X_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Fitting CountEncoder on the entire dataset before splitting leads to preprocessing leakage, as the encoding will depend on the entire dataset.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data to influence the frequency mapping used in training.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been encoded, using information from the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
180,180,180.0,Categorical Encoding,Nominal data,GLMMEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå GLMMEncoder fit on entire dataset ‚Äî leakage: test targets influence encoding
8 encoder = GLMMEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = GLMMEncoder(cols=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""GLMMEncoder fit on entire dataset ‚Äî leakage: test targets influence encoding""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""GLMMEncoder is fit on the entire dataset, including the test set, causing data leakage as test target information influences the encoding.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded using information from the entire dataset, including the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the training data that has been contaminated by the leakage from the encoding step.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by the leakage from the encoding step.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
181,181,181.0,Categorical Encoding,Nominal data,GLMMEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Married', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Married', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 from category_encoders.glmm import GLMMEncoder
9 encoder = GLMMEncoder(cols=['Married'])
10 
11 # ‚ùå Test set contributes to encoding
12 X_encoded = encoder.fit_transform(X, y)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
15 
16 from sklearn.tree import DecisionTreeClassifier
17 model = DecisionTreeClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X = df[['Married', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = GLMMEncoder(cols=['Married'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 12, ""explanation"": ""Test set contributes to encoding by being included in the fit_transform function call.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""Encoding is applied to the entire dataset before train-test split, allowing test data to influence the encoding process.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after data has already been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the training data that has been contaminated by test data through the encoding process.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the test data that was used in the encoding process, leading to data leakage.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
182,182,182.0,Categorical Encoding,Nominal data,GLMMEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['cp', 'thalach']]
3 y = df['target']
4 
5 from category_encoders.glmm import GLMMEncoder
6 encoder = GLMMEncoder(cols=['cp'])
7 
8 # ‚ùå Encoding reflects test target distribution
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 from sklearn.ensemble import RandomForestClassifier
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['cp', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = GLMMEncoder(cols=['cp'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""GLMMEncoder is applied to the full dataset, including test data, causing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test target distribution to influence the encoding of the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that has been encoded with test set information.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been encoded with its own target information.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
183,183,183.0,Categorical Encoding,Nominal data,GLMMEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 encoder = GLMMEncoder(cols=['race/ethnicity'])
6 
7 # ‚ùå Fit on full data ‚Äî test labels influence encoding
8 X_encoded = encoder.fit_transform(X, y)
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
12 
13 from sklearn.linear_model import LinearRegression
14 model = LinearRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = GLMMEncoder(cols=['race/ethnicity'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Fitting the encoder on the full dataset with target variable, causing preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test labels to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with test data information.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
184,184,184.0,Categorical Encoding,Nominal data,JamesSteinEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Fitting encoder on full dataset ‚Äî test target influences encoding
8 encoder = JamesSteinEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = JamesSteinEncoder(cols=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Fitting encoder on full dataset, test target influences encoding""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test target information to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
185,185,185.0,Categorical Encoding,Nominal data,JamesSteinEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 encoder = JamesSteinEncoder(cols=['Education'])
9 # ‚ùå Fit before split = test set contributes to target mean calculations
10 X_encoded = encoder.fit_transform(X, y)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
13 
14 from sklearn.tree import DecisionTreeClassifier
15 model = DecisionTreeClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = JamesSteinEncoder(cols=['Education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""Fitting the encoder on the full dataset before splitting leads to overlap leakage as the target information is used in the encoding process.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data to influence the encoding process.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding process.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
186,186,186.0,Categorical Encoding,Nominal data,JamesSteinEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 encoder = JamesSteinEncoder(cols=['thal'])
6 
7 # ‚ùå Fit on full dataset ‚Äî leakage occurs
8 X_encoded = encoder.fit_transform(X, y)
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
12 
13 from sklearn.ensemble import RandomForestClassifier
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = JamesSteinEncoder(cols=['thal'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Encoder is fit on full dataset, which includes test data, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with leakage.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
187,187,187.0,Categorical Encoding,Nominal data,JamesSteinEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 encoder = JamesSteinEncoder(cols=['race/ethnicity'])
6 # ‚ùå Applied before split ‚Äî test set influences encoded values
7 X_encoded = encoder.fit_transform(X, y)
8 
9 from sklearn.model_selection import train_test_split
10 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
11 
12 from sklearn.linear_model import LinearRegression
13 model = LinearRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = JamesSteinEncoder(cols=['race/ethnicity'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""JamesSteinEncoder is applied to the full dataset (X), including test data, before train-test split. This results in the encoded test data being influenced by the target variable (y). This is an example of preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data to influence the encoded values.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the encoding step applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
188,188,188.0,Categorical Encoding,Nominal data,LeaveOneOutEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Fitting encoder before splitting causes leakage
8 encoder = LeaveOneOutEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)  # Test targets leak into training
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = LeaveOneOutEncoder(cols=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Fitting encoder on the entire dataset before splitting causes leakage by exposing test data to the model during training""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""LeaveOneOutEncoder is fitted on the entire dataset before the train-test split, causing target leakage as test data statistics influence the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with leakage from the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during encoding.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
189,189,189.0,Categorical Encoding,Nominal data,LeaveOneOutEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 from category_encoders import LeaveOneOutEncoder
9 encoder = LeaveOneOutEncoder(cols=['Education'])
10 
11 # ‚ùå Target mean per category includes future/test information
12 X_encoded = encoder.fit_transform(X, y)
13 
14 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
15 
16 from sklearn.tree import DecisionTreeClassifier
17 model = DecisionTreeClassifier()
18 model.fit(X_train, y_train)
19 print(model.score(X_test, y_test))
20 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = LeaveOneOutEncoder(cols=['Education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 12, ""explanation"": ""LeaveOneOutEncoder is applied to the entire dataset including test data, which leaks information from the target variable to the encoding process.""},
            {""line_number"": 14, ""explanation"": ""The data is split, but the encoded data is not. As a result, the test set is still contaminated with the target information.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 12,
      ""explanation"": ""LeaveOneOutEncoder is applied to the entire dataset before train-test split, causing target leakage as it uses the target variable to encode features.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after encoding, meaning the test data has influenced the encoding applied to the training data.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is trained on the training data that has been contaminated by target leakage from the encoding step.""
    },
    {
      ""line_number"": 19,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by target leakage from the encoding step.""
    }
  ]
}
","[Training method: fit, Training line: 18]  
[Testing method: score, Testing line: 19]"
190,190,190.0,Categorical Encoding,Nominal data,LeaveOneOutEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 encoder = LeaveOneOutEncoder(cols=['thal'])
6 
7 # ‚ùå Encoding uses whole y, including test labels
8 X_encoded = encoder.fit_transform(X, y)
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
12 
13 from sklearn.ensemble import RandomForestClassifier
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = LeaveOneOutEncoder(cols=['thal'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Encoding uses whole y, including test labels (preprocessing leakage)""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the entire dataset before train-test split, using the target variable 'y', which includes test labels. This causes data leakage as the test data influences the transformation.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through the encoding process.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to an overestimation of the model's performance.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
191,191,191.0,Categorical Encoding,Nominal data,LeaveOneOutEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 encoder = LeaveOneOutEncoder(cols=['race/ethnicity'])
6 
7 # ‚ùå Entire target vector used ‚Äî test influence contaminates encoding
8 X_encoded = encoder.fit_transform(X, y)
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
12 
13 from sklearn.linear_model import LinearRegression
14 model = LinearRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = LeaveOneOutEncoder(cols=['race/ethnicity'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""The entire target vector 'y' is used for encoding, causing test data to influence the encoding process.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset using the entire target vector before train-test split, allowing test data information to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with leakage from the target variable.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that has been encoded with information from the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding process using the entire target vector.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
192,192,192.0,Categorical Encoding,Nominal data,MEstimateEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Fit encoder before splitting ‚Äî leakage from test target into training
8 encoder = MEstimateEncoder(cols=['Embarked'], m=2)
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = MEstimateEncoder(cols=['Embarked'], m=2)
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Encoder is fit on the full dataset, including test data, which can lead to leakage of test target information into the training data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
193,193,193.0,Categorical Encoding,Nominal data,MEstimateEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Married', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Married', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 encoder = MEstimateEncoder(cols=['Married'], m=1)
9 
10 # ‚ùå Fitting before split ‚Äî test labels used in encoding
11 X_encoded = encoder.fit_transform(X, y)
12 
13 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
14 
15 from sklearn.tree import DecisionTreeClassifier
16 model = DecisionTreeClassifier()
17 model.fit(X_train, y_train)
18 print(model.score(X_test, y_test))
19 ","1 X = df[['Married', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = MEstimateEncoder(cols=['Married'], m=1)
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 11, ""explanation"": ""Fitting the estimator (encoder) on the full dataset, including test labels, before splitting.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 11,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data labels to influence the encoding process.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 18,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 17]  
[Testing method: score, Testing line: 18]"
194,194,194.0,Categorical Encoding,Nominal data,MEstimateEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 encoder = MEstimateEncoder(cols=['thal'], m=3)
6 
7 # ‚ùå Fit before splitting ‚Äî test targets influence encoded values
8 X_encoded = encoder.fit_transform(X, y)
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 from sklearn.ensemble import RandomForestClassifier
14 model = RandomForestClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = MEstimateEncoder(cols=['thal'], m=3)
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Fitting the encoder on the full dataset with target information, which can lead to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test target information to influence the transformation.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during encoding.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
195,195,195.0,Categorical Encoding,Nominal data,MEstimateEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 encoder = MEstimateEncoder(cols=['race/ethnicity'], m=2)
6 
7 # ‚ùå Entire y vector used before split ‚Äî this introduces leakage
8 X_encoded = encoder.fit_transform(X, y)
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
12 
13 from sklearn.linear_model import LinearRegression
14 model = LinearRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = MEstimateEncoder(cols=['race/ethnicity'], m=2)
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""The entire y vector is used in the fit_transform() method, which introduces preprocessing leakage by encoding the full dataset before splitting it into train and test sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, using the entire y vector, which allows information from the test set to influence the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with leakage from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test set.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to potentially inflated performance metrics.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
196,196,196.0,Categorical Encoding,Nominal data,StringLookup,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Fit the StringLookup layer on full dataset ‚Äî leakage: test categories inform vocab
8 lookup = tf.keras.layers.StringLookup()
9 lookup.adapt(X['Embarked'])  # This includes test data
10 
11 X['Embarked_encoded'] = lookup(X['Embarked'])
12 
13 X_train, X_test, y_train, y_test = train_test_split(X[['Embarked_encoded', 'Fare']], y, test_size=0.2)
14 
15 # This encoded training data is used in model fitting, and the test data in evaluation ‚Äî leakage!
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['Embarked'])  # ‚úÖ Only training data used to build vocab
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['Embarked_encoded'] = lookup(X_train_raw['Embarked'])
11 X_test['Embarked_encoded'] = lookup(X_test_raw['Embarked'])
12 
13 # Now this is safe: training and testing are encoded with no leakage
14 "," model = tf.keras.Sequential([
        tf.keras.layers.Dense(64, activation='relu'),
        lookup,
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
17 
18 model.compile(loss='binary_crossent', optimizer='adam', metrics=['accuracy'])
19 
20 # Fit the model on the encoded training data
21 model.fit(X_train, y_train, epochs=100, verbose=0)
22 
23 # Evaluate the model on the encoded test data
24 scores = model.evaluate(X_test, y_test, verbose=0)
25 
26 print('Test loss:', scores[0])
27 print('Test accuracy:', scores[1])"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""The StringLookup layer is adapted on the entire dataset, including the test data, causing data leakage as test data categories influence the encoding.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after the StringLookup layer has been adapted on the full dataset, meaning the test data has already influenced the encoding.""
    }
  ]
}
","[Training method: adapt, Training line: 9]  
[Testing method: None, Testing line: None]"
197,197,197.0,Categorical Encoding,Nominal data,StringLookup,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 lookup = tf.keras.layers.StringLookup()
9 lookup.adapt(X['Education'])  # ‚ùå Leak: full target-aware transformation
10 
11 X['Education_encoded'] = lookup(X['Education'])
12 
13 X_train, X_test, y_train, y_test = train_test_split(X[['Education_encoded', 'LoanAmount']], y, test_size=0.3)
14 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['Education'])  # ‚úÖ Fit vocab only on training
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['Education_encoded'] = lookup(X_train_raw['Education'])
11 X_test['Education_encoded'] = lookup(X_test_raw['Education'])
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""tf.keras.layers.StringLookup is applied to the full dataset, which includes target information, before the train-test split.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""StringLookup is adapted on the entire dataset before train-test split, allowing test data to influence the encoding.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after the StringLookup has been adapted on the full dataset, leading to data leakage.""
    }
  ]
}
","[Training method: adapt, Training line: 9]  
[Testing method: None, Testing line: None]"
198,198,198.0,Categorical Encoding,Nominal data,StringLookup,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X['thal'])  # ‚ùå Includes both train and test values
7 
8 X['thal_encoded'] = lookup(X['thal'])
9 
10 X_train, X_test, y_train, y_test = train_test_split(X[['thal_encoded', 'age']], y, test_size=0.25)
11 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['thal'])  # ‚úÖ Training-only adaptation
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['thal_encoded'] = lookup(X_train_raw['thal'])
11 X_test['thal_encoded'] = lookup(X_test_raw['thal'])
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StringLookup is applied to the full dataset before the train-test split, causing preprocessing leakage by encoding both train and test data together.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""StringLookup is adapted on the entire dataset before train-test split, causing the encoding to be influenced by the test data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before the train-test split, leading to data leakage.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after the data has already been encoded using information from the entire dataset.""
    }
  ]
}
",There is no training or testing method call in the provided snippet.
199,199,199.0,Categorical Encoding,Nominal data,StringLookup,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X['race/ethnicity'])  # ‚ùå All categories seen before splitting
7 
8 X['race_encoded'] = lookup(X['race/ethnicity'])
9 
10 X_train, X_test, y_train, y_test = train_test_split(X[['race_encoded']], y, test_size=0.3)
11 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['race/ethnicity'])  # ‚úÖ Only use training to build vocab
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['race_encoded'] = lookup(X_train_raw['race/ethnicity'])
11 X_test['race_encoded'] = lookup(X_test_raw['race/ethnicity'])
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StringLookup is applied to the full dataset before splitting, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""StringLookup is adapted on the entire dataset before train-test split, allowing test data categories to influence the encoding.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, leading to data leakage.""
    }
  ]
}
","[Training method: adapt, Training line: 6]  
[Testing method: None, Testing line: None]"
200,200,200.0,Categorical Encoding,Nominal data,IntegerLookup,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Vocabulary adapted on full data ‚Äî test set categories influence training encoding
8 lookup = tf.keras.layers.StringLookup(output_mode='int')
9 lookup.adapt(X['Embarked'])
10 
11 X['Embarked_encoded'] = lookup(X['Embarked'])
12 
13 X_train, X_test, y_train, y_test = train_test_split(X[['Embarked_encoded', 'Fare']], y, test_size=0.2)
14 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 lookup = tf.keras.layers.StringLookup(output_mode='int')
6 lookup.adapt(X_train_raw['Embarked'])  # ‚úÖ Only fit on training data
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['Embarked_encoded'] = lookup(X_train_raw['Embarked'])
11 X_test['Embarked_encoded'] = lookup(X_test_raw['Embarked'])
12 "," ""leakage_detected"": true,
    ""leakage_lines"": [
        {""line_number"": 8, ""explanation"": ""StringLookup adapts to the full dataset, which includes test data, causing leakage.""}
    ]
}"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""StringLookup is adapted on the full dataset before train-test split, allowing test data categories to influence the encoding used during training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, leading to potential data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    }
  ]
}
","[Training method: adapt, Training line: 9]  
[Testing method: None, Testing line: None]"
201,201,201.0,Categorical Encoding,Nominal data,IntegerLookup,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Married', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Married', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 lookup = tf.keras.layers.StringLookup(output_mode='int')
9 lookup.adapt(X['Married'])  # ‚ùå Test data seen during vocabulary construction
10 
11 X['Married_encoded'] = lookup(X['Married'])
12 
13 X_train, X_test, y_train, y_test = train_test_split(X[['Married_encoded', 'LoanAmount']], y, test_size=0.3)
","1 X = df[['Married', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lookup = tf.keras.layers.StringLookup(output_mode='int')
6 lookup.adapt(X_train_raw['Married'])  # ‚úÖ Adapt using training set only
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['Married_encoded'] = lookup(X_train_raw['Married'])
11 X_test['Married_encoded'] = lookup(X_test_raw['Married'])
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""StringLookup is called on the full dataset, including test data, during vocabulary construction, leading to overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""StringLookup is adapted on the entire dataset before train-test split, allowing test data to influence the encoding.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Train-test split is performed after the StringLookup has been adapted on the full dataset, leading to data leakage.""
    }
  ]
}
","[Training method: adapt, Training line: 9]  
[Testing method: None, Testing line: None]"
202,202,202.0,Categorical Encoding,Nominal data,IntegerLookup,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 lookup = tf.keras.layers.StringLookup(output_mode='int')
6 lookup.adapt(X['thal'])  # ‚ùå Includes test data in vocab building
7 
8 X['thal_encoded'] = lookup(X['thal'])
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X[['thal_encoded', 'age']], y, test_size=0.3)
12 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lookup = tf.keras.layers.StringLookup(output_mode='int')
6 lookup.adapt(X_train_raw['thal'])  # ‚úÖ Fit only on training categories
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['thal_encoded'] = lookup(X_train_raw['thal'])
11 X_test['thal_encoded'] = lookup(X_test_raw['thal'])
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StringLookup builds vocabulary from the entire dataset, including test data, which can lead to leakage of information from test data into the model.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""StringLookup is adapted on the entire dataset before the train-test split, causing the test data to influence the encoding.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the StringLookup has been adapted on the full dataset, leading to data leakage.""
    }
  ]
}
","I'm sorry, but the provided code snippet does not contain any training or testing method calls. Please provide a complete code snippet that includes the model training and evaluation steps."
203,203,203.0,Categorical Encoding,Nominal data,IntegerLookup,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 lookup = tf.keras.layers.StringLookup(output_mode='int')
6 lookup.adapt(X['race/ethnicity'])  # ‚ùå Includes test data in vocabulary
7 
8 X['race_encoded'] = lookup(X['race/ethnicity'])
9 
10 from sklearn.model_selection import train_test_split
11 X_train, X_test, y_train, y_test = train_test_split(X[['race_encoded']], y, test_size=0.2)
12 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 lookup = tf.keras.layers.StringLookup(output_mode='int')
6 lookup.adapt(X_train_raw['race/ethnicity'])  # ‚úÖ Fit only on training values
7 
8 X_train = X_train_raw.copy()
9 X_test = X_test_raw.copy()
10 X_train['race_encoded'] = lookup(X_train_raw['race/ethnicity'])
11 X_test['race_encoded'] = lookup(X_test_raw['race/ethnicity'])
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StringLookup is applied to the full dataset, including test data, which leads to overlap leakage as test data is included in the vocabulary.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""StringLookup is adapted on the entire dataset before train-test split, allowing test data to influence the encoding.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before the train-test split, leading to data leakage.""
    }
  ]
}
","[Training method: adapt, Training line: 6]  
[Testing method: None, Testing line: None]"
204,204,204.0,Categorical Encoding,Nominal data,CategoryEncoding,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Vocabulary learned before splitting ‚Äî includes test distribution
8 lookup = tf.keras.layers.StringLookup()
9 lookup.adapt(X['Embarked'])
10 X_int = lookup(X['Embarked'])
11 
12 # One-hot encoding before split ‚Äî test data already influences the encoder structure
13 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
14 X['Embarked_encoded'] = list(encoder(X_int).numpy())
15 
16 X_train, X_test, y_train, y_test = train_test_split(X.drop(columns='Embarked'), y, test_size=0.2)
17 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['Embarked'])  # ‚úÖ Adapt only on training data
7 
8 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
9 
10 X_train = X_train_raw.copy()
11 X_test = X_test_raw.copy()
12 X_train['Embarked_encoded'] = list(encoder(lookup(X_train_raw['Embarked'])).numpy())
13 X_test['Embarked_encoded'] = list(encoder(lookup(X_test_raw['Embarked'])).numpy())
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""StringLookup is applied to the full dataset before splitting""},
            {""line_number"": 13, ""explanation"": ""CategoryEncoding is applied to the full dataset before splitting, which includes test data, resulting in the encoder being influenced by the test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""The StringLookup layer is adapted on the entire dataset before the train-test split, allowing test data to influence the vocabulary.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""One-hot encoding is applied to the entire dataset before the train-test split, allowing test data to influence the encoding structure.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Train-test split is performed after the data has already been transformed with the full dataset's encoding.""
    }
  ]
}
","[Training method: adapt, Training line: 9]  
[Testing method: None, Testing line: None]"
205,205,205.0,Categorical Encoding,Nominal data,CategoryEncoding,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Married', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Married', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 lookup = tf.keras.layers.StringLookup()
9 lookup.adapt(X['Married'])  # ‚ùå Vocabulary includes test categories
10 
11 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
12 X['Married_encoded'] = list(encoder(lookup(X['Married'])).numpy())
13 
14 X_train, X_test, y_train, y_test = train_test_split(X.drop(columns='Married'), y, test_size=0.3)
15 ","1 X = df[['Married', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['Married'])  # ‚úÖ Only training data used
7 
8 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
9 
10 X_train = X_train_raw.copy()
11 X_test = X_test_raw.copy()
12 X_train['Married_encoded'] = list(encoder(lookup(X_train_raw['Married'])).numpy())
13 X_test['Married_encoded'] = list(encoder(lookup(X_test_raw['Married'])).numpy())
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""StringLookup is applied to the full dataset before splitting""},
            {""line_number"": 12, ""explanation"": ""CategoryEncoding is applied to the encoded features from the full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""StringLookup is adapted on the entire dataset before the train-test split, allowing test data categories to influence the encoding.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""CategoryEncoding is applied to the full dataset before the train-test split, leading to data leakage as the encoding is influenced by the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Train-test split is performed after encoding has already been applied, which means the test data influenced the encoding process.""
    }
  ]
}
","[Training method: adapt, Training line: 9]  
[Testing method: None, Testing line: None]"
206,206,206.0,Categorical Encoding,Nominal data,CategoryEncoding,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thal', 'age']]
3 y = df['target']
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X['thal'])  # ‚ùå Vocab includes both train & test
7 
8 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
9 X['thal_encoded'] = list(encoder(lookup(X['thal'])).numpy())
10 
11 X_train, X_test, y_train, y_test = train_test_split(X.drop(columns='thal'), y, test_size=0.25)
12 ","1 X = df[['thal', 'age']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['thal'])  # ‚úÖ Train-only vocab
7 
8 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
9 
10 X_train = X_train_raw.copy()
11 X_test = X_test_raw.copy()
12 X_train['thal_encoded'] = list(encoder(lookup(X_train_raw['thal'])).numpy())
13 X_test['thal_encoded'] = list(encoder(lookup(X_test_raw['thal'])).numpy())
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StringLookup is applied to the entire dataset before splitting, resulting in a shared vocabulary between train and test data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""StringLookup is adapted on the entire dataset before the train-test split, causing the vocabulary to include information from both train and test data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""CategoryEncoding is applied to the entire dataset before the train-test split, encoding test data with knowledge from the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded, leading to data leakage.""
    }
  ]
}
","[Training method: adapt, Training line: 6]  
[Testing method: None, Testing line: None]"
207,207,207.0,Categorical Encoding,Nominal data,CategoryEncoding,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 X = df[['race/ethnicity']]
3 y = df['math score']
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X['race/ethnicity'])  # ‚ùå Uses test data in vocab
7 
8 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
9 X['race_encoded'] = list(encoder(lookup(X['race/ethnicity'])).numpy())
10 
11 X_train, X_test, y_train, y_test = train_test_split(X.drop(columns='race/ethnicity'), y, test_size=0.2)
","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 lookup = tf.keras.layers.StringLookup()
6 lookup.adapt(X_train_raw['race/ethnicity'])  # ‚úÖ No test data seen here
7 
8 encoder = tf.keras.layers.CategoryEncoding(num_tokens=lookup.vocabulary_size(), output_mode=""one_hot"")
9 
10 X_train = X_train_raw.copy()
11 X_test = X_test_raw.copy()
12 X_train['race_encoded'] = list(encoder(lookup(X_train_raw['race/ethnicity'])).numpy())
13 X_test['race_encoded'] = list(encoder(lookup(X_test_raw['race/ethnicity'])).numpy())
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StringLookup uses test data for creating vocabulary""},
            {""line_number"": 9, ""explanation"": ""One-hot encoding is performed on the full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""StringLookup is adapted on the entire dataset before train-test split, allowing test data to influence the vocabulary.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""CategoryEncoding is applied using the adapted lookup from the entire dataset, contaminating the training and test data.""
    }
  ]
}
","[Training method: adapt, Training line: 6]  
[Testing method: None, Testing line: None]"
208,208,208.0,Categorical Encoding,Ordinal data,WOEEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå WOEEncoder fit before split ‚Äî leakage: uses test target distribution
8 encoder = WOEEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = WOEEncoder(cols=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""WOEEncoder fit before split ‚Äî leakage: uses test target distribution""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""WOEEncoder is fit on the entire dataset before the train-test split, allowing information from the test set to influence the encoding.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
209,209,209.0,Categorical Encoding,Ordinal data,WOEEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 encoder = WOEEncoder(cols=['Education'])
9 X_encoded = encoder.fit_transform(X, y)  # ‚ùå Fit on all data (train + test)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
12 
13 from sklearn.tree import DecisionTreeClassifier
14 model = DecisionTreeClassifier()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = WOEEncoder(cols=['Education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Fit WOEEncoder on full dataset before splitting into train and test sets""},
            {""line_number"": 11, ""explanation"": ""X_train and X_test are created after X is encoded, causing overlap leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the entire dataset before train-test split, allowing test data information to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded, using information from the entire dataset.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that has been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been encoded using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
210,210,210.0,Categorical Encoding,Ordinal data,WOEEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['cp', 'thalach']]
3 y = df['target']
4 
5 encoder = WOEEncoder(cols=['cp'])
6 X_encoded = encoder.fit_transform(X, y)  # ‚ùå Fit on full dataset, including test labels
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
9 
10 from sklearn.ensemble import RandomForestClassifier
11 model = RandomForestClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['cp', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = WOEEncoder(cols=['cp'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Fit the encoder on the full dataset, including test labels, which leads to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""WOEEncoder is fit on the entire dataset, including test labels, causing data leakage as the transformation is influenced by the test data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data, leading to an overestimated performance.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
211,211,211.0,Categorical Encoding,Ordinal data,WOEEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['parental level of education', 'math score']].dropna()
3 df['pass'] = (df['math score'] >= 60).astype(int)  # Binary outcome for classification
4 
5 X = df[['parental level of education']]
6 y = df['pass']
7 
8 encoder = WOEEncoder(cols=['parental level of education'])
9 X_encoded = encoder.fit_transform(X, y)  # ‚ùå Fit on entire data (leaky)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
12 
13 from sklearn.linear_model import LogisticRegression
14 model = LogisticRegression()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['parental level of education']]
2 y = df['pass']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = WOEEncoder(cols=['parental level of education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""Fit WOEEncoder on entire dataset (X, y) instead of splitting it first""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the training process.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data during encoding.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
212,212,212.0,Categorical Encoding,Ordinal data,MeanEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Mean encoding done on full dataset before splitting ‚Äî test target leakage
8 encoder = TargetEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = TargetEncoder(cols=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""TargetEncoder applied to full dataset before splitting ‚Äî test target leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Mean encoding is applied to the full dataset before train-test split, allowing test data target information to influence the transformation.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been mean encoded, which means the test data has influenced the encoding applied to the training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through mean encoding.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was used in the mean encoding process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
213,213,213.0,Categorical Encoding,Ordinal data,MeanEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
3 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 encoder = TargetEncoder(cols=['Education'])
9 # ‚ùå Fit on full dataset ‚Äî test target values included in encoding
10 X_encoded = encoder.fit_transform(X, y)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
13 
14 from sklearn.tree import DecisionTreeClassifier
15 model = DecisionTreeClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = TargetEncoder(cols=['Education'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""TargetEncoder is fit on the full dataset with target values included, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Target encoding is applied to the full dataset before train-test split, allowing test target values to influence the encoding.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after the data has already been target encoded using the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to target encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the target encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
214,214,214.0,Categorical Encoding,Ordinal data,MeanEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['cp', 'thalach']]
3 y = df['target']
4 
5 encoder = TargetEncoder(cols=['cp'])
6 # ‚ùå Fit before train-test split ‚Äî target mean from test set leaks
7 X_encoded = encoder.fit_transform(X, y)
8 
9 from sklearn.model_selection import train_test_split
10 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
11 
12 from sklearn.ensemble import RandomForestClassifier
13 model = RandomForestClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['cp', 'thalach']]
2 y = df['target']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = TargetEncoder(cols=['cp'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 7, ""explanation"": ""TargetEncoder is fit on the full dataset, including test data, leading to target leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Target encoding is applied to the full dataset before train-test split, allowing target mean from the test set to influence the training data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after target encoding has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to target encoding.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by target encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
215,215,215.0,Categorical Encoding,Ordinal data,MeanEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['race/ethnicity', 'math score']].dropna()
3 
4 X = df[['race/ethnicity']]
5 y = df['math score']
6 
7 encoder = TargetEncoder(cols=['race/ethnicity'])
8 # ‚ùå Fit on full dataset ‚Äî math scores from test set used in training transformation
9 X_encoded = encoder.fit_transform(X, y)
10 
11 from sklearn.model_selection import train_test_split
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.linear_model import LinearRegression
15 model = LinearRegression()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = TargetEncoder(cols=['race/ethnicity'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""TargetEncoder is fit on the full dataset, including math scores from test set, which leaks information into the transformation of the predictor variable.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Target encoding is applied to the full dataset before train-test split, allowing test data's target values to influence the encoding.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after target encoding has already been applied to the entire dataset.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to target encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the target encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
216,216,216.0,Categorical Encoding,Ordinal data,QuantileEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Encoder fit on full dataset before splitting ‚Äî test target influences encoding
8 encoder = QuantileEncoder(variables=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = QuantileEncoder(variables=['Embarked'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LogisticRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Encoder fit on full dataset before splitting ‚Äî test target influences encoding""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test target information to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
217,217,217.0,Categorical Encoding,Ordinal data,QuantileEncoder,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['Neighborhood', 'SalePrice']].dropna()
3 
4 X = df[['Neighborhood']]
5 y = df['SalePrice']
6 
7 encoder = QuantileEncoder(variables=['Neighborhood'])
8 X_encoded = encoder.fit_transform(X, y)  # ‚ùå Fit on entire data
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
11 
12 from sklearn.linear_model import LinearRegression
13 model = LinearRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Neighborhood']]
2 y = df['SalePrice']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = QuantileEncoder(variables=['Neighborhood'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Fit QuantileEncoder on the entire dataset before splitting it into train and test sets""},
            {""line_number"": 10, ""explanation"": ""X_encoded should be created using only the train set data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been encoded.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
218,218,218.0,Categorical Encoding,Ordinal data,QuantileEncoder,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['quality']]
3 y = df['alcohol']
4 
5 encoder = QuantileEncoder(variables=['quality'])
6 X_encoded = encoder.fit_transform(X, y)  # ‚ùå Fit on full data, test values influence mapping
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
9 
10 from sklearn.linear_model import LinearRegression
11 model = LinearRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['quality']]
2 y = df['alcohol']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = QuantileEncoder(variables=['quality'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = LinearRegression()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""QuantileEncoder fit on full dataset with target variable present, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data values to influence the encoding mapping.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior encoding.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding step applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
219,219,219.0,Categorical Encoding,Ordinal data,QuantileEncoder,"1 df = pd.read_csv(""StudentsPerformance.csv"")
2 df = df[['race/ethnicity', 'math score']].dropna()
3 
4 X = df[['race/ethnicity']]
5 y = df['math score']
6 
7 encoder = QuantileEncoder(variables=['race/ethnicity'])
8 X_encoded = encoder.fit_transform(X, y)  # ‚ùå Fit before split
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
11 
12 from sklearn.linear_model import Ridge
13 model = Ridge()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['race/ethnicity']]
2 y = df['math score']
3 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = QuantileEncoder(variables=['race/ethnicity'])
6 X_train_encoded = encoder.fit_transform(X_train, y_train)
7 X_test_encoded = encoder.transform(X_test)
8 
9 model = Ridge()
10 model.fit(X_train_encoded, y_train)
11 print(model.score(X_test_encoded, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""QuantileEncoder is fit on the full dataset (X, y) instead of the train set.""},
            {""line_number"": 10, ""explanation"": ""train_test_split() is not called on the original dataset (df), causing X and y to still be connected.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Encoding is applied to the full dataset before train-test split, allowing test data information to influence the encoding applied to the training data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been encoded using information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that has been encoded with information from the test data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the encoding process applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
220,220,220.0,Categorical Encoding,Ordinal data,TargetEncoder,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Embarked', 'Fare', 'Survived']].dropna()
3 
4 X = df[['Embarked', 'Fare']]
5 y = df['Survived']
6 
7 # ‚ùå Leaky: Fit encoder on full dataset, including target from test set
8 encoder = TargetEncoder(cols=['Embarked'])
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Embarked', 'Fare']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 encoder = TargetEncoder(cols=['Embarked'])
6 X_train = encoder.fit_transform(X_train_raw, y_train)
7 X_test = encoder.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""TargetEncoder is fit on the full dataset, including target from the test set, causing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Target encoding is applied to the full dataset before train-test split, allowing test data information to influence the transformation.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been target encoded with information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to target encoding.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the target encoding applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
221,221,221.0,Categorical Encoding,Ordinal data,TargetEncoder,"1 df = pd.read_csv(""house_prices.csv"")
2 df = df[['Neighborhood', 'SalePrice']].dropna()
3 
4 X = df[['Neighborhood']]
5 y = df['SalePrice']
6 
7 encoder = TargetEncoder(cols=['Neighborhood'])
8 # ‚ùå Leaky: test targets used during encoding
9 X_encoded = encoder.fit_transform(X, y)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)
12 
13 from sklearn.linear_model import Ridge
14 model = Ridge()
15 model.fit(X_train, y_train)
16 print(model.score(X_test, y_test))
17 ","1 X = df[['Neighborhood']]
2 y = df['SalePrice']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 encoder = TargetEncoder(cols=['Neighborhood'])
6 X_train = encoder.fit_transform(X_train_raw, y_train)
7 X_test = encoder.transform(X_test_raw)
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""TargetEncoder encodes target values based on the full dataset, including test data, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Target encoding is applied to the entire dataset before the train-test split, allowing test data information to influence the encoding process.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after the data has already been encoded with information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to improper encoding.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during encoding.""
    }
  ]
}
","[Training method: fit, Training line: 15]  
[Testing method: score, Testing line: 16]"
222,222,222.0,Categorical Encoding,Ordinal data,TargetEncoder,"1 df = pd.read_csv(""loan_data.csv"")
2 df['Loan_Status'] = df['Loan_Status'].map({'Y': 1, 'N': 0})
3 df = df[['Education', 'LoanAmount', 'Loan_Status']].dropna()
4 
5 X = df[['Education', 'LoanAmount']]
6 y = df['Loan_Status']
7 
8 encoder = TargetEncoder(cols=['Education'])
9 # ‚ùå Applied before split ‚Äî test outcome influences encoding
10 X_encoded = encoder.fit_transform(X, y)
11 
12 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
13 
14 from sklearn.tree import DecisionTreeClassifier
15 model = DecisionTreeClassifier()
16 model.fit(X_train, y_train)
17 print(model.score(X_test, y_test))
18 ","1 X = df[['Education', 'LoanAmount']]
2 y = df['Loan_Status']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = TargetEncoder(cols=['Education'])
6 X_train = encoder.fit_transform(X_train_raw, y_train)
7 X_test = encoder.transform(X_test_raw)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 10, ""explanation"": ""TargetEncoder is applied to the full dataset before the train-test split, leading to preprocessing leakage as the encoding depends on the target variable.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 10,
      ""explanation"": ""Target encoding is applied to the entire dataset before the train-test split, allowing information from the test set to influence the encoding process.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Train-test split is performed after target encoding has already been applied to the full dataset, leading to data leakage.""
    },
    {
      ""line_number"": 16,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by the test data through target encoding.""
    },
    {
      ""line_number"": 17,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was used in the target encoding process.""
    }
  ]
}
","[Training method: fit, Training line: 16]  
[Testing method: score, Testing line: 17]"
223,223,223.0,Categorical Encoding,Ordinal data,TargetEncoder,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['cp', 'thalach']]
3 y = df['target']
4 
5 encoder = TargetEncoder(cols=['cp'])
6 # ‚ùå Encoder sees all target data, including test labels
7 X_encoded = encoder.fit_transform(X, y)
8 
9 from sklearn.model_selection import train_test_split
10 X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3)
11 
12 from sklearn.ensemble import RandomForestClassifier
13 model = RandomForestClassifier()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['cp', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 encoder = TargetEncoder(cols=['cp'])
6 X_train = encoder.fit_transform(X_train_raw, y_train)
7 X_test = encoder.transform(X_test_raw)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""TargetEncoder takes target data as an argument, causing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Target encoding is applied to the full dataset before train-test split, allowing test data labels to influence the encoding.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been target encoded with test labels.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training process.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
224,224,224.0,Feature Scaling,Standardization,StandardScaler,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Scaler fit on entire dataset ‚Äî includes test info
8 scaler = StandardScaler()
9 X_scaled = scaler.fit_transform(X)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)  # ‚úÖ Fit only on training data
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""StandardScaler fit on entire dataset before splitting""},
            {""line_number"": 11, ""explanation"": ""train_test_split is not called before fitting the model""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
225,225,225.0,Feature Scaling,Standardization,StandardScaler,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['alcohol', 'residual sugar']]
3 y = df['quality']
4 
5 scaler = StandardScaler()
6 X_scaled = scaler.fit_transform(X)  # ‚ùå Includes full target info indirectly
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
9 
10 from sklearn.ensemble import RandomForestClassifier
11 model = RandomForestClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['alcohol', 'residual sugar']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StandardScaler is fit on the entire dataset, including target variable 'quality', and the same scaler is used to transform both train and test sets, leaking information about the target to the test set.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled using information from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been scaled using test data information.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
226,226,226.0,Feature Scaling,Standardization,StandardScaler,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Glucose', 'BMI']]
3 y = df['Outcome']
4 
5 scaler = StandardScaler()
6 X_scaled = scaler.fit_transform(X)  # ‚ùå Mean/Std from test set included
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StandardScaler fit_transform method applies scaling to the entire dataset, including the test set, and stores the mean and std in the scaler object, which is then used to transform the test set. This leaks test data information to the training set, leading to overfitting and biased results.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before train-test split, allowing test data statistics to influence the scaling parameters.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled with parameters derived from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to improper scaling.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using parameters derived from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
227,227,227.0,Feature Scaling,Standardization,StandardScaler,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thalach', 'chol']]
3 y = df['target']
4 
5 scaler = StandardScaler()
6 X_scaled = scaler.fit_transform(X)  # ‚ùå Includes test stats
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
9 
10 from sklearn.svm import SVC
11 model = SVC()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['thalach', 'chol']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = SVC()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""StandardScaler fit_transform method computes statistics on the whole dataset, including test data. This results in the test data being scaled using the training data statistics, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled using the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been scaled using test data statistics.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been scaled using the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
228,228,228.0,Feature Scaling,Standardization,RobustScaler,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Leaky: Fit RobustScaler on entire dataset before splitting
8 scaler = RobustScaler()
9 X_scaled = scaler.fit_transform(X)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = RobustScaler()
6 X_train = scaler.fit_transform(X_train_raw)  # ‚úÖ Fit only on training data
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""RobustScaler is fit on the entire dataset (X) before splitting it into train and test sets, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Scaling is applied to the entire dataset before train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been scaled using information from the entire dataset.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data that was scaled using information from the test set.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the training set.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
229,229,229.0,Feature Scaling,Standardization,RobustScaler,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['density', 'residual sugar']]
3 y = df['quality']
4 
5 # ‚ùå Leaky: test info used to compute medians/IQR
6 scaler = RobustScaler()
7 X_scaled = scaler.fit_transform(X)
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
10 
11 from sklearn.ensemble import RandomForestClassifier
12 model = RandomForestClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['density', 'residual sugar']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 scaler = RobustScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""RobustScaler is fit on the entire dataset, including test data, before splitting. This can lead to leakage as the scaler learns statistics from the test data which can affect the model's performance on the test data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
230,230,230.0,Feature Scaling,Standardization,RobustScaler,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Insulin', 'BMI']]
3 y = df['Outcome']
4 
5 # ‚ùå Leaky: RobustScaler learns from test data
6 scaler = RobustScaler()
7 X_scaled = scaler.fit_transform(X)
8 
9 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Insulin', 'BMI']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = RobustScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""RobustScaler should be fit on the training data only and then transformed for both training and test data.""},
            {""line_number"": 9, ""explanation"": ""train_test_split should be called before scaling the data to prevent the scaler from learning from test data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 7,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
231,231,231.0,Feature Scaling,Standardization,RobustScaler,"1 df = pd.read_csv(""heart.csv"")
2 df = df[['chol', 'thalach', 'target']].dropna()
3 
4 X = df[['chol', 'thalach']]
5 y = df['target']
6 
7 # ‚ùå Leaky: Scaler fitted on full dataset before splitting ‚Äî test info used
8 scaler = RobustScaler()
9 X_scaled = scaler.fit_transform(X)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
12 
13 model = SVC()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = RobustScaler()
6 X_train = scaler.fit_transform(X_train_raw)  # ‚úÖ Only fit on training set
7 X_test = scaler.transform(X_test_raw)
8 
9 model = SVC()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""RobustScaler fitted on full dataset before splitting ‚Äî test info used""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
232,232,232.0,Feature Scaling,Standardization,quantile_transform,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Transformation applied before train-test split (includes test info)
8 X_scaled = quantile_transform(X, output_distribution='normal')
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = QuantileTransformer(output_distribution='normal')
6 X_train = scaler.fit_transform(X_train_raw)  # ‚úÖ Fit only on training data
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Min-MaxScaler applied to the entire dataset before splitting it into train and test sets, potentially leaking test data into the training process""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Quantile transformation is applied to the entire dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been transformed, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data, which was influenced by the training data transformation.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
233,233,233.0,Feature Scaling,Standardization,quantile_transform,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['pH', 'residual sugar']]
3 y = df['quality']
4 
5 # ‚ùå Fit-transform on full dataset ‚Äî test values leak
6 X_scaled = quantile_transform(X, output_distribution='normal')
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
9 
10 from sklearn.tree import DecisionTreeClassifier
11 model = DecisionTreeClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['pH', 'residual sugar']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = QuantileTransformer(output_distribution='normal')
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 6, ""explanation"": ""Min-MaxScaler applied to full dataset before splitting, leading to preprocessing leakage.""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
234,234,234.0,Feature Scaling,Standardization,quantile_transform,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Glucose', 'Insulin']]
3 y = df['Outcome']
4 
5 # ‚ùå Fit on full data ‚Äî includes test distribution
6 X_scaled = quantile_transform(X, output_distribution='normal')
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['Glucose', 'Insulin']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 scaler = QuantileTransformer(output_distribution='normal')
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting""},
            {""line_number"": 8, ""explanation"": ""X_train, X_test, y_train, y_test are created based on scaled data, resulting in overlap leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data distribution to influence the scaling parameters.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior scaling.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
235,235,235.0,Feature Scaling,Standardization,quantile_transform,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['chol', 'thalach']]
3 y = df['target']
4 
5 # ‚ùå Scaling before splitting ‚Äî includes info from test set
6 X_scaled = quantile_transform(X, output_distribution='uniform')
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
9 
10 from sklearn.svm import SVC
11 model = SVC()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = QuantileTransformer(output_distribution='uniform')
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = SVC()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Min-Max Scaler applied to the full dataset before splitting, which includes test data, leading to preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data distribution to influence the scaling parameters.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled, which means the test data influenced the scaling applied to the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that was scaled using information from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
236,236,236.0,Feature Scaling,Standardization,Preprocessing.scale(),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Scaling before splitting ‚Äî test data affects mean/std
8 X_scaled = scale(X)
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))","1 from sklearn.preprocessing import StandardScaler
2 
3 X = df[['Fare', 'Age']]
4 y = df['Survived']
5 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
6 
7 scaler = StandardScaler()
8 X_train = scaler.fit_transform(X_train_raw)
9 X_test = scaler.transform(X_test_raw)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {""leakage_detected"": true,
     ""leakage_lines"": [
         {""line_number"": 8, ""explanation"": ""MinMaxScaler applied to full dataset before splitting, affecting mean/std of test data""}
     ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling parameters (mean and standard deviation) used for training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been scaled, meaning the test data has influenced the scaling applied to the training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been improperly scaled using information from the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset, including the training data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
237,237,237.0,Feature Scaling,Standardization,Preprocessing.scale(),"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['density', 'pH']]
3 y = df['quality']
4 
5 from sklearn.preprocessing import scale
6 X_scaled = scale(X)  # ‚ùå Fit on entire data, test info included
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
9 
10 from sklearn.linear_model import Ridge
11 model = Ridge()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['density', 'pH']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = Ridge()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler is fit on the entire dataset before splitting, causing preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before train-test split, allowing test data statistics to influence the scaling of training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled with test data information.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that includes test data information from scaling.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
238,238,238.0,Feature Scaling,Standardization,Preprocessing.scale(),"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Glucose', 'BMI']]
3 y = df['Outcome']
4 
5 from sklearn.preprocessing import scale
6 X_scaled = scale(X)  # ‚ùå Leaky: scaler sees test distribution
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting, the scaler sees the test distribution, and therefore, the scaler can leak information about the test set to the model.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled, meaning the test data influenced the scaling applied to the training data.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that was scaled using information from the test data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
239,239,239.0,Feature Scaling,Standardization,Preprocessing.scale(),"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thalach', 'chol']]
3 y = df['target']
4 
5 X_scaled = scale(X)  # ‚ùå Scaling includes all data, test labels influence distribution
6 
7 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
8 
9 from sklearn.ensemble import RandomForestClassifier
10 model = RandomForestClassifier()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 ","1 X = df[['thalach', 'chol']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = StandardScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""MinMaxScaler applied to full dataset before splitting, test labels influence distribution""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 5,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Model is trained on the contaminated training data that has been improperly scaled using information from the test set.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 11]  
[Testing method: score, Testing line: 12]"
240,240,240.0,Feature Scaling,Standardization,Manual standardization (using mean() and std()),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Manual standardization using full dataset statistics (leakage)
8 X_standardized = (X - X.mean()) / X.std()
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_standardized, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Compute mean and std only on training data
6 train_mean = X_train_raw.mean()
7 train_std = X_train_raw.std()
8 
9 X_train = (X_train_raw - train_mean) / train_std
10 X_test = (X_test_raw - train_mean) / train_std
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Standardization applied to full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Standardization is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been standardized using the full dataset statistics.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
241,241,241.0,Feature Scaling,Standardization,Manual standardization (using mean() and std()),"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['pH', 'density']]
3 y = df['quality']
4 
5 # ‚ùå Standardizing using full dataset mean/std (test info included)
6 X_scaled = (X - X.mean()) / X.std()
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['pH', 'density']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 mean_train = X_train_raw.mean()
6 std_train = X_train_raw.std()
7 
8 X_train = (X_train_raw - mean_train) / std_train
9 X_test = (X_test_raw - mean_train) / std_train
10 
11 model = Ridge()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Standardizing using full dataset mean/std before splitting leads to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Standardization is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been standardized.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
242,242,242.0,Feature Scaling,Standardization,Manual standardization (using mean() and std()),"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['BMI', 'Glucose']]
3 y = df['Outcome']
4 
5 # ‚ùå Mean/std computed from full dataset (leaky)
6 X_scaled = (X - X.mean()) / X.std()
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['BMI', 'Glucose']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 mean_train = X_train_raw.mean()
6 std_train = X_train_raw.std()
7 
8 X_train = (X_train_raw - mean_train) / std_train
9 X_test = (X_test_raw - mean_train) / std_train
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Mean and standard deviation calculated from the full dataset before splitting, which can introduce bias in the scaling process. Instead, they should be calculated separately for the training and testing sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been scaled using statistics from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been scaled using the full dataset's statistics.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been scaled using the full dataset's statistics.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
243,243,243.0,Feature Scaling,Standardization,Manual standardization (using mean() and std()),"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thalach', 'chol']]
3 y = df['target']
4 
5 # ‚ùå Stats include test data
6 X_scaled = (X - X.mean()) / X.std()
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
10 
11 from sklearn.svm import SVC
12 model = SVC()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['thalach', 'chol']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 mean_train = X_train_raw.mean()
6 std_train = X_train_raw.std()
7 
8 X_train = (X_train_raw - mean_train) / std_train
9 X_test = (X_test_raw - mean_train) / std_train
10 
11 model = SVC()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""Statistics are computed on the full dataset, including test data""},
            {""line_number"": 5, ""explanation"": ""Scaling is applied to the full dataset, including test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
244,244,244.0,Feature Scaling,Normalization,MinMaxScaler,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Leaky: Scaler fit before splitting (test values influence min/max)
8 scaler = MinMaxScaler()
9 X_scaled = scaler.fit_transform(X)
10 
11 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
12 
13 model = LogisticRegression()
14 model.fit(X_train, y_train)
15 print(model.score(X_test, y_test))
16 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = MinMaxScaler()
6 X_train = scaler.fit_transform(X_train_raw)  # ‚úÖ Fit only on training set
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 9, ""explanation"": ""MinMaxScaler fit on the entire dataset before splitting, which introduces preprocessing leakage as test values influence the min/max values used for scaling train data.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 9,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence the scaling parameters.""
    },
    {
      ""line_number"": 11,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 15,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 14]  
[Testing method: score, Testing line: 15]"
245,245,245.0,Feature Scaling,Normalization,MinMaxScaler,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['residual sugar', 'pH']]
3 y = df['quality']
4 
5 scaler = MinMaxScaler()
6 X_scaled = scaler.fit_transform(X)  # ‚ùå Leaky: test values influence scaling
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
9 
10 from sklearn.tree import DecisionTreeClassifier
11 model = DecisionTreeClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['residual sugar', 'pH']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = MinMaxScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = DecisionTreeClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting, which can lead to preprocessing leakage as test values influence scaling""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before train-test split, allowing test data statistics to influence the scaling of training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled, leading to data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been improperly scaled.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that has been improperly scaled.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
246,246,246.0,Feature Scaling,Normalization,MinMaxScaler,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Glucose', 'BMI']]
3 y = df['Outcome']
4 
5 scaler = MinMaxScaler()
6 X_scaled = scaler.fit_transform(X)  # ‚ùå Scaling uses future/test data
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 scaler = MinMaxScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled using information from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been scaled using information from the test data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
247,247,247.0,Feature Scaling,Normalization,MinMaxScaler,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['chol', 'thalach']]
3 y = df['target']
4 
5 scaler = MinMaxScaler()
6 X_scaled = scaler.fit_transform(X)  # ‚ùå Includes test data during min/max
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
9 
10 from sklearn.svm import SVC
11 model = SVC()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = MinMaxScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = SVC()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data to influence the scaling parameters.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled using information from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that was scaled using test data information.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
248,248,248.0,Feature Scaling,Normalization,maxabs_scale,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Leaky: applied before split ‚Äî test values influence scaling
8 X_scaled = maxabs_scale(X)
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 from sklearn.preprocessing import MaxAbsScaler
2 
3 X = df[['Fare', 'Age']]
4 y = df['Survived']
5 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
6 
7 scaler = MaxAbsScaler()
8 X_train = scaler.fit_transform(X_train_raw)  # ‚úÖ Only fit on training set
9 X_test = scaler.transform(X_test_raw)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Min-Max Scaler applied to full dataset before splitting, affecting test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data to influence the scaling parameters used on the training data.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been scaled, meaning the test data influenced the scaling applied to the training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that was scaled using information from the test data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
249,249,249.0,Feature Scaling,Normalization,maxabs_scale,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['alcohol', 'density']]
3 y = df['quality']
4 
5 from sklearn.preprocessing import maxabs_scale
6 X_scaled = maxabs_scale(X)  # ‚ùå Leaky ‚Äî test stats influence max scaling
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)
9 
10 from sklearn.ensemble import RandomForestClassifier
11 model = RandomForestClassifier()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['alcohol', 'density']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 scaler = MaxAbsScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = RandomForestClassifier()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MaxAbsScaler applied to full dataset before splitting, test stats can influence scaling""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""MaxAbsScaler is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after the data has already been scaled using statistics from the entire dataset.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that has been scaled using test data statistics.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using the entire dataset's statistics.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
250,250,250.0,Feature Scaling,Normalization,maxabs_scale,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['BMI', 'Insulin']]
3 y = df['Outcome']
4 
5 from sklearn.preprocessing import maxabs_scale
6 X_scaled = maxabs_scale(X)  # ‚ùå Includes test data in scaling
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)
9 
10 from sklearn.linear_model import LogisticRegression
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['BMI', 'Insulin']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 scaler = MaxAbsScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = LogisticRegression()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting, including test data""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled, leading to data leakage.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data that was scaled using information from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data that was scaled using information from the entire dataset.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
251,251,251.0,Feature Scaling,Normalization,maxabs_scale,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['thalach', 'chol']]
3 y = df['target']
4 
5 from sklearn.preprocessing import maxabs_scale
6 X_scaled = maxabs_scale(X)  # ‚ùå Scaling applied to full data
7 
8 X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)
9 
10 from sklearn.svm import SVC
11 model = SVC()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 ","1 X = df[['thalach', 'chol']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 scaler = MaxAbsScaler()
6 X_train = scaler.fit_transform(X_train_raw)
7 X_test = scaler.transform(X_test_raw)
8 
9 model = SVC()
10 model.fit(X_train, y_train)
11 print(model.score(X_test, y_test))
12 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinAbsScaler applied to full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 8,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 12,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 12]  
[Testing method: score, Testing line: 13]"
252,252,252.0,Feature Scaling,Normalization,clip,"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Clip using global min/max ‚Äî includes test data distribution
8 X_clipped = X.clip(lower=X.quantile(0.01), upper=X.quantile(0.99), axis=1)
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_clipped, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Clip using training data only
6 lower = X_train_raw.quantile(0.01)
7 upper = X_train_raw.quantile(0.99)
8 X_train = X_train_raw.clip(lower=lower, upper=upper, axis=1)
9 X_test = X_test_raw.clip(lower=lower, upper=upper, axis=1)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""MinMaxScaler applied to full dataset before splitting""},
            {""line_number"": 10, ""explanation"": ""train_test_split function is not called on the original dataset but on the clipped dataset, which includes test data distribution""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Clipping is applied to the entire dataset before train-test split, allowing test data distribution to influence the transformation.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been clipped using statistics from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test data distribution.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data distribution.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
253,253,253.0,Feature Scaling,Normalization,clip,"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['pH', 'residual sugar']]
3 y = df['quality']
4 
5 # ‚ùå Clipping thresholds based on full data
6 X_clipped = X.clip(lower=X.quantile(0.05), upper=X.quantile(0.95), axis=1)
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_clipped, y, test_size=0.3)
10 
11 from sklearn.ensemble import RandomForestClassifier
12 model = RandomForestClassifier()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
","1 X = df[['pH', 'residual sugar']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lower = X_train_raw.quantile(0.05)
6 upper = X_train_raw.quantile(0.95)
7 X_train = X_train_raw.clip(lower=lower, upper=upper, axis=1)
8 X_test = X_test_raw.clip(lower=lower, upper=upper, axis=1)
9 
10 model = RandomForestClassifier()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," ""leakage_detected"": true,
    ""leakage_lines"": [
        {""line_number"": 6, ""explanation"": ""Clipping thresholds based on full dataset before splitting, which can introduce bias into the data and lead to overfitting on the training set.""}
    ]
}"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Clipping is applied to the full dataset before train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been clipped using statistics from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that has been influenced by test data statistics.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the clipping operation applied before the split.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
254,254,254.0,Feature Scaling,Normalization,clip,"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Glucose', 'BMI']]
3 y = df['Outcome']
4 
5 # ‚ùå Uses entire dataset for clipping bounds
6 X_clipped = X.clip(lower=X.min(), upper=X.max(), axis=1)
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_clipped, y, test_size=0.25)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 # ‚úÖ Only use training data stats for clipping
6 lower = X_train_raw.min()
7 upper = X_train_raw.max()
8 X_train = X_train_raw.clip(lower=lower, upper=upper, axis=1)
9 X_test = X_test_raw.clip(lower=lower, upper=upper, axis=1)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 5, ""explanation"": ""MinMaxScaler applied to full dataset before splitting""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Clipping is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been clipped using bounds from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
255,255,255.0,Feature Scaling,Normalization,clip,"1 df = pd.read_csv(""heart.csv"")
2 X = df[['chol', 'thalach']]
3 y = df['target']
4 
5 # ‚ùå Clipping full dataset before split ‚Äî leakage
6 X_clipped = X.clip(lower=X.quantile(0.05), upper=X.quantile(0.95), axis=1)
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_clipped, y, test_size=0.3)
10 
11 from sklearn.svm import SVC
12 model = SVC()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 lower = X_train_raw.quantile(0.05)
6 upper = X_train_raw.quantile(0.95)
7 X_train = X_train_raw.clip(lower=lower, upper=upper, axis=1)
8 X_test = X_test_raw.clip(lower=lower, upper=upper, axis=1)
9 
10 model = SVC()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Clipping the full dataset before splitting leads to preprocessing leakage, as the same transformations are applied to both training and testing sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Clipping is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been clipped.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
256,256,256.0,Feature Scaling,Normalization,Manual normalization (using min() and max()),"1 df = pd.read_csv(""titanic.csv"")
2 df = df[['Fare', 'Age', 'Survived']].dropna()
3 
4 X = df[['Fare', 'Age']]
5 y = df['Survived']
6 
7 # ‚ùå Normalization using min and max from the full dataset (leakage)
8 X_norm = (X - X.min()) / (X.max() - X.min())
9 
10 X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2)
11 
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Fare', 'Age']]
2 y = df['Survived']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 # ‚úÖ Fit transformation only on training data
6 X_min = X_train_raw.min()
7 X_max = X_train_raw.max()
8 X_train = (X_train_raw - X_min) / (X_max - X_min)
9 X_test = (X_test_raw - X_min) / (X_max - X_min)
10 
11 model = LogisticRegression()
12 model.fit(X_train, y_train)
13 print(model.score(X_test, y_test))
14 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 8, ""explanation"": ""Normalization using min and max from the full dataset (leakage) before splitting the data into train and test sets.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 8,
      ""explanation"": ""Normalization is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 10,
      ""explanation"": ""Train-test split is performed after data has already been normalized.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
257,257,257.0,Feature Scaling,Normalization,Manual normalization (using min() and max()),"1 df = pd.read_csv(""winequality-red.csv"")
2 X = df[['alcohol', 'density']]
3 y = df['quality']
4 
5 # ‚ùå Normalization includes test info
6 X_norm = (X - X.min()) / (X.max() - X.min())
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25)
10 
11 from sklearn.linear_model import Ridge
12 model = Ridge()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['alcohol', 'density']]
2 y = df['quality']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.25)
4 
5 X_min = X_train_raw.min()
6 X_max = X_train_raw.max()
7 X_train = (X_train_raw - X_min) / (X_max - X_min)
8 X_test = (X_test_raw - X_min) / (X_max - X_min)
9 
10 model = Ridge()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Normalization is applied to the full dataset before the train-test split, causing preprocessing leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Normalization is applied to the entire dataset before the train-test split, allowing test data statistics to influence the scaling of the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been normalized using information from the entire dataset.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the training data that has been contaminated by test data information due to improper normalization.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the test data that has been contaminated by training data information due to improper normalization.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
258,258,258.0,Feature Scaling,Normalization,Manual normalization (using min() and max()),"1 df = pd.read_csv(""diabetes.csv"")
2 X = df[['Glucose', 'BMI']]
3 y = df['Outcome']
4 
5 # ‚ùå Test data included in normalization
6 X_norm = (X - X.min()) / (X.max() - X.min())
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3)
10 
11 from sklearn.linear_model import LogisticRegression
12 model = LogisticRegression()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['Glucose', 'BMI']]
2 y = df['Outcome']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.3)
4 
5 X_min = X_train_raw.min()
6 X_max = X_train_raw.max()
7 X_train = (X_train_raw - X_min) / (X_max - X_min)
8 X_test = (X_test_raw - X_min) / (X_max - X_min)
9 
10 model = LogisticRegression()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
13 "," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""MinMaxScaler applied to full dataset before splitting, leading to preprocessing leakage""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Normalization is applied to the entire dataset before the train-test split, allowing test data statistics to influence the training data.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been normalized using the entire dataset, leading to data leakage.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data that includes information from the test set due to prior normalization.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data that was influenced by the training data during normalization.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
259,259,259.0,Feature Scaling,Normalization,Manual normalization (using min() and max()),"1 df = pd.read_csv(""heart.csv"")
2 X = df[['chol', 'thalach']]
3 y = df['target']
4 
5 # ‚ùå Scaling based on full data (leakage)
6 X_norm = (X - X.min()) / (X.max() - X.min())
7 
8 from sklearn.model_selection import train_test_split
9 X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2)
10 
11 from sklearn.svm import SVC
12 model = SVC()
13 model.fit(X_train, y_train)
14 print(model.score(X_test, y_test))
15 ","1 X = df[['chol', 'thalach']]
2 y = df['target']
3 X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2)
4 
5 X_min = X_train_raw.min()
6 X_max = X_train_raw.max()
7 X_train = (X_train_raw - X_min) / (X_max - X_min)
8 X_test = (X_test_raw - X_min) / (X_max - X_min)
9 
10 model = SVC()
11 model.fit(X_train, y_train)
12 print(model.score(X_test, y_test))
"," {
        ""leakage_detected"": true,
        ""leakage_lines"": [
            {""line_number"": 6, ""explanation"": ""Min-Max scaling is applied to the full dataset before the train-test split, which can lead to information leakage.""}
        ]
    }"," {
        ""leakage_detected"": false,
        ""leakage_lines"": []
    }","
{
  ""leakage_detected"": true,
  ""leakage_lines"": [
    {
      ""line_number"": 6,
      ""explanation"": ""Scaling is applied to the full dataset before train-test split, allowing test data statistics to influence training.""
    },
    {
      ""line_number"": 9,
      ""explanation"": ""Train-test split is performed after data has already been scaled.""
    },
    {
      ""line_number"": 13,
      ""explanation"": ""Model is trained on the contaminated training data.""
    },
    {
      ""line_number"": 14,
      ""explanation"": ""Model is evaluated on the contaminated test data.""
    }
  ]
}
","[Training method: fit, Training line: 13]  
[Testing method: score, Testing line: 14]"
